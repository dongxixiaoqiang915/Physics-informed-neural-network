{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import argparse\n",
    "from prettytable import PrettyTable\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from ssim_loss import SSIM\n",
    "from Unet_block import *\n",
    "from TIE_model import *\n",
    "from split_dataset import *\n",
    "from initialization import *\n",
    "from torchvision.models import DenseNet\n",
    "from torchvision.models.densenet import _Transition, _load_state_dict\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" #select num.0 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NORMalize(image, MIN_B, MAX_B):\n",
    "    image = (image - MIN_B) / (MAX_B - MIN_B)\n",
    "   #image[image>1] = 1.\n",
    "   #image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "def DENORMalize(image, MIN_B, MAX_B):\n",
    "    image = image * (MAX_B - MIN_B) + MIN_B\n",
    "    return image\n",
    "\n",
    "    \n",
    "def build_phasedata(dataset, norm_range = (0.0, 1.0)):\n",
    "    \n",
    "    nt_red = 6\n",
    "    data = scio.loadmat('')['im']\n",
    "    nx, ny, nt = data.shape\n",
    "    s1 = nt//nt_red\n",
    "    train_s = s1*4\n",
    "    small_sample = s1*4+2\n",
    "    reshape_order = 'C'\n",
    "    \n",
    "    data_path_train_in = '' #file direction\n",
    "    data_path_train_out = ''\n",
    "    data_path_intensity = ''\n",
    "    \n",
    "    mat_im = scio.loadmat(data_path_train_in + '\\\\im')['im']\n",
    "    mat_gt = scio.loadmat(data_path_train_out + '\\\\label')['gt']\n",
    "    mat_id = scio.loadmat(data_path_intensity + '\\\\in')['in']\n",
    "    mat_i0 = scio.loadmat(data_path_intensity + '\\\\i0')['i0']\n",
    "\n",
    "    mat_im = np.reshape(np.transpose(mat_im,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    mat_gt = np.reshape(np.transpose(mat_gt,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    mat_id = np.reshape(np.transpose(mat_id,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    mat_i0 = np.reshape(np.transpose(mat_i0,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        \n",
    "        im = mat_im[:small_sample,...]\n",
    "        gt = mat_gt[:small_sample,...]\n",
    "        I_d = mat_id[:small_sample,...]\n",
    "        I_0= mat_i0[:small_sample,...]\n",
    "        dataset = (im, gt, I_d, I_0)\n",
    "            \n",
    "    if dataset == 'valid':\n",
    "        \n",
    "        im = mat_im[small_sample:small_sample+s1,...]\n",
    "        gt = mat_gt[small_sample:small_sample+s1,...]\n",
    "        I_d = mat_id[small_sample:small_sample+s1,...]\n",
    "        I_0 = mat_i0[small_sample:small_sample+s1,...]\n",
    "        dataset = (im, gt, I_d, I_0)\n",
    "        \n",
    "    if dataset == 'test':\n",
    "        \n",
    "        im = mat_im[s1*5+2:,...]\n",
    "        gt = mat_gt[s1*5+2:,...]\n",
    "        I_d = mat_id[s1*5+2:,...]\n",
    "        I_0 = mat_i0[s1*5+2:,...]\n",
    "        dataset = (im, gt, I_d, I_0)\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "class train_phase_data_loader(Dataset):\n",
    "    def __init__(self, dataset, crop_size=None, crop_n=None):\n",
    "        self.dataset = dataset\n",
    "        self.crop_size = crop_size\n",
    "        self.crop_n = crop_n\n",
    "\n",
    "    def __getitem__(self):\n",
    "        (im, gt, I_d, I_0) = self.dataset\n",
    "        input_img = im\n",
    "        target_img = gt\n",
    "        inten_id = I_d\n",
    "        inten_i0 = I_0\n",
    "\n",
    "        if self.crop_n:\n",
    "            assert input_img.shape == target_img.shape\n",
    "            crop_input = []\n",
    "            crop_target = []\n",
    "            n_c, h, w = input_img.shape\n",
    "            new_h, new_w = self.crop_size, self.crop_size\n",
    "            for _ in range(self.crop_n):\n",
    "                top = np.random.randint(0, h - new_h)\n",
    "                left = np.random.randint(0, w - new_w)\n",
    "                input_img_ = input_img[top:top + new_h, left:left + new_w]\n",
    "                target_img_ = target_img[top:top + new_h, left:left + new_w]\n",
    "                crop_input.append(input_img_)\n",
    "                crop_target.append(target_img_)\n",
    "            crop_input = np.array(crop_input)\n",
    "            crop_target = np.array(crop_target)\n",
    "\n",
    "            sample = (crop_input, crop_target)\n",
    "            return sample\n",
    "        else:\n",
    "            sample = (input_img, target_img, inten_id, inten_i0)\n",
    "            return sample\n",
    "        \n",
    "\n",
    "class LambdaLR_():  #learning_rate schedulers\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)\n",
    "\n",
    "def prep_input(im, mode):\n",
    "    \"\"\"Undersample the batch, then reformat them into what the network accepts.\n",
    "    Parameters: patch the data\n",
    "    \"\"\"\n",
    "    #input variable\n",
    "    (phase_var, target_var, id_var, i0_var) = im\n",
    "    if mode == 'train':\n",
    "        phase_var = torch.tensor(phase_var, requires_grad=True).to(device)\n",
    "    else:\n",
    "        phase_var = torch.tensor(phase_var).to(device)\n",
    "    target_var = torch.tensor(target_var).to(device)\n",
    "    id_var = torch.tensor(id_var).to(device)\n",
    "    i0_var = torch.tensor(i0_var).to(device)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        phase_var = phase_var.type(torch.cuda.FloatTensor)\n",
    "        target_var = target_var.type(torch.cuda.FloatTensor)\n",
    "        id_var = id_var.type(torch.cuda.FloatTensor)\n",
    "        i0_var = i0_var.type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    data = DeepChainMap({'input': phase_var}, {'targets': target_var}, {'fres_input': id_var}, {'inverse_input': i0_var})\n",
    "\n",
    "    return data\n",
    "    \n",
    "\n",
    "def calc_gradeint_penalty(discriminator, real_data, fake_data):\n",
    "    #alpha = torch.rand(real_data.size()[0], 1)\n",
    "    #alpha = alpha.expand(real_data.size())\n",
    "    alpha = torch.Tensor(np.random.random((real_data.size(0),1,1,1)))\n",
    "    alpha = alpha.cuda() if torch.cuda.is_available() else alpha\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = discriminator(interpolates)\n",
    "\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones(disc_interpolates.size()).cuda() if torch.cuda.is_available() else torch.ones(disc_interpolates.size()), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "class no_op(object):\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        pass\n",
    "\n",
    "def maybe_to_torch(d):\n",
    "    if isinstance(d, list):\n",
    "        d = [maybe_to_torch(i) if not isinstance(i, torch.Tensor) else i for i in d]\n",
    "    elif not isinstance(d, torch.Tensor):\n",
    "        d = torch.from_numpy(d).float()\n",
    "    return d\n",
    "\n",
    "\n",
    "def to_cuda(data, non_blocking=True, gpu_id=0):\n",
    "    if isinstance(data, list):\n",
    "        data = [i.cuda(gpu_id, non_blocking=non_blocking) for i in data]\n",
    "    else:\n",
    "        data = data.cuda(gpu_id, non_blocking=True)\n",
    "    return data\n",
    "\n",
    "softmax_helper = lambda x: F.softmax(x, 1)\n",
    "\n",
    "def count_parameters(model):\n",
    "    # table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseUNetEncoder(DenseNet):\n",
    "    def __init__(self, skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, downsample):\n",
    "        super(_DenseUNetEncoder, self).__init__(growth_rate, block_config, num_init_features, bn_size, drop_rate)\n",
    "        \n",
    "        self.skip_connections = skip_connections\n",
    "\n",
    "        # remove last norm, classifier\n",
    "        features = OrderedDict(list(self.features.named_children())[:-1])\n",
    "        delattr(self, 'classifier')\n",
    "        if not downsample:\n",
    "            features['conv0'].stride = 1\n",
    "            del features['pool0']\n",
    "        self.features = nn.Sequential(features)\n",
    "        \n",
    "        for module in self.features.modules():\n",
    "            if isinstance(module, nn.AvgPool2d):\n",
    "                module.register_forward_hook(lambda _, input, output : self.skip_connections.append(input[0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "        \n",
    "class _DenseUNetDecoder(DenseNet):\n",
    "    def __init__(self, skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, upsample):\n",
    "        super(_DenseUNetDecoder, self).__init__(growth_rate, block_config, num_init_features, bn_size, drop_rate)\n",
    "        \n",
    "        self.skip_connections = skip_connections\n",
    "        self.upsample = upsample\n",
    "        \n",
    "        # remove conv0, norm0, relu0, pool0, last denseblock, last norm, classifier\n",
    "        features = list(self.features.named_children())[4:-2]\n",
    "        delattr(self, 'classifier')\n",
    "\n",
    "        num_features = num_init_features\n",
    "        num_features_list = []\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            num_input_features = num_features + num_layers * growth_rate\n",
    "            num_output_features = num_features // 2\n",
    "            num_features_list.append((num_input_features, num_output_features))\n",
    "            num_features = num_input_features // 2\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            name, module = features[i]\n",
    "            if isinstance(module, _Transition):\n",
    "                num_input_features, num_output_features = num_features_list.pop(1)\n",
    "                features[i] = (name, _TransitionUp(num_input_features, num_output_features, skip_connections))\n",
    "\n",
    "        features.reverse()\n",
    "        \n",
    "        self.features = nn.Sequential(OrderedDict(features))\n",
    "        \n",
    "        num_input_features, _ = num_features_list.pop(0)\n",
    "        \n",
    "        if upsample:\n",
    "            self.features.add_module('upsample0', nn.Upsample(scale_factor=4, mode='bilinear'))\n",
    "        self.features.add_module('norm0', nn.BatchNorm2d(num_input_features))\n",
    "        self.features.add_module('relu0', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('conv0', nn.Conv2d(num_input_features, num_init_features, kernel_size=1, stride=1, bias=False))\n",
    "        self.features.add_module('norm1', nn.BatchNorm2d(num_init_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "          \n",
    "        \n",
    "class _Concatenate(nn.Module):\n",
    "    def __init__(self, skip_connections):\n",
    "        super(_Concatenate, self).__init__()\n",
    "        self.skip_connections = skip_connections\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([x, self.skip_connections.pop()], 1)\n",
    "\n",
    "          \n",
    "class _TransitionUp(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features, skip_connections):\n",
    "        super(_TransitionUp, self).__init__()\n",
    "        \n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, num_output_features * 2,\n",
    "                                              kernel_size=1, stride=1, bias=False))\n",
    "        \n",
    "        self.add_module('upsample', nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        self.add_module('cat', _Concatenate(skip_connections))\n",
    "        self.add_module('norm2', nn.BatchNorm2d(num_output_features * 4))\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv2', nn.Conv2d(num_output_features * 4, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "\n",
    "class DenseUNet(nn.Module):\n",
    "    def __init__(self, n_classes, growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64, bn_size=4, drop_rate=0, downsample=False, pretrained_encoder_uri=None, progress=None):\n",
    "        super(DenseUNet, self).__init__()\n",
    "        self.skip_connections = []\n",
    "        self.encoder = _DenseUNetEncoder(self.skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, downsample)\n",
    "        self.decoder = _DenseUNetDecoder(self.skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, downsample)\n",
    "        self.classifier = nn.Conv2d(num_init_features, n_classes, kernel_size=1, stride=1, bias=True)\n",
    "        \n",
    "        self.encoder._load_state_dict = self.encoder.load_state_dict\n",
    "        self.encoder.load_state_dict = lambda state_dict : self.encoder._load_state_dict(state_dict, strict=False)\n",
    "        if pretrained_encoder_uri:\n",
    "            _load_state_dict(self.encoder, str(pretrained_encoder_uri), progress)\n",
    "        self.encoder.load_state_dict = lambda state_dict : self.encoder._load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        y = self.classifier(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks, drop_rate=0.5):\n",
    "        super(Unet, self).__init__()\n",
    "        self.inc = inconv(n_channels, nf, ks)\n",
    "        self.down1 = down(nf, nf*2, ks)\n",
    "        self.down2 = down(nf*2, nf*4, ks)\n",
    "        self.down3 = down(nf*4, nf*8, ks)\n",
    "        self.down4 = down(nf*8, nf*16, ks)\n",
    "        self.up1 = up(nf*24, nf*8, ks)\n",
    "        self.up2 = up(nf*12, nf*4, ks)\n",
    "        self.up3 = up(nf*6, nf*2, ks, drop_rate)\n",
    "        self.up4 = up(nf*3, nf, ks, drop_rate)\n",
    "        self.outc = outconv(nf, n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, im):\n",
    "        raw = im['input']\n",
    "\n",
    "        x1 = self.inc(raw)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        x = self.outc(x)\n",
    "\n",
    "        x = raw - x\n",
    "\n",
    "        return x\n",
    "\n",
    "class Seven_Unetplusplus(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks, drop_rate=0.5):\n",
    "        super(Seven_Unetplusplus, self).__init__()\n",
    "        self.inc = inconv(n_channels, nf, ks)\n",
    "        self.down1 = down(nf, nf*2, ks)\n",
    "        self.down2 = down(nf*2, nf*4, ks)\n",
    "        self.down3 = down(nf*4, nf*8, ks)\n",
    "        self.up1 = up(nf*12, nf*4, ks)\n",
    "        self.up2 = up(nf*6, nf*2, ks, drop_rate)\n",
    "        self.up3 = up(nf*3, nf, ks, drop_rate)\n",
    "        \n",
    "        self.dense1 = Dense_Block(nf,3)\n",
    "        self.dense2 = Dense_Block(nf,2)\n",
    "\n",
    "        self.outc = outconv(nf, n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up1(x4, x3)\n",
    "        x21,x22 = self.dense2(x2,x3)\n",
    "        x = self.up2(x, x22)\n",
    "        x13 = self.dense1(x1,x2,x21)\n",
    "        x = self.up3(x, x13)\n",
    "\n",
    "        x = self.outc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks,trade_off, dpix, z, Hsize, _lambda, k, method, nc=3, nd=5, **kwargs):\n",
    "        super(PINN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.nd = nd\n",
    "        self.method = method\n",
    "        self.trade_off = trade_off\n",
    "        conv_dim = 2\n",
    "        dilation = 1\n",
    "        n_ch = n_channels\n",
    "        n_out = n_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print('Creating D{}C{}'.format(nd, nc))\n",
    "        conv_blocks = []\n",
    "        dcs = []\n",
    "        gamma = []\n",
    "        \n",
    "        pad_conv = 1\n",
    "        if dilation > 1:\n",
    "        # in = floor(in + 2*pad - dilation * (ks-1) - 1)/stride + 1)\n",
    "        # pad = dilation\n",
    "            pad_dilconv = dilation\n",
    "        else:\n",
    "            pad_dilconv = pad_conv\n",
    "        \n",
    "        for i in range(nc):\n",
    "            conv_blocks.append(Seven_Unetplusplus(n_ch, n_out, nf, ks, **kwargs))\n",
    "            gamma.append(torch.tensor(self.trade_off,device = self.device,requires_grad=True))\n",
    "            with torch.no_grad():\n",
    "                dcs.append(Data_consistency(dpix, z, Hsize, _lambda, k, **kwargs))\n",
    "\n",
    "        self.conv_blocks = nn.ModuleList(conv_blocks)\n",
    "        self.dcs = dcs\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, im):\n",
    "        \n",
    "        raw = im['input']\n",
    "        x = im['input']\n",
    "        x_i0 = im['inverse_input']\n",
    "        x_id = im['fres_input']\n",
    "\n",
    "        for i in range(self.nc):\n",
    "            x_phase = self.dcs[0].perform(x,x_i0,x_id)\n",
    "\n",
    "            if i == 0:\n",
    "                x = raw - self.conv_blocks[i](raw)\n",
    "            else:\n",
    "                x = x - self.conv_blocks[i](x)\n",
    "\n",
    "            if self.method == 'constant':\n",
    "                x = x - x_phase*self.trade_off\n",
    "            elif self.method == 'learn':\n",
    "                x = x - x_phase*self.gamma[i]\n",
    "                \n",
    "        return x \n",
    "\n",
    "    \n",
    "class PINNShared(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks,trade_off, dpix, z, Hsize, _lambda, k, nc=3, nd=5, **kwargs):\n",
    "        super(PINNShared, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.nd = nd\n",
    "        self.trade_off = trade_off\n",
    "        print('Creating D{}C{}-S (2D)'.format(nd, nc))\n",
    "        conv_blocks = []\n",
    "        dc = []\n",
    "        gamma = []\n",
    "\n",
    "        conv_blocks.append(Seven_Unetplusplus(n_channels, n_classes, nf, ks, **kwargs))\n",
    "        gamma.append(torch.tensor(self.trade_off,device = self.device,requires_grad=True))\n",
    "        self.conv_blocks = nn.ModuleList(conv_blocks)\n",
    "        with torch.no_grad():\n",
    "            self.dcs = Data_consistency(dpix, z, Hsize, _lambda, k, **kwargs)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, im):\n",
    "\n",
    "        raw = im['input']\n",
    "        x = im['input']\n",
    "        x_i0 = im['inverse_input']\n",
    "        x_id = im['fres_input']\n",
    "\n",
    "        for i in range(self.nc):\n",
    "            x_phase = self.dcs[0].perform(x,x_i0,x_id)\n",
    "            x = x - self.conv_blocks[0](x)\n",
    "            if self.method == 'constant':\n",
    "                x = x - x_phase*self.trade_off\n",
    "            elif self.method == 'learn':\n",
    "                x = x - x_phase*self.gamma[0]\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    parser = argparse.ArgumentParser(description='parameters of PINN')\n",
    "    parser.add_argument('--NUM_EPOCH', default = 200, type=int,nargs='*', help='number of epochs')\n",
    "    parser.add_argument('--START_EPOCH', default = 0, type=int, nargs='*', help='start epoch')\n",
    "    parser.add_argument('--DECAY_EPOCH', default = 5, type=int, nargs='*', help='decay epoch')\n",
    "    parser.add_argument('--CRITIC_ITER', default = 1, type=int, nargs='*', help='critic iteration')\n",
    "    parser.add_argument('--SAVE_EPOCH', default = 10, type=int, nargs='*', help='save iteration')\n",
    "    parser.add_argument('--BATCH_SIZE', default = 1, type=int, nargs=1, help='batch size')\n",
    "    parser.add_argument('--lr', default = 5e-4, type=float, nargs=1, help='initial learning rate')\n",
    "    parser.add_argument('--beta1', default = 0.9, type=float, nargs=1, help='first-moment exponential decay rate')\n",
    "    parser.add_argument('--beta2', default = 0.999, type=float, nargs=1, help='second-moment exponential decay rate')\n",
    "    parser.add_argument('--input_nc', default = 1, type=int, nargs=1, help='input channel')\n",
    "    parser.add_argument('--output_nc', default = 1, type=int, nargs=1, help='output channel')\n",
    "    parser.add_argument('--nf', default = 32, type=int, nargs=1, help='number of filters')\n",
    "    parser.add_argument('--ks', default = 3, type=int, nargs=1, help='kernel size')\n",
    "    parser.add_argument('--tradeoff', default = 1e-2, nargs=1, type=float, help='trade-off value')\n",
    "    parser.add_argument('--itr_method', default = 'learn', nargs=1, type=str, help='constant or learning trade-off value')\n",
    "    parser.add_argument('--dpix', default = 0.22e-6, type=float, nargs=1, help='pixel size')\n",
    "    parser.add_argument('--d', default = 2e-6, type=float, nargs=1, help='propagation distance')\n",
    "    parser.add_argument('--Hsize', default = 512, type=int, nargs=1, help='image size')\n",
    "    parser.add_argument('--wl', default = 660e-9, type=float, nargs=1, help='wave length')\n",
    "    parser.add_argument('--k', default = 9.51e6, nargs=1, type=int, help='k value')\n",
    "    parser.add_argument('--loss_function', default = 'mix', type=str, help='training loss function')\n",
    "    parser.add_argument('--alpha', default = 5, type=float, nargs=1, help='trade-off value of mix loss function')\n",
    "    parser.add_argument('--model_name', default = 'pinn', type=str, help='project model')\n",
    "    parser.add_argument('--pretrain', default = False, type=bool, help='model pretrain')\n",
    "    parser.add_argument('--debug', action='store_true', help='debug mode')\n",
    "    parser.add_argument('--savefig', action='store_true',\n",
    "                        help='Save output images and masks')\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "    save_frq = 10\n",
    "    \n",
    "    #specify work\n",
    "    if args.model_name == 'pinn':\n",
    "        pinn = PINN(n_channels = args.input_nc, n_classes = args.output_nc, nf = args.nf, ks = args.ks, trade_off = args.tradeoff,\n",
    "                        dpix = args.dpix, z = args.d, Hsize = args.Hsize, _lambda = args.wl, k = args.k, method = args.itr_method) \n",
    "    elif args.model_name == 'unet':\n",
    "        pinn = Unet(n_channels = args.input_nc, n_classes = args.output_nc, nf = args.nf, ks = args.ks)\n",
    "    else:\n",
    "        pinn= DenseUNet(n_classes = args.output_nc)\n",
    "   \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Use {} GPUs\".format(torch.cuda.device_count()), \"=\" * 9)\n",
    "        pinn = nn.DataParallel(pinn)\n",
    "        if args.pretrain is True:\n",
    "            init_weights(pinn, 'normal', init_gain=0.02)\n",
    "    \n",
    "    pinn.to(device)\n",
    "    # loss\n",
    "    criterion_GAN = nn.MSELoss() #L2 loss\n",
    "    criterion_Sensitive = nn.L1Loss() #L1 loss\n",
    "    criterion_ssim = SSIM(window_size = 11) #SSIM loss\n",
    "    \n",
    "    # mix loss function recommended\n",
    "    if cuda:\n",
    "        pinn = pinn.cuda()\n",
    "        if args.loss_function == 'l2':\n",
    "            criterion_loss = criterion_GAN.cuda()\n",
    "        elif args.loss_function == 'l1':\n",
    "            criterion_loss = criterion_Sensitive.cuda()\n",
    "        elif args.loss_function == 'ssim':\n",
    "            criterion_loss = criterion_ssim.cuda()\n",
    "        elif args.loss_function == 'mix':\n",
    "            criterion_ssim = criterion_ssim.cuda() \n",
    "            criterion_mse = criterion_GAN.cuda()   \n",
    "\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(pinn.parameters(), lr=args.lr, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    # learning rate schedulers\n",
    "    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=LambdaLR_(args.NUM_EPOCH, args.START_EPOCH, args.DECAY_EPOCH).step)\n",
    "\n",
    "   # input & target data & intensity images\n",
    "    train_dataset = build_phasedata(dataset = 'train', norm_range=(0, 1))\n",
    "    train_loader = train_phase_data_loader(dataset = train_dataset, crop_size=None, crop_n=None)\n",
    "    train_data = train_loader.__getitem__()\n",
    "    (train_im, train_gt, train_id, train_i0) = train_data\n",
    "    (m, m_chan, m_r, m_c) = train_im.shape\n",
    "\n",
    "    valid_dataset = build_phasedata(dataset = 'valid', norm_range=(0, 1))\n",
    "    valid_loader = train_phase_data_loader(dataset = valid_dataset, crop_size=None, crop_n=None)\n",
    "    valid_data = valid_loader.__getitem__()\n",
    "    (valid_im, valid_gt, valid_id, valid_i0) = valid_data\n",
    "    (m_valid, n_chan, n_r, n_c) = valid_im.shape\n",
    "\n",
    "    test_dataset = build_phasedata(dataset = 'test', norm_range=(0, 1))\n",
    "    test_loader = train_phase_data_loader(dataset = test_dataset, crop_size=None, crop_n=None)                                    \n",
    "    test_data = test_loader.__getitem__()\n",
    "    \n",
    "#     Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "    Tensor = torch.cuda.FloatTensor #GPU only\n",
    "    \n",
    "    Loss_list = [] #visualize result\n",
    "    valid_list = []\n",
    "    #Store models and the results in test-set\n",
    "    project_root = '' \n",
    "    save_dir = os.path.join(project_root, '\\\\%s' % args.model_name)\n",
    "    os.chdir(save_dir)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for epoch in range(args.START_EPOCH, args.NUM_EPOCH):\n",
    "        start_time = time.time()\n",
    "        count = 0\n",
    "        total_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        torch.cuda.empty_cache() #crear the GPU storage\n",
    "        train_mini_batches, valid_mini_batches, test_mini_batches = random_mini_batches(train_data, valid_data, test_data, mini_batch_size=args.BATCH_SIZE, shuffle = True)\n",
    "\n",
    "        #Training process\n",
    "        for minibatch in train_mini_batches:\n",
    "            count += 1\n",
    "        \n",
    "            im = prep_input(minibatch, mode='train')\n",
    "            target_img = im['targets']\n",
    "\n",
    "            ######## Train PINN ########\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            if count % args.CRITIC_ITER == 0:\n",
    "                \n",
    "                fake_img = pinn(im)\n",
    "                if args.loss_function == 'ssim':\n",
    "                    loss_G = -criterion_loss(fake_img,target_img)\n",
    "                elif args.loss_function == 'mix':\n",
    "                    loss_G = (1-criterion_ssim(fake_img,target_img)) * args.alpha + criterion_mse(fake_img,target_img)\n",
    "                else:\n",
    "                    loss_G = criterion_loss(fake_img,target_img)\n",
    "                total_loss += float(loss_G)\n",
    "                loss_G.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if count % 10 == 0:\n",
    "                print(\"EPOCH [{}/{}], STEP [{}/{}]\".format(epoch+1, args.NUM_EPOCH, count+1, m))\n",
    "                print(\"Total Loss G: {}\".format(loss_G))\n",
    "        end_time = time.time()\n",
    "        print(\"Training time is \",(end_time-start_time)/60,'mins')\n",
    "        Loss_list.append(total_loss / m)\n",
    "        \n",
    "    #Validation process\n",
    "        count = 0\n",
    "        for minibatch in valid_mini_batches:\n",
    "            count += 1\n",
    "            im = prep_input(minibatch, mode='valid')\n",
    "            target_img = im['targets']\n",
    "        \n",
    "            if count % args.CRITIC_ITER == 0:\n",
    "                \n",
    "                fake_img = pinn(im)\n",
    "                if args.loss_function == 'mix':\n",
    "                    loss_V = (1-criterion_ssim(fake_img,target_img)) * args.alpha + criterion_mse(fake_img,target_img)\n",
    "                else:\n",
    "                    loss_V = criterion_loss(fake_img,target_img)\n",
    "                valid_loss += float(loss_V)\n",
    "                \n",
    "            if count % 10 == 0:\n",
    "                print(\"Valid: 2-shot EPOCH [{}/{}], STEP [{}/{}]\".format(epoch+1, args.NUM_EPOCH, count, m_valid))\n",
    "                print(\"Total Loss V: {}\".format(loss_V))\n",
    "        valid_list.append(valid_loss / m_valid)\n",
    "    \n",
    "\n",
    "        #Test process save test figure in every 10 epochs\n",
    "        total_loss_t = 0.\n",
    "        test_count = 0\n",
    "        if (epoch+1) > (args.NUM_EPOCH/2) and (epoch+1) % args.SAVE_EPOCH == 0:\n",
    "            for mini_batch in test_mini_batches:\n",
    "                test_count += 1\n",
    "                im = prep_input(mini_batch, mode='test')\n",
    "                input_img = im['input']\n",
    "                target_img = im['targets']\n",
    "\n",
    "                fake_img = pinn(im)\n",
    "\n",
    "                if test_count % 1 == 0:\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "\n",
    "                        #pytorch tensor\n",
    "                        input_pic = input_img.cpu().numpy()\n",
    "                        fake_pic = fake_img.cpu().numpy()\n",
    "                        target_pic = target_img.cpu().numpy()\n",
    "\n",
    "                        #numpy array\n",
    "                        scio.savemat(\"InputIn\"+str(test_count)+\".mat\", {'array':input_pic})\n",
    "                        scio.savemat(str(epoch+1)+\"_\"+str(test_count)+\".mat\", {'array':fake_pic})\n",
    "                        scio.savemat(\"GT\"+str(test_count)+\".mat\", {'array':target_pic})\n",
    "    \n",
    "    #save models\n",
    "    torch.save(pinn.state_dict(),os.path.join(save_dir,'net.pth'))\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch_WXF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fabc88d99945535ba9ceb4ce867800f20bfe6c6f54ef3203be94f92b308bfbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
