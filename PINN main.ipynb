{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as scio\n",
    "import argparse\n",
    "from prettytable import PrettyTable\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from ssim_loss import SSIM\n",
    "from Unet_block import *\n",
    "from TIE_model import *\n",
    "from split_dataset import *\n",
    "from initialization import *\n",
    "from torchvision.models import DenseNet\n",
    "from torchvision.models.densenet import _Transition, _load_state_dict\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" #select num.0 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NORMalize(image, MIN_B, MAX_B):\n",
    "    image = (image - MIN_B) / (MAX_B - MIN_B)\n",
    "   #image[image>1] = 1.\n",
    "   #image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "def DENORMalize(image, MIN_B, MAX_B):\n",
    "    image = image * (MAX_B - MIN_B) + MIN_B\n",
    "    return image\n",
    "\n",
    "    \n",
    "def build_phasedata(dataset, norm_range = (0.0, 1.0)):\n",
    "    \n",
    "    nt_red = 6\n",
    "    data = scio.loadmat('')['im']\n",
    "    nx, ny, nt = data.shape\n",
    "    s1 = nt//nt_red\n",
    "    train_s = s1*4\n",
    "    small_sample = s1*4+2\n",
    "    reshape_order = 'C'\n",
    "    \n",
    "    data_path_train_in = '' #file direction\n",
    "    data_path_train_out = ''\n",
    "    data_path_intensity = ''\n",
    "    \n",
    "    mat_im = scio.loadmat(data_path_train_in + '\\\\im')['im']\n",
    "    mat_gt = scio.loadmat(data_path_train_out + '\\\\label')['gt']\n",
    "    mat_id = scio.loadmat(data_path_intensity + '\\\\in')['in']\n",
    "    mat_i0 = scio.loadmat(data_path_intensity + '\\\\i0')['i0']\n",
    "\n",
    "    mat_im = np.reshape(np.transpose(mat_im,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    mat_gt = np.reshape(np.transpose(mat_gt,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    mat_id = np.reshape(np.transpose(mat_id,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    mat_i0 = np.reshape(np.transpose(mat_i0,(2,0,1)), (nt,1,nx,ny), order=reshape_order)\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        \n",
    "        im = mat_im[:small_sample,...]\n",
    "        gt = mat_gt[:small_sample,...]\n",
    "        I_d = mat_id[:small_sample,...]\n",
    "        I_0= mat_i0[:small_sample,...]\n",
    "        dataset = (im, gt, I_d, I_0)\n",
    "            \n",
    "    if dataset == 'valid':\n",
    "        \n",
    "        im = mat_im[small_sample:small_sample+s1,...]\n",
    "        gt = mat_gt[small_sample:small_sample+s1,...]\n",
    "        I_d = mat_id[small_sample:small_sample+s1,...]\n",
    "        I_0 = mat_i0[small_sample:small_sample+s1,...]\n",
    "        dataset = (im, gt, I_d, I_0)\n",
    "        \n",
    "    if dataset == 'test':\n",
    "        \n",
    "        im = mat_im[s1*5+2:,...]\n",
    "        gt = mat_gt[s1*5+2:,...]\n",
    "        I_d = mat_id[s1*5+2:,...]\n",
    "        I_0 = mat_i0[s1*5+2:,...]\n",
    "        dataset = (im, gt, I_d, I_0)\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "class train_phase_data_loader(Dataset):\n",
    "    def __init__(self, dataset, crop_size=None, crop_n=None):\n",
    "        self.dataset = dataset\n",
    "        self.crop_size = crop_size\n",
    "        self.crop_n = crop_n\n",
    "\n",
    "    def __getitem__(self):\n",
    "        (im, gt, I_d, I_0) = self.dataset\n",
    "        input_img = im\n",
    "        target_img = gt\n",
    "        inten_id = I_d\n",
    "        inten_i0 = I_0\n",
    "\n",
    "        if self.crop_n:\n",
    "            assert input_img.shape == target_img.shape\n",
    "            crop_input = []\n",
    "            crop_target = []\n",
    "            n_c, h, w = input_img.shape\n",
    "            new_h, new_w = self.crop_size, self.crop_size\n",
    "            for _ in range(self.crop_n):\n",
    "                top = np.random.randint(0, h - new_h)\n",
    "                left = np.random.randint(0, w - new_w)\n",
    "                input_img_ = input_img[top:top + new_h, left:left + new_w]\n",
    "                target_img_ = target_img[top:top + new_h, left:left + new_w]\n",
    "                crop_input.append(input_img_)\n",
    "                crop_target.append(target_img_)\n",
    "            crop_input = np.array(crop_input)\n",
    "            crop_target = np.array(crop_target)\n",
    "\n",
    "            sample = (crop_input, crop_target)\n",
    "            return sample\n",
    "        else:\n",
    "            sample = (input_img, target_img, inten_id, inten_i0)\n",
    "            return sample\n",
    "        \n",
    "\n",
    "class LambdaLR_():  #learning_rate schedulers\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)\n",
    "\n",
    "def prep_input(im, mode):\n",
    "    \"\"\"Undersample the batch, then reformat them into what the network accepts.\n",
    "    Parameters: patch the data\n",
    "    \"\"\"\n",
    "    #input variable\n",
    "    (phase_var, target_var, id_var, i0_var) = im\n",
    "    if mode == 'train':\n",
    "        phase_var = torch.tensor(phase_var, requires_grad=True).to(device)\n",
    "    else:\n",
    "        phase_var = torch.tensor(phase_var).to(device)\n",
    "    target_var = torch.tensor(target_var).to(device)\n",
    "    id_var = torch.tensor(id_var).to(device)\n",
    "    i0_var = torch.tensor(i0_var).to(device)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        phase_var = phase_var.type(torch.cuda.FloatTensor)\n",
    "        target_var = target_var.type(torch.cuda.FloatTensor)\n",
    "        id_var = id_var.type(torch.cuda.FloatTensor)\n",
    "        i0_var = i0_var.type(torch.cuda.FloatTensor)\n",
    "    \n",
    "    data = DeepChainMap({'input': phase_var}, {'targets': target_var}, {'fres_input': id_var}, {'inverse_input': i0_var})\n",
    "\n",
    "    return data\n",
    "    \n",
    "\n",
    "def calc_gradeint_penalty(discriminator, real_data, fake_data):\n",
    "    #alpha = torch.rand(real_data.size()[0], 1)\n",
    "    #alpha = alpha.expand(real_data.size())\n",
    "    alpha = torch.Tensor(np.random.random((real_data.size(0),1,1,1)))\n",
    "    alpha = alpha.cuda() if torch.cuda.is_available() else alpha\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        interpolates = interpolates.cuda()\n",
    "    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = discriminator(interpolates)\n",
    "\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones(disc_interpolates.size()).cuda() if torch.cuda.is_available() else torch.ones(disc_interpolates.size()), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "class no_op(object):\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        pass\n",
    "\n",
    "def maybe_to_torch(d):\n",
    "    if isinstance(d, list):\n",
    "        d = [maybe_to_torch(i) if not isinstance(i, torch.Tensor) else i for i in d]\n",
    "    elif not isinstance(d, torch.Tensor):\n",
    "        d = torch.from_numpy(d).float()\n",
    "    return d\n",
    "\n",
    "\n",
    "def to_cuda(data, non_blocking=True, gpu_id=0):\n",
    "    if isinstance(data, list):\n",
    "        data = [i.cuda(gpu_id, non_blocking=non_blocking) for i in data]\n",
    "    else:\n",
    "        data = data.cuda(gpu_id, non_blocking=True)\n",
    "    return data\n",
    "\n",
    "softmax_helper = lambda x: F.softmax(x, 1)\n",
    "\n",
    "def count_parameters(model):\n",
    "    # table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseUNetEncoder(DenseNet):\n",
    "    def __init__(self, skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, downsample):\n",
    "        super(_DenseUNetEncoder, self).__init__(growth_rate, block_config, num_init_features, bn_size, drop_rate)\n",
    "        \n",
    "        self.skip_connections = skip_connections\n",
    "\n",
    "        # remove last norm, classifier\n",
    "        features = OrderedDict(list(self.features.named_children())[:-1])\n",
    "        delattr(self, 'classifier')\n",
    "        if not downsample:\n",
    "            features['conv0'].stride = 1\n",
    "            del features['pool0']\n",
    "        self.features = nn.Sequential(features)\n",
    "        \n",
    "        for module in self.features.modules():\n",
    "            if isinstance(module, nn.AvgPool2d):\n",
    "                module.register_forward_hook(lambda _, input, output : self.skip_connections.append(input[0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "        \n",
    "class _DenseUNetDecoder(DenseNet):\n",
    "    def __init__(self, skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, upsample):\n",
    "        super(_DenseUNetDecoder, self).__init__(growth_rate, block_config, num_init_features, bn_size, drop_rate)\n",
    "        \n",
    "        self.skip_connections = skip_connections\n",
    "        self.upsample = upsample\n",
    "        \n",
    "        # remove conv0, norm0, relu0, pool0, last denseblock, last norm, classifier\n",
    "        features = list(self.features.named_children())[4:-2]\n",
    "        delattr(self, 'classifier')\n",
    "\n",
    "        num_features = num_init_features\n",
    "        num_features_list = []\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            num_input_features = num_features + num_layers * growth_rate\n",
    "            num_output_features = num_features // 2\n",
    "            num_features_list.append((num_input_features, num_output_features))\n",
    "            num_features = num_input_features // 2\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            name, module = features[i]\n",
    "            if isinstance(module, _Transition):\n",
    "                num_input_features, num_output_features = num_features_list.pop(1)\n",
    "                features[i] = (name, _TransitionUp(num_input_features, num_output_features, skip_connections))\n",
    "\n",
    "        features.reverse()\n",
    "        \n",
    "        self.features = nn.Sequential(OrderedDict(features))\n",
    "        \n",
    "        num_input_features, _ = num_features_list.pop(0)\n",
    "        \n",
    "        if upsample:\n",
    "            self.features.add_module('upsample0', nn.Upsample(scale_factor=4, mode='bilinear'))\n",
    "        self.features.add_module('norm0', nn.BatchNorm2d(num_input_features))\n",
    "        self.features.add_module('relu0', nn.ReLU(inplace=True))\n",
    "        self.features.add_module('conv0', nn.Conv2d(num_input_features, num_init_features, kernel_size=1, stride=1, bias=False))\n",
    "        self.features.add_module('norm1', nn.BatchNorm2d(num_init_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "          \n",
    "        \n",
    "class _Concatenate(nn.Module):\n",
    "    def __init__(self, skip_connections):\n",
    "        super(_Concatenate, self).__init__()\n",
    "        self.skip_connections = skip_connections\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([x, self.skip_connections.pop()], 1)\n",
    "\n",
    "          \n",
    "class _TransitionUp(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features, skip_connections):\n",
    "        super(_TransitionUp, self).__init__()\n",
    "        \n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, num_output_features * 2,\n",
    "                                              kernel_size=1, stride=1, bias=False))\n",
    "        \n",
    "        self.add_module('upsample', nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        self.add_module('cat', _Concatenate(skip_connections))\n",
    "        self.add_module('norm2', nn.BatchNorm2d(num_output_features * 4))\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv2', nn.Conv2d(num_output_features * 4, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "\n",
    "class DenseUNet(nn.Module):\n",
    "    def __init__(self, n_classes, growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64, bn_size=4, drop_rate=0, downsample=False, pretrained_encoder_uri=None, progress=None):\n",
    "        super(DenseUNet, self).__init__()\n",
    "        self.skip_connections = []\n",
    "        self.encoder = _DenseUNetEncoder(self.skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, downsample)\n",
    "        self.decoder = _DenseUNetDecoder(self.skip_connections, growth_rate, block_config, num_init_features, bn_size, drop_rate, downsample)\n",
    "        self.classifier = nn.Conv2d(num_init_features, n_classes, kernel_size=1, stride=1, bias=True)\n",
    "        \n",
    "        self.encoder._load_state_dict = self.encoder.load_state_dict\n",
    "        self.encoder.load_state_dict = lambda state_dict : self.encoder._load_state_dict(state_dict, strict=False)\n",
    "        if pretrained_encoder_uri:\n",
    "            _load_state_dict(self.encoder, str(pretrained_encoder_uri), progress)\n",
    "        self.encoder.load_state_dict = lambda state_dict : self.encoder._load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        y = self.classifier(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks, drop_rate=0.5):\n",
    "        super(Unet, self).__init__()\n",
    "        self.inc = inconv(n_channels, nf, ks)\n",
    "        self.down1 = down(nf, nf*2, ks)\n",
    "        self.down2 = down(nf*2, nf*4, ks)\n",
    "        self.down3 = down(nf*4, nf*8, ks)\n",
    "        self.down4 = down(nf*8, nf*16, ks)\n",
    "        self.up1 = up(nf*24, nf*8, ks)\n",
    "        self.up2 = up(nf*12, nf*4, ks)\n",
    "        self.up3 = up(nf*6, nf*2, ks, drop_rate)\n",
    "        self.up4 = up(nf*3, nf, ks, drop_rate)\n",
    "        self.outc = outconv(nf, n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, im):\n",
    "        raw = im['input']\n",
    "\n",
    "        x1 = self.inc(raw)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "\n",
    "        x = self.outc(x)\n",
    "\n",
    "        x = raw - x\n",
    "\n",
    "        return x\n",
    "\n",
    "class Seven_Unetplusplus(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks, drop_rate=0.5):\n",
    "        super(Seven_Unetplusplus, self).__init__()\n",
    "        self.inc = inconv(n_channels, nf, ks)\n",
    "        self.down1 = down(nf, nf*2, ks)\n",
    "        self.down2 = down(nf*2, nf*4, ks)\n",
    "        self.down3 = down(nf*4, nf*8, ks)\n",
    "        self.up1 = up(nf*12, nf*4, ks)\n",
    "        self.up2 = up(nf*6, nf*2, ks, drop_rate)\n",
    "        self.up3 = up(nf*3, nf, ks, drop_rate)\n",
    "        \n",
    "        self.dense1 = Dense_Block(nf,3)\n",
    "        self.dense2 = Dense_Block(nf,2)\n",
    "\n",
    "        self.outc = outconv(nf, n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x = self.up1(x4, x3)\n",
    "        x21,x22 = self.dense2(x2,x3)\n",
    "        x = self.up2(x, x22)\n",
    "        x13 = self.dense1(x1,x2,x21)\n",
    "        x = self.up3(x, x13)\n",
    "\n",
    "        x = self.outc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks,trade_off, dpix, z, Hsize, _lambda, k, method, nc=3, nd=5, **kwargs):\n",
    "        super(PINN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.nd = nd\n",
    "        self.method = method\n",
    "        self.trade_off = trade_off\n",
    "        conv_dim = 2\n",
    "        dilation = 1\n",
    "        n_ch = n_channels\n",
    "        n_out = n_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print('Creating D{}C{}'.format(nd, nc))\n",
    "        conv_blocks = []\n",
    "        dcs = []\n",
    "        gamma = []\n",
    "        \n",
    "        pad_conv = 1\n",
    "        if dilation > 1:\n",
    "        # in = floor(in + 2*pad - dilation * (ks-1) - 1)/stride + 1)\n",
    "        # pad = dilation\n",
    "            pad_dilconv = dilation\n",
    "        else:\n",
    "            pad_dilconv = pad_conv\n",
    "        \n",
    "        for i in range(nc):\n",
    "            conv_blocks.append(Seven_Unetplusplus(n_ch, n_out, nf, ks, **kwargs))\n",
    "            gamma.append(torch.tensor(self.trade_off,device = self.device,requires_grad=True))\n",
    "            with torch.no_grad():\n",
    "                dcs.append(Data_consistency(dpix, z, Hsize, _lambda, k, **kwargs))\n",
    "\n",
    "        self.conv_blocks = nn.ModuleList(conv_blocks)\n",
    "        self.dcs = dcs\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, im):\n",
    "        \n",
    "        raw = im['input']\n",
    "        x = im['input']\n",
    "        x_i0 = im['inverse_input']\n",
    "        x_id = im['fres_input']\n",
    "\n",
    "        for i in range(self.nc):\n",
    "            x_phase = self.dcs[0].perform(x,x_i0,x_id)\n",
    "\n",
    "            if i == 0:\n",
    "                x = raw - self.conv_blocks[i](raw)\n",
    "            else:\n",
    "                x = x - self.conv_blocks[i](x)\n",
    "\n",
    "            if self.method == 'constant':\n",
    "                x = x - x_phase*self.trade_off\n",
    "            elif self.method == 'learn':\n",
    "                x = x - x_phase*self.gamma[i]\n",
    "                \n",
    "        return x \n",
    "\n",
    "    \n",
    "class PINNShared(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nf, ks,trade_off, dpix, z, Hsize, _lambda, k, nc=3, nd=5, **kwargs):\n",
    "        super(PINNShared, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.nd = nd\n",
    "        self.trade_off = trade_off\n",
    "        print('Creating D{}C{}-S (2D)'.format(nd, nc))\n",
    "        conv_blocks = []\n",
    "        dc = []\n",
    "        gamma = []\n",
    "\n",
    "        conv_blocks.append(Seven_Unetplusplus(n_channels, n_classes, nf, ks, **kwargs))\n",
    "        gamma.append(torch.tensor(self.trade_off,device = self.device,requires_grad=True))\n",
    "        self.conv_blocks = nn.ModuleList(conv_blocks)\n",
    "        with torch.no_grad():\n",
    "            self.dcs = Data_consistency(dpix, z, Hsize, _lambda, k, **kwargs)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, im):\n",
    "\n",
    "        raw = im['input']\n",
    "        x = im['input']\n",
    "        x_i0 = im['inverse_input']\n",
    "        x_id = im['fres_input']\n",
    "\n",
    "        for i in range(self.nc):\n",
    "            x_phase = self.dcs[0].perform(x,x_i0,x_id)\n",
    "            x = x - self.conv_blocks[0](x)\n",
    "            if self.method == 'constant':\n",
    "                x = x - x_phase*self.trade_off\n",
    "            elif self.method == 'learn':\n",
    "                x = x - x_phase*self.gamma[0]\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating D5C3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David Wu\\Python program\\PINN\\TIE_model.py:371: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pi,lamda,z,dpix,Hsize = [torch.tensor(i,device=self.device) for i in [np.pi,self._lambda,z,self.dpix,self.Hsize]]\n",
      "c:\\Users\\David Wu\\Python program\\PINN\\TIE_model.py:606: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.z = torch.tensor(self.z,device = self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [1/200], STEP [11/134]\n",
      "Total Loss G: 1.791059136390686\n",
      "EPOCH [1/200], STEP [21/134]\n",
      "Total Loss G: 3.2435414791107178\n",
      "EPOCH [1/200], STEP [31/134]\n",
      "Total Loss G: 0.6815721988677979\n",
      "EPOCH [1/200], STEP [41/134]\n",
      "Total Loss G: 2.3443777561187744\n",
      "EPOCH [1/200], STEP [51/134]\n",
      "Total Loss G: 1.8194869756698608\n",
      "EPOCH [1/200], STEP [61/134]\n",
      "Total Loss G: 1.6262032985687256\n",
      "EPOCH [1/200], STEP [71/134]\n",
      "Total Loss G: 1.1527962684631348\n",
      "EPOCH [1/200], STEP [81/134]\n",
      "Total Loss G: 2.3574440479278564\n",
      "EPOCH [1/200], STEP [91/134]\n",
      "Total Loss G: 1.4220061302185059\n",
      "EPOCH [1/200], STEP [101/134]\n",
      "Total Loss G: 1.6221528053283691\n",
      "EPOCH [1/200], STEP [111/134]\n",
      "Total Loss G: 1.4837125539779663\n",
      "EPOCH [1/200], STEP [121/134]\n",
      "Total Loss G: 1.5281918048858643\n",
      "EPOCH [1/200], STEP [131/134]\n",
      "Total Loss G: 2.2293293476104736\n",
      "EPOCH [1/200], STEP [141/134]\n",
      "Total Loss G: 2.4842910766601562\n",
      "Training time is  1.1524493098258972 mins\n",
      "Valid: 2-shot EPOCH [1/200], STEP [10/33]\n",
      "Total Loss V: 1.6021842956542969\n",
      "Valid: 2-shot EPOCH [1/200], STEP [20/33]\n",
      "Total Loss V: 1.5799551010131836\n",
      "Valid: 2-shot EPOCH [1/200], STEP [30/33]\n",
      "Total Loss V: 1.3446006774902344\n",
      "EPOCH [2/200], STEP [11/134]\n",
      "Total Loss G: 0.7032867670059204\n",
      "EPOCH [2/200], STEP [21/134]\n",
      "Total Loss G: 1.484735369682312\n",
      "EPOCH [2/200], STEP [31/134]\n",
      "Total Loss G: 0.7564017176628113\n",
      "EPOCH [2/200], STEP [41/134]\n",
      "Total Loss G: 2.120626211166382\n",
      "EPOCH [2/200], STEP [51/134]\n",
      "Total Loss G: 1.453497290611267\n",
      "EPOCH [2/200], STEP [61/134]\n",
      "Total Loss G: 0.6845649480819702\n",
      "EPOCH [2/200], STEP [71/134]\n",
      "Total Loss G: 0.6781060099601746\n",
      "EPOCH [2/200], STEP [81/134]\n",
      "Total Loss G: 1.513388752937317\n",
      "EPOCH [2/200], STEP [91/134]\n",
      "Total Loss G: 0.6843969821929932\n",
      "EPOCH [2/200], STEP [101/134]\n",
      "Total Loss G: 0.7694298624992371\n",
      "EPOCH [2/200], STEP [111/134]\n",
      "Total Loss G: 0.527320146560669\n",
      "EPOCH [2/200], STEP [121/134]\n",
      "Total Loss G: 1.0514634847640991\n",
      "EPOCH [2/200], STEP [131/134]\n",
      "Total Loss G: 0.6847977638244629\n",
      "EPOCH [2/200], STEP [141/134]\n",
      "Total Loss G: 0.9964482188224792\n",
      "Training time is  1.1171305656433106 mins\n",
      "Valid: 2-shot EPOCH [2/200], STEP [10/33]\n",
      "Total Loss V: 1.7360341548919678\n",
      "Valid: 2-shot EPOCH [2/200], STEP [20/33]\n",
      "Total Loss V: 2.068873405456543\n",
      "Valid: 2-shot EPOCH [2/200], STEP [30/33]\n",
      "Total Loss V: 0.45467609167099\n",
      "EPOCH [3/200], STEP [11/134]\n",
      "Total Loss G: 0.8801352381706238\n",
      "EPOCH [3/200], STEP [21/134]\n",
      "Total Loss G: 1.7549996376037598\n",
      "EPOCH [3/200], STEP [31/134]\n",
      "Total Loss G: 0.75581955909729\n",
      "EPOCH [3/200], STEP [41/134]\n",
      "Total Loss G: 1.442080020904541\n",
      "EPOCH [3/200], STEP [51/134]\n",
      "Total Loss G: 1.5545927286148071\n",
      "EPOCH [3/200], STEP [61/134]\n",
      "Total Loss G: 0.5547285676002502\n",
      "EPOCH [3/200], STEP [71/134]\n",
      "Total Loss G: 0.48038575053215027\n",
      "EPOCH [3/200], STEP [81/134]\n",
      "Total Loss G: 1.2733180522918701\n",
      "EPOCH [3/200], STEP [91/134]\n",
      "Total Loss G: 0.67872154712677\n",
      "EPOCH [3/200], STEP [101/134]\n",
      "Total Loss G: 0.7679272890090942\n",
      "EPOCH [3/200], STEP [111/134]\n",
      "Total Loss G: 0.40111449360847473\n",
      "EPOCH [3/200], STEP [121/134]\n",
      "Total Loss G: 0.9815632700920105\n",
      "EPOCH [3/200], STEP [131/134]\n",
      "Total Loss G: 0.6376001834869385\n",
      "EPOCH [3/200], STEP [141/134]\n",
      "Total Loss G: 0.9443410634994507\n",
      "Training time is  1.116141680876414 mins\n",
      "Valid: 2-shot EPOCH [3/200], STEP [10/33]\n",
      "Total Loss V: 1.9663912057876587\n",
      "Valid: 2-shot EPOCH [3/200], STEP [20/33]\n",
      "Total Loss V: 1.7439337968826294\n",
      "Valid: 2-shot EPOCH [3/200], STEP [30/33]\n",
      "Total Loss V: 0.4428462088108063\n",
      "EPOCH [4/200], STEP [11/134]\n",
      "Total Loss G: 0.4057016968727112\n",
      "EPOCH [4/200], STEP [21/134]\n",
      "Total Loss G: 1.1835076808929443\n",
      "EPOCH [4/200], STEP [31/134]\n",
      "Total Loss G: 0.8336489796638489\n",
      "EPOCH [4/200], STEP [41/134]\n",
      "Total Loss G: 1.4419409036636353\n",
      "EPOCH [4/200], STEP [51/134]\n",
      "Total Loss G: 1.7253280878067017\n",
      "EPOCH [4/200], STEP [61/134]\n",
      "Total Loss G: 0.5239598751068115\n",
      "EPOCH [4/200], STEP [71/134]\n",
      "Total Loss G: 0.6119206547737122\n",
      "EPOCH [4/200], STEP [81/134]\n",
      "Total Loss G: 1.2879754304885864\n",
      "EPOCH [4/200], STEP [91/134]\n",
      "Total Loss G: 0.5427785515785217\n",
      "EPOCH [4/200], STEP [101/134]\n",
      "Total Loss G: 0.7952098846435547\n",
      "EPOCH [4/200], STEP [111/134]\n",
      "Total Loss G: 0.39061981439590454\n",
      "EPOCH [4/200], STEP [121/134]\n",
      "Total Loss G: 0.9610206484794617\n",
      "EPOCH [4/200], STEP [131/134]\n",
      "Total Loss G: 0.5960732698440552\n",
      "EPOCH [4/200], STEP [141/134]\n",
      "Total Loss G: 0.9290763735771179\n",
      "Training time is  1.118892534573873 mins\n",
      "Valid: 2-shot EPOCH [4/200], STEP [10/33]\n",
      "Total Loss V: 1.8060857057571411\n",
      "Valid: 2-shot EPOCH [4/200], STEP [20/33]\n",
      "Total Loss V: 1.8005934953689575\n",
      "Valid: 2-shot EPOCH [4/200], STEP [30/33]\n",
      "Total Loss V: 0.38145098090171814\n",
      "EPOCH [5/200], STEP [11/134]\n",
      "Total Loss G: 0.49079540371894836\n",
      "EPOCH [5/200], STEP [21/134]\n",
      "Total Loss G: 0.9362565875053406\n",
      "EPOCH [5/200], STEP [31/134]\n",
      "Total Loss G: 0.7122973203659058\n",
      "EPOCH [5/200], STEP [41/134]\n",
      "Total Loss G: 1.2755975723266602\n",
      "EPOCH [5/200], STEP [51/134]\n",
      "Total Loss G: 1.299300193786621\n",
      "EPOCH [5/200], STEP [61/134]\n",
      "Total Loss G: 0.8635295033454895\n",
      "EPOCH [5/200], STEP [71/134]\n",
      "Total Loss G: 0.3996191620826721\n",
      "EPOCH [5/200], STEP [81/134]\n",
      "Total Loss G: 1.2603158950805664\n",
      "EPOCH [5/200], STEP [91/134]\n",
      "Total Loss G: 0.6040766835212708\n",
      "EPOCH [5/200], STEP [101/134]\n",
      "Total Loss G: 0.4811854064464569\n",
      "EPOCH [5/200], STEP [111/134]\n",
      "Total Loss G: 0.2988492548465729\n",
      "EPOCH [5/200], STEP [121/134]\n",
      "Total Loss G: 0.8897899985313416\n",
      "EPOCH [5/200], STEP [131/134]\n",
      "Total Loss G: 0.4997466802597046\n",
      "EPOCH [5/200], STEP [141/134]\n",
      "Total Loss G: 0.8452486991882324\n",
      "Training time is  1.0292243917783102 mins\n",
      "Valid: 2-shot EPOCH [5/200], STEP [10/33]\n",
      "Total Loss V: 1.8464155197143555\n",
      "Valid: 2-shot EPOCH [5/200], STEP [20/33]\n",
      "Total Loss V: 1.877180576324463\n",
      "Valid: 2-shot EPOCH [5/200], STEP [30/33]\n",
      "Total Loss V: 0.29159361124038696\n",
      "EPOCH [6/200], STEP [11/134]\n",
      "Total Loss G: 0.32038000226020813\n",
      "EPOCH [6/200], STEP [21/134]\n",
      "Total Loss G: 0.7483279705047607\n",
      "EPOCH [6/200], STEP [31/134]\n",
      "Total Loss G: 0.5566122531890869\n",
      "EPOCH [6/200], STEP [41/134]\n",
      "Total Loss G: 1.4175211191177368\n",
      "EPOCH [6/200], STEP [51/134]\n",
      "Total Loss G: 1.3635808229446411\n",
      "EPOCH [6/200], STEP [61/134]\n",
      "Total Loss G: 0.46837660670280457\n",
      "EPOCH [6/200], STEP [71/134]\n",
      "Total Loss G: 0.36891821026802063\n",
      "EPOCH [6/200], STEP [81/134]\n",
      "Total Loss G: 1.032916784286499\n",
      "EPOCH [6/200], STEP [91/134]\n",
      "Total Loss G: 0.5807943344116211\n",
      "EPOCH [6/200], STEP [101/134]\n",
      "Total Loss G: 0.5789152979850769\n",
      "EPOCH [6/200], STEP [111/134]\n",
      "Total Loss G: 0.46535250544548035\n",
      "EPOCH [6/200], STEP [121/134]\n",
      "Total Loss G: 0.9203810095787048\n",
      "EPOCH [6/200], STEP [131/134]\n",
      "Total Loss G: 0.5043274164199829\n",
      "EPOCH [6/200], STEP [141/134]\n",
      "Total Loss G: 0.8335300087928772\n",
      "Training time is  0.9691359718640645 mins\n",
      "Valid: 2-shot EPOCH [6/200], STEP [10/33]\n",
      "Total Loss V: 1.7636269330978394\n",
      "Valid: 2-shot EPOCH [6/200], STEP [20/33]\n",
      "Total Loss V: 1.6266586780548096\n",
      "Valid: 2-shot EPOCH [6/200], STEP [30/33]\n",
      "Total Loss V: 0.2986888289451599\n",
      "EPOCH [7/200], STEP [11/134]\n",
      "Total Loss G: 0.4137400686740875\n",
      "EPOCH [7/200], STEP [21/134]\n",
      "Total Loss G: 1.0442423820495605\n",
      "EPOCH [7/200], STEP [31/134]\n",
      "Total Loss G: 0.4562270939350128\n",
      "EPOCH [7/200], STEP [41/134]\n",
      "Total Loss G: 1.5658396482467651\n",
      "EPOCH [7/200], STEP [51/134]\n",
      "Total Loss G: 1.4324637651443481\n",
      "EPOCH [7/200], STEP [61/134]\n",
      "Total Loss G: 0.5411021709442139\n",
      "EPOCH [7/200], STEP [71/134]\n",
      "Total Loss G: 0.5315269231796265\n",
      "EPOCH [7/200], STEP [81/134]\n",
      "Total Loss G: 1.1090742349624634\n",
      "EPOCH [7/200], STEP [91/134]\n",
      "Total Loss G: 0.5861182808876038\n",
      "EPOCH [7/200], STEP [101/134]\n",
      "Total Loss G: 0.7132459878921509\n",
      "EPOCH [7/200], STEP [111/134]\n",
      "Total Loss G: 0.46216005086898804\n",
      "EPOCH [7/200], STEP [121/134]\n",
      "Total Loss G: 0.9002596139907837\n",
      "EPOCH [7/200], STEP [131/134]\n",
      "Total Loss G: 0.4952262043952942\n",
      "EPOCH [7/200], STEP [141/134]\n",
      "Total Loss G: 0.7435826659202576\n",
      "Training time is  0.969426937898 mins\n",
      "Valid: 2-shot EPOCH [7/200], STEP [10/33]\n",
      "Total Loss V: 1.6508296728134155\n",
      "Valid: 2-shot EPOCH [7/200], STEP [20/33]\n",
      "Total Loss V: 1.8131183385849\n",
      "Valid: 2-shot EPOCH [7/200], STEP [30/33]\n",
      "Total Loss V: 0.279794842004776\n",
      "EPOCH [8/200], STEP [11/134]\n",
      "Total Loss G: 0.533586323261261\n",
      "EPOCH [8/200], STEP [21/134]\n",
      "Total Loss G: 1.2254819869995117\n",
      "EPOCH [8/200], STEP [31/134]\n",
      "Total Loss G: 0.4340049922466278\n",
      "EPOCH [8/200], STEP [41/134]\n",
      "Total Loss G: 1.5138633251190186\n",
      "EPOCH [8/200], STEP [51/134]\n",
      "Total Loss G: 1.587257981300354\n",
      "EPOCH [8/200], STEP [61/134]\n",
      "Total Loss G: 0.4176245927810669\n",
      "EPOCH [8/200], STEP [71/134]\n",
      "Total Loss G: 0.4885317087173462\n",
      "EPOCH [8/200], STEP [81/134]\n",
      "Total Loss G: 1.3699371814727783\n",
      "EPOCH [8/200], STEP [91/134]\n",
      "Total Loss G: 0.6684333682060242\n",
      "EPOCH [8/200], STEP [101/134]\n",
      "Total Loss G: 0.5510677099227905\n",
      "EPOCH [8/200], STEP [111/134]\n",
      "Total Loss G: 0.41556164622306824\n",
      "EPOCH [8/200], STEP [121/134]\n",
      "Total Loss G: 0.873167872428894\n",
      "EPOCH [8/200], STEP [131/134]\n",
      "Total Loss G: 0.521233320236206\n",
      "EPOCH [8/200], STEP [141/134]\n",
      "Total Loss G: 0.8352640867233276\n",
      "Training time is  0.9707059899965922 mins\n",
      "Valid: 2-shot EPOCH [8/200], STEP [10/33]\n",
      "Total Loss V: 1.7302955389022827\n",
      "Valid: 2-shot EPOCH [8/200], STEP [20/33]\n",
      "Total Loss V: 2.1435539722442627\n",
      "Valid: 2-shot EPOCH [8/200], STEP [30/33]\n",
      "Total Loss V: 0.3147575855255127\n",
      "EPOCH [9/200], STEP [11/134]\n",
      "Total Loss G: 0.31334999203681946\n",
      "EPOCH [9/200], STEP [21/134]\n",
      "Total Loss G: 0.6237557530403137\n",
      "EPOCH [9/200], STEP [31/134]\n",
      "Total Loss G: 0.5533055067062378\n",
      "EPOCH [9/200], STEP [41/134]\n",
      "Total Loss G: 1.2949970960617065\n",
      "EPOCH [9/200], STEP [51/134]\n",
      "Total Loss G: 1.606097936630249\n",
      "EPOCH [9/200], STEP [61/134]\n",
      "Total Loss G: 0.4165239632129669\n",
      "EPOCH [9/200], STEP [71/134]\n",
      "Total Loss G: 0.37454017996788025\n",
      "EPOCH [9/200], STEP [81/134]\n",
      "Total Loss G: 1.056464433670044\n",
      "EPOCH [9/200], STEP [91/134]\n",
      "Total Loss G: 0.5703482031822205\n",
      "EPOCH [9/200], STEP [101/134]\n",
      "Total Loss G: 0.6221489906311035\n",
      "EPOCH [9/200], STEP [111/134]\n",
      "Total Loss G: 0.39136263728141785\n",
      "EPOCH [9/200], STEP [121/134]\n",
      "Total Loss G: 1.03764808177948\n",
      "EPOCH [9/200], STEP [131/134]\n",
      "Total Loss G: 0.5145186185836792\n",
      "EPOCH [9/200], STEP [141/134]\n",
      "Total Loss G: 0.7931137681007385\n",
      "Training time is  0.9683122316996257 mins\n",
      "Valid: 2-shot EPOCH [9/200], STEP [10/33]\n",
      "Total Loss V: 1.7237073183059692\n",
      "Valid: 2-shot EPOCH [9/200], STEP [20/33]\n",
      "Total Loss V: 2.157212734222412\n",
      "Valid: 2-shot EPOCH [9/200], STEP [30/33]\n",
      "Total Loss V: 0.384519100189209\n",
      "EPOCH [10/200], STEP [11/134]\n",
      "Total Loss G: 0.2907419204711914\n",
      "EPOCH [10/200], STEP [21/134]\n",
      "Total Loss G: 0.6181216835975647\n",
      "EPOCH [10/200], STEP [31/134]\n",
      "Total Loss G: 0.41458427906036377\n",
      "EPOCH [10/200], STEP [41/134]\n",
      "Total Loss G: 1.2459369897842407\n",
      "EPOCH [10/200], STEP [51/134]\n",
      "Total Loss G: 1.5529060363769531\n",
      "EPOCH [10/200], STEP [61/134]\n",
      "Total Loss G: 0.41798168420791626\n",
      "EPOCH [10/200], STEP [71/134]\n",
      "Total Loss G: 0.39496833086013794\n",
      "EPOCH [10/200], STEP [81/134]\n",
      "Total Loss G: 1.161289095878601\n",
      "EPOCH [10/200], STEP [91/134]\n",
      "Total Loss G: 0.5856556296348572\n",
      "EPOCH [10/200], STEP [101/134]\n",
      "Total Loss G: 0.5992698073387146\n",
      "EPOCH [10/200], STEP [111/134]\n",
      "Total Loss G: 0.43970969319343567\n",
      "EPOCH [10/200], STEP [121/134]\n",
      "Total Loss G: 0.8433331251144409\n",
      "EPOCH [10/200], STEP [131/134]\n",
      "Total Loss G: 0.4821757674217224\n",
      "EPOCH [10/200], STEP [141/134]\n",
      "Total Loss G: 0.7525078058242798\n",
      "Training time is  0.9695189555486043 mins\n",
      "Valid: 2-shot EPOCH [10/200], STEP [10/33]\n",
      "Total Loss V: 1.6836304664611816\n",
      "Valid: 2-shot EPOCH [10/200], STEP [20/33]\n",
      "Total Loss V: 1.9924898147583008\n",
      "Valid: 2-shot EPOCH [10/200], STEP [30/33]\n",
      "Total Loss V: 0.27003106474876404\n",
      "EPOCH [11/200], STEP [11/134]\n",
      "Total Loss G: 0.28842365741729736\n",
      "EPOCH [11/200], STEP [21/134]\n",
      "Total Loss G: 0.6519094705581665\n",
      "EPOCH [11/200], STEP [31/134]\n",
      "Total Loss G: 0.43919411301612854\n",
      "EPOCH [11/200], STEP [41/134]\n",
      "Total Loss G: 1.2871989011764526\n",
      "EPOCH [11/200], STEP [51/134]\n",
      "Total Loss G: 1.4991859197616577\n",
      "EPOCH [11/200], STEP [61/134]\n",
      "Total Loss G: 0.46699824929237366\n",
      "EPOCH [11/200], STEP [71/134]\n",
      "Total Loss G: 0.3634580671787262\n",
      "EPOCH [11/200], STEP [81/134]\n",
      "Total Loss G: 1.062825322151184\n",
      "EPOCH [11/200], STEP [91/134]\n",
      "Total Loss G: 0.6151634454727173\n",
      "EPOCH [11/200], STEP [101/134]\n",
      "Total Loss G: 0.57216876745224\n",
      "EPOCH [11/200], STEP [111/134]\n",
      "Total Loss G: 0.3213578462600708\n",
      "EPOCH [11/200], STEP [121/134]\n",
      "Total Loss G: 0.8829381465911865\n",
      "EPOCH [11/200], STEP [131/134]\n",
      "Total Loss G: 0.5042449235916138\n",
      "EPOCH [11/200], STEP [141/134]\n",
      "Total Loss G: 0.744602382183075\n",
      "Training time is  0.9670156002044678 mins\n",
      "Valid: 2-shot EPOCH [11/200], STEP [10/33]\n",
      "Total Loss V: 1.6519553661346436\n",
      "Valid: 2-shot EPOCH [11/200], STEP [20/33]\n",
      "Total Loss V: 2.0154943466186523\n",
      "Valid: 2-shot EPOCH [11/200], STEP [30/33]\n",
      "Total Loss V: 0.2662816345691681\n",
      "EPOCH [12/200], STEP [11/134]\n",
      "Total Loss G: 0.35642075538635254\n",
      "EPOCH [12/200], STEP [21/134]\n",
      "Total Loss G: 0.7088012099266052\n",
      "EPOCH [12/200], STEP [31/134]\n",
      "Total Loss G: 0.42065975069999695\n",
      "EPOCH [12/200], STEP [41/134]\n",
      "Total Loss G: 1.173298954963684\n",
      "EPOCH [12/200], STEP [51/134]\n",
      "Total Loss G: 1.484067440032959\n",
      "EPOCH [12/200], STEP [61/134]\n",
      "Total Loss G: 0.44383636116981506\n",
      "EPOCH [12/200], STEP [71/134]\n",
      "Total Loss G: 0.7083359360694885\n",
      "EPOCH [12/200], STEP [81/134]\n",
      "Total Loss G: 1.09236741065979\n",
      "EPOCH [12/200], STEP [91/134]\n",
      "Total Loss G: 0.9876272678375244\n",
      "EPOCH [12/200], STEP [101/134]\n",
      "Total Loss G: 0.6045405268669128\n",
      "EPOCH [12/200], STEP [111/134]\n",
      "Total Loss G: 0.35708269476890564\n",
      "EPOCH [12/200], STEP [121/134]\n",
      "Total Loss G: 0.9002584218978882\n",
      "EPOCH [12/200], STEP [131/134]\n",
      "Total Loss G: 0.5064171552658081\n",
      "EPOCH [12/200], STEP [141/134]\n",
      "Total Loss G: 0.7794800400733948\n",
      "Training time is  0.8838459451993307 mins\n",
      "Valid: 2-shot EPOCH [12/200], STEP [10/33]\n",
      "Total Loss V: 1.6597696542739868\n",
      "Valid: 2-shot EPOCH [12/200], STEP [20/33]\n",
      "Total Loss V: 1.8764818906784058\n",
      "Valid: 2-shot EPOCH [12/200], STEP [30/33]\n",
      "Total Loss V: 0.2487383782863617\n",
      "EPOCH [13/200], STEP [11/134]\n",
      "Total Loss G: 0.40833359956741333\n",
      "EPOCH [13/200], STEP [21/134]\n",
      "Total Loss G: 0.5866759419441223\n",
      "EPOCH [13/200], STEP [31/134]\n",
      "Total Loss G: 0.4624292850494385\n",
      "EPOCH [13/200], STEP [41/134]\n",
      "Total Loss G: 1.2602747678756714\n",
      "EPOCH [13/200], STEP [51/134]\n",
      "Total Loss G: 1.4537163972854614\n",
      "EPOCH [13/200], STEP [61/134]\n",
      "Total Loss G: 0.45948702096939087\n",
      "EPOCH [13/200], STEP [71/134]\n",
      "Total Loss G: 0.4038771688938141\n",
      "EPOCH [13/200], STEP [81/134]\n",
      "Total Loss G: 1.0839420557022095\n",
      "EPOCH [13/200], STEP [91/134]\n",
      "Total Loss G: 0.5500038862228394\n",
      "EPOCH [13/200], STEP [101/134]\n",
      "Total Loss G: 0.5259334444999695\n",
      "EPOCH [13/200], STEP [111/134]\n",
      "Total Loss G: 0.36101508140563965\n",
      "EPOCH [13/200], STEP [121/134]\n",
      "Total Loss G: 0.8307509422302246\n",
      "EPOCH [13/200], STEP [131/134]\n",
      "Total Loss G: 0.3809100091457367\n",
      "EPOCH [13/200], STEP [141/134]\n",
      "Total Loss G: 0.75290447473526\n",
      "Training time is  0.8231225728988647 mins\n",
      "Valid: 2-shot EPOCH [13/200], STEP [10/33]\n",
      "Total Loss V: 1.643385410308838\n",
      "Valid: 2-shot EPOCH [13/200], STEP [20/33]\n",
      "Total Loss V: 1.9470751285552979\n",
      "Valid: 2-shot EPOCH [13/200], STEP [30/33]\n",
      "Total Loss V: 0.32801634073257446\n",
      "EPOCH [14/200], STEP [11/134]\n",
      "Total Loss G: 0.3190557658672333\n",
      "EPOCH [14/200], STEP [21/134]\n",
      "Total Loss G: 0.6738660931587219\n",
      "EPOCH [14/200], STEP [31/134]\n",
      "Total Loss G: 0.51580411195755\n",
      "EPOCH [14/200], STEP [41/134]\n",
      "Total Loss G: 1.2720056772232056\n",
      "EPOCH [14/200], STEP [51/134]\n",
      "Total Loss G: 1.4394139051437378\n",
      "EPOCH [14/200], STEP [61/134]\n",
      "Total Loss G: 0.4433491826057434\n",
      "EPOCH [14/200], STEP [71/134]\n",
      "Total Loss G: 0.49209314584732056\n",
      "EPOCH [14/200], STEP [81/134]\n",
      "Total Loss G: 1.0083954334259033\n",
      "EPOCH [14/200], STEP [91/134]\n",
      "Total Loss G: 0.47179490327835083\n",
      "EPOCH [14/200], STEP [101/134]\n",
      "Total Loss G: 0.5401895046234131\n",
      "EPOCH [14/200], STEP [111/134]\n",
      "Total Loss G: 0.2686430811882019\n",
      "EPOCH [14/200], STEP [121/134]\n",
      "Total Loss G: 0.8571258187294006\n",
      "EPOCH [14/200], STEP [131/134]\n",
      "Total Loss G: 0.5314719080924988\n",
      "EPOCH [14/200], STEP [141/134]\n",
      "Total Loss G: 0.7612237930297852\n",
      "Training time is  0.8191429098447164 mins\n",
      "Valid: 2-shot EPOCH [14/200], STEP [10/33]\n",
      "Total Loss V: 1.5786594152450562\n",
      "Valid: 2-shot EPOCH [14/200], STEP [20/33]\n",
      "Total Loss V: 1.6444642543792725\n",
      "Valid: 2-shot EPOCH [14/200], STEP [30/33]\n",
      "Total Loss V: 0.32669442892074585\n",
      "EPOCH [15/200], STEP [11/134]\n",
      "Total Loss G: 0.40109309554100037\n",
      "EPOCH [15/200], STEP [21/134]\n",
      "Total Loss G: 0.5386958718299866\n",
      "EPOCH [15/200], STEP [31/134]\n",
      "Total Loss G: 0.5442461967468262\n",
      "EPOCH [15/200], STEP [41/134]\n",
      "Total Loss G: 1.228019118309021\n",
      "EPOCH [15/200], STEP [51/134]\n",
      "Total Loss G: 1.3140970468521118\n",
      "EPOCH [15/200], STEP [61/134]\n",
      "Total Loss G: 0.36844438314437866\n",
      "EPOCH [15/200], STEP [71/134]\n",
      "Total Loss G: 0.4237960875034332\n",
      "EPOCH [15/200], STEP [81/134]\n",
      "Total Loss G: 1.0969294309616089\n",
      "EPOCH [15/200], STEP [91/134]\n",
      "Total Loss G: 0.5344185829162598\n",
      "EPOCH [15/200], STEP [101/134]\n",
      "Total Loss G: 0.48391684889793396\n",
      "EPOCH [15/200], STEP [111/134]\n",
      "Total Loss G: 0.2516091763973236\n",
      "EPOCH [15/200], STEP [121/134]\n",
      "Total Loss G: 0.8191515803337097\n",
      "EPOCH [15/200], STEP [131/134]\n",
      "Total Loss G: 0.42384132742881775\n",
      "EPOCH [15/200], STEP [141/134]\n",
      "Total Loss G: 0.7740365862846375\n",
      "Training time is  0.8252108971277873 mins\n",
      "Valid: 2-shot EPOCH [15/200], STEP [10/33]\n",
      "Total Loss V: 1.6661289930343628\n",
      "Valid: 2-shot EPOCH [15/200], STEP [20/33]\n",
      "Total Loss V: 1.737452507019043\n",
      "Valid: 2-shot EPOCH [15/200], STEP [30/33]\n",
      "Total Loss V: 0.30921924114227295\n",
      "EPOCH [16/200], STEP [11/134]\n",
      "Total Loss G: 0.41640058159828186\n",
      "EPOCH [16/200], STEP [21/134]\n",
      "Total Loss G: 0.558639407157898\n",
      "EPOCH [16/200], STEP [31/134]\n",
      "Total Loss G: 0.4062480032444\n",
      "EPOCH [16/200], STEP [41/134]\n",
      "Total Loss G: 1.1266885995864868\n",
      "EPOCH [16/200], STEP [51/134]\n",
      "Total Loss G: 1.344348669052124\n",
      "EPOCH [16/200], STEP [61/134]\n",
      "Total Loss G: 0.40204066038131714\n",
      "EPOCH [16/200], STEP [71/134]\n",
      "Total Loss G: 0.3760547637939453\n",
      "EPOCH [16/200], STEP [81/134]\n",
      "Total Loss G: 1.0519397258758545\n",
      "EPOCH [16/200], STEP [91/134]\n",
      "Total Loss G: 0.5136141777038574\n",
      "EPOCH [16/200], STEP [101/134]\n",
      "Total Loss G: 0.42298340797424316\n",
      "EPOCH [16/200], STEP [111/134]\n",
      "Total Loss G: 0.3144320249557495\n",
      "EPOCH [16/200], STEP [121/134]\n",
      "Total Loss G: 0.7956947684288025\n",
      "EPOCH [16/200], STEP [131/134]\n",
      "Total Loss G: 0.44958972930908203\n",
      "EPOCH [16/200], STEP [141/134]\n",
      "Total Loss G: 0.7507236003875732\n",
      "Training time is  0.8277705470720927 mins\n",
      "Valid: 2-shot EPOCH [16/200], STEP [10/33]\n",
      "Total Loss V: 1.6778700351715088\n",
      "Valid: 2-shot EPOCH [16/200], STEP [20/33]\n",
      "Total Loss V: 1.6981725692749023\n",
      "Valid: 2-shot EPOCH [16/200], STEP [30/33]\n",
      "Total Loss V: 0.3128027319908142\n",
      "EPOCH [17/200], STEP [11/134]\n",
      "Total Loss G: 0.3433489203453064\n",
      "EPOCH [17/200], STEP [21/134]\n",
      "Total Loss G: 0.5940687656402588\n",
      "EPOCH [17/200], STEP [31/134]\n",
      "Total Loss G: 0.4468128979206085\n",
      "EPOCH [17/200], STEP [41/134]\n",
      "Total Loss G: 1.1723127365112305\n",
      "EPOCH [17/200], STEP [51/134]\n",
      "Total Loss G: 1.4263792037963867\n",
      "EPOCH [17/200], STEP [61/134]\n",
      "Total Loss G: 0.42919856309890747\n",
      "EPOCH [17/200], STEP [71/134]\n",
      "Total Loss G: 0.4513961672782898\n",
      "EPOCH [17/200], STEP [81/134]\n",
      "Total Loss G: 1.1260550022125244\n",
      "EPOCH [17/200], STEP [91/134]\n",
      "Total Loss G: 0.6176145672798157\n",
      "EPOCH [17/200], STEP [101/134]\n",
      "Total Loss G: 0.5182616114616394\n",
      "EPOCH [17/200], STEP [111/134]\n",
      "Total Loss G: 0.2722533047199249\n",
      "EPOCH [17/200], STEP [121/134]\n",
      "Total Loss G: 0.9423111081123352\n",
      "EPOCH [17/200], STEP [131/134]\n",
      "Total Loss G: 0.5234668254852295\n",
      "EPOCH [17/200], STEP [141/134]\n",
      "Total Loss G: 0.6943089365959167\n",
      "Training time is  0.8241039474805196 mins\n",
      "Valid: 2-shot EPOCH [17/200], STEP [10/33]\n",
      "Total Loss V: 1.4892430305480957\n",
      "Valid: 2-shot EPOCH [17/200], STEP [20/33]\n",
      "Total Loss V: 1.99074387550354\n",
      "Valid: 2-shot EPOCH [17/200], STEP [30/33]\n",
      "Total Loss V: 0.2639167308807373\n",
      "EPOCH [18/200], STEP [11/134]\n",
      "Total Loss G: 0.6566442847251892\n",
      "EPOCH [18/200], STEP [21/134]\n",
      "Total Loss G: 0.6431106925010681\n",
      "EPOCH [18/200], STEP [31/134]\n",
      "Total Loss G: 0.4276682734489441\n",
      "EPOCH [18/200], STEP [41/134]\n",
      "Total Loss G: 1.239895224571228\n",
      "EPOCH [18/200], STEP [51/134]\n",
      "Total Loss G: 1.4376530647277832\n",
      "EPOCH [18/200], STEP [61/134]\n",
      "Total Loss G: 0.3826631009578705\n",
      "EPOCH [18/200], STEP [71/134]\n",
      "Total Loss G: 0.3241882026195526\n",
      "EPOCH [18/200], STEP [81/134]\n",
      "Total Loss G: 1.0800656080245972\n",
      "EPOCH [18/200], STEP [91/134]\n",
      "Total Loss G: 0.6581815481185913\n",
      "EPOCH [18/200], STEP [101/134]\n",
      "Total Loss G: 0.4638100266456604\n",
      "EPOCH [18/200], STEP [111/134]\n",
      "Total Loss G: 0.2674919366836548\n",
      "EPOCH [18/200], STEP [121/134]\n",
      "Total Loss G: 0.727190375328064\n",
      "EPOCH [18/200], STEP [131/134]\n",
      "Total Loss G: 0.3852475583553314\n",
      "EPOCH [18/200], STEP [141/134]\n",
      "Total Loss G: 0.7831168174743652\n",
      "Training time is  0.8261252482732137 mins\n",
      "Valid: 2-shot EPOCH [18/200], STEP [10/33]\n",
      "Total Loss V: 1.5230745077133179\n",
      "Valid: 2-shot EPOCH [18/200], STEP [20/33]\n",
      "Total Loss V: 1.577155590057373\n",
      "Valid: 2-shot EPOCH [18/200], STEP [30/33]\n",
      "Total Loss V: 0.273201048374176\n",
      "EPOCH [19/200], STEP [11/134]\n",
      "Total Loss G: 0.5662508606910706\n",
      "EPOCH [19/200], STEP [21/134]\n",
      "Total Loss G: 0.5990025401115417\n",
      "EPOCH [19/200], STEP [31/134]\n",
      "Total Loss G: 0.45427224040031433\n",
      "EPOCH [19/200], STEP [41/134]\n",
      "Total Loss G: 1.1561254262924194\n",
      "EPOCH [19/200], STEP [51/134]\n",
      "Total Loss G: 1.2015446424484253\n",
      "EPOCH [19/200], STEP [61/134]\n",
      "Total Loss G: 0.36571961641311646\n",
      "EPOCH [19/200], STEP [71/134]\n",
      "Total Loss G: 0.29565730690956116\n",
      "EPOCH [19/200], STEP [81/134]\n",
      "Total Loss G: 0.9838389754295349\n",
      "EPOCH [19/200], STEP [91/134]\n",
      "Total Loss G: 0.4014851748943329\n",
      "EPOCH [19/200], STEP [101/134]\n",
      "Total Loss G: 0.49552324414253235\n",
      "EPOCH [19/200], STEP [111/134]\n",
      "Total Loss G: 0.5441595315933228\n",
      "EPOCH [19/200], STEP [121/134]\n",
      "Total Loss G: 0.8692553043365479\n",
      "EPOCH [19/200], STEP [131/134]\n",
      "Total Loss G: 0.5448219180107117\n",
      "EPOCH [19/200], STEP [141/134]\n",
      "Total Loss G: 0.7224563360214233\n",
      "Training time is  0.8249203483263652 mins\n",
      "Valid: 2-shot EPOCH [19/200], STEP [10/33]\n",
      "Total Loss V: 1.588837742805481\n",
      "Valid: 2-shot EPOCH [19/200], STEP [20/33]\n",
      "Total Loss V: 1.7042018175125122\n",
      "Valid: 2-shot EPOCH [19/200], STEP [30/33]\n",
      "Total Loss V: 0.2685830295085907\n",
      "EPOCH [20/200], STEP [11/134]\n",
      "Total Loss G: 0.3854879140853882\n",
      "EPOCH [20/200], STEP [21/134]\n",
      "Total Loss G: 0.5730335712432861\n",
      "EPOCH [20/200], STEP [31/134]\n",
      "Total Loss G: 0.32160258293151855\n",
      "EPOCH [20/200], STEP [41/134]\n",
      "Total Loss G: 1.0530610084533691\n",
      "EPOCH [20/200], STEP [51/134]\n",
      "Total Loss G: 1.243720531463623\n",
      "EPOCH [20/200], STEP [61/134]\n",
      "Total Loss G: 0.4213826656341553\n",
      "EPOCH [20/200], STEP [71/134]\n",
      "Total Loss G: 0.44118383526802063\n",
      "EPOCH [20/200], STEP [81/134]\n",
      "Total Loss G: 1.0621672868728638\n",
      "EPOCH [20/200], STEP [91/134]\n",
      "Total Loss G: 0.5942142009735107\n",
      "EPOCH [20/200], STEP [101/134]\n",
      "Total Loss G: 0.4586809575557709\n",
      "EPOCH [20/200], STEP [111/134]\n",
      "Total Loss G: 0.32582351565361023\n",
      "EPOCH [20/200], STEP [121/134]\n",
      "Total Loss G: 0.754875123500824\n",
      "EPOCH [20/200], STEP [131/134]\n",
      "Total Loss G: 0.4497462213039398\n",
      "EPOCH [20/200], STEP [141/134]\n",
      "Total Loss G: 0.7696169018745422\n",
      "Training time is  0.8286856134732564 mins\n",
      "Valid: 2-shot EPOCH [20/200], STEP [10/33]\n",
      "Total Loss V: 1.6131000518798828\n",
      "Valid: 2-shot EPOCH [20/200], STEP [20/33]\n",
      "Total Loss V: 1.5142052173614502\n",
      "Valid: 2-shot EPOCH [20/200], STEP [30/33]\n",
      "Total Loss V: 0.3061980605125427\n",
      "EPOCH [21/200], STEP [11/134]\n",
      "Total Loss G: 0.625335156917572\n",
      "EPOCH [21/200], STEP [21/134]\n",
      "Total Loss G: 0.5916324853897095\n",
      "EPOCH [21/200], STEP [31/134]\n",
      "Total Loss G: 0.3656429946422577\n",
      "EPOCH [21/200], STEP [41/134]\n",
      "Total Loss G: 1.11848783493042\n",
      "EPOCH [21/200], STEP [51/134]\n",
      "Total Loss G: 1.25226891040802\n",
      "EPOCH [21/200], STEP [61/134]\n",
      "Total Loss G: 0.371614933013916\n",
      "EPOCH [21/200], STEP [71/134]\n",
      "Total Loss G: 0.3323369324207306\n",
      "EPOCH [21/200], STEP [81/134]\n",
      "Total Loss G: 1.0288026332855225\n",
      "EPOCH [21/200], STEP [91/134]\n",
      "Total Loss G: 0.6297122240066528\n",
      "EPOCH [21/200], STEP [101/134]\n",
      "Total Loss G: 0.42655590176582336\n",
      "EPOCH [21/200], STEP [111/134]\n",
      "Total Loss G: 0.30159565806388855\n",
      "EPOCH [21/200], STEP [121/134]\n",
      "Total Loss G: 0.6989515423774719\n",
      "EPOCH [21/200], STEP [131/134]\n",
      "Total Loss G: 0.5170807838439941\n",
      "EPOCH [21/200], STEP [141/134]\n",
      "Total Loss G: 0.7106497287750244\n",
      "Training time is  0.8267262736956279 mins\n",
      "Valid: 2-shot EPOCH [21/200], STEP [10/33]\n",
      "Total Loss V: 1.5334709882736206\n",
      "Valid: 2-shot EPOCH [21/200], STEP [20/33]\n",
      "Total Loss V: 1.4521652460098267\n",
      "Valid: 2-shot EPOCH [21/200], STEP [30/33]\n",
      "Total Loss V: 0.3079151213169098\n",
      "EPOCH [22/200], STEP [11/134]\n",
      "Total Loss G: 0.5371112823486328\n",
      "EPOCH [22/200], STEP [21/134]\n",
      "Total Loss G: 0.5958592295646667\n",
      "EPOCH [22/200], STEP [31/134]\n",
      "Total Loss G: 0.5937932133674622\n",
      "EPOCH [22/200], STEP [41/134]\n",
      "Total Loss G: 1.032746434211731\n",
      "EPOCH [22/200], STEP [51/134]\n",
      "Total Loss G: 1.3356232643127441\n",
      "EPOCH [22/200], STEP [61/134]\n",
      "Total Loss G: 0.3804709017276764\n",
      "EPOCH [22/200], STEP [71/134]\n",
      "Total Loss G: 0.3277529180049896\n",
      "EPOCH [22/200], STEP [81/134]\n",
      "Total Loss G: 1.0886365175247192\n",
      "EPOCH [22/200], STEP [91/134]\n",
      "Total Loss G: 0.48710185289382935\n",
      "EPOCH [22/200], STEP [101/134]\n",
      "Total Loss G: 0.4009702503681183\n",
      "EPOCH [22/200], STEP [111/134]\n",
      "Total Loss G: 0.3368890583515167\n",
      "EPOCH [22/200], STEP [121/134]\n",
      "Total Loss G: 0.7248266339302063\n",
      "EPOCH [22/200], STEP [131/134]\n",
      "Total Loss G: 0.42602190375328064\n",
      "EPOCH [22/200], STEP [141/134]\n",
      "Total Loss G: 0.7111077904701233\n",
      "Training time is  0.8252109328905741 mins\n",
      "Valid: 2-shot EPOCH [22/200], STEP [10/33]\n",
      "Total Loss V: 1.4705846309661865\n",
      "Valid: 2-shot EPOCH [22/200], STEP [20/33]\n",
      "Total Loss V: 1.5502634048461914\n",
      "Valid: 2-shot EPOCH [22/200], STEP [30/33]\n",
      "Total Loss V: 0.25179004669189453\n",
      "EPOCH [23/200], STEP [11/134]\n",
      "Total Loss G: 0.608527421951294\n",
      "EPOCH [23/200], STEP [21/134]\n",
      "Total Loss G: 0.5374736189842224\n",
      "EPOCH [23/200], STEP [31/134]\n",
      "Total Loss G: 0.43165311217308044\n",
      "EPOCH [23/200], STEP [41/134]\n",
      "Total Loss G: 1.040785551071167\n",
      "EPOCH [23/200], STEP [51/134]\n",
      "Total Loss G: 1.2249367237091064\n",
      "EPOCH [23/200], STEP [61/134]\n",
      "Total Loss G: 0.37505459785461426\n",
      "EPOCH [23/200], STEP [71/134]\n",
      "Total Loss G: 0.4293135106563568\n",
      "EPOCH [23/200], STEP [81/134]\n",
      "Total Loss G: 1.0500471591949463\n",
      "EPOCH [23/200], STEP [91/134]\n",
      "Total Loss G: 0.5086780786514282\n",
      "EPOCH [23/200], STEP [101/134]\n",
      "Total Loss G: 0.3487975597381592\n",
      "EPOCH [23/200], STEP [111/134]\n",
      "Total Loss G: 0.2971574366092682\n",
      "EPOCH [23/200], STEP [121/134]\n",
      "Total Loss G: 0.6742540597915649\n",
      "EPOCH [23/200], STEP [131/134]\n",
      "Total Loss G: 0.4434470236301422\n",
      "EPOCH [23/200], STEP [141/134]\n",
      "Total Loss G: 0.7319980263710022\n",
      "Training time is  0.8287347952524821 mins\n",
      "Valid: 2-shot EPOCH [23/200], STEP [10/33]\n",
      "Total Loss V: 1.4499635696411133\n",
      "Valid: 2-shot EPOCH [23/200], STEP [20/33]\n",
      "Total Loss V: 1.2737065553665161\n",
      "Valid: 2-shot EPOCH [23/200], STEP [30/33]\n",
      "Total Loss V: 0.2544742226600647\n",
      "EPOCH [24/200], STEP [11/134]\n",
      "Total Loss G: 0.7637398838996887\n",
      "EPOCH [24/200], STEP [21/134]\n",
      "Total Loss G: 0.5988628268241882\n",
      "EPOCH [24/200], STEP [31/134]\n",
      "Total Loss G: 0.3401928246021271\n",
      "EPOCH [24/200], STEP [41/134]\n",
      "Total Loss G: 1.1391340494155884\n",
      "EPOCH [24/200], STEP [51/134]\n",
      "Total Loss G: 1.2040486335754395\n",
      "EPOCH [24/200], STEP [61/134]\n",
      "Total Loss G: 0.33463728427886963\n",
      "EPOCH [24/200], STEP [71/134]\n",
      "Total Loss G: 0.35786473751068115\n",
      "EPOCH [24/200], STEP [81/134]\n",
      "Total Loss G: 0.9792630076408386\n",
      "EPOCH [24/200], STEP [91/134]\n",
      "Total Loss G: 0.5321465730667114\n",
      "EPOCH [24/200], STEP [101/134]\n",
      "Total Loss G: 0.34640297293663025\n",
      "EPOCH [24/200], STEP [111/134]\n",
      "Total Loss G: 0.27874624729156494\n",
      "EPOCH [24/200], STEP [121/134]\n",
      "Total Loss G: 0.6972032189369202\n",
      "EPOCH [24/200], STEP [131/134]\n",
      "Total Loss G: 0.5974841713905334\n",
      "EPOCH [24/200], STEP [141/134]\n",
      "Total Loss G: 0.627572238445282\n",
      "Training time is  0.8243937412897746 mins\n",
      "Valid: 2-shot EPOCH [24/200], STEP [10/33]\n",
      "Total Loss V: 1.2551382780075073\n",
      "Valid: 2-shot EPOCH [24/200], STEP [20/33]\n",
      "Total Loss V: 1.3186683654785156\n",
      "Valid: 2-shot EPOCH [24/200], STEP [30/33]\n",
      "Total Loss V: 0.24056077003479004\n",
      "EPOCH [25/200], STEP [11/134]\n",
      "Total Loss G: 1.2525036334991455\n",
      "EPOCH [25/200], STEP [21/134]\n",
      "Total Loss G: 0.7617759704589844\n",
      "EPOCH [25/200], STEP [31/134]\n",
      "Total Loss G: 0.4026896357536316\n",
      "EPOCH [25/200], STEP [41/134]\n",
      "Total Loss G: 1.0285449028015137\n",
      "EPOCH [25/200], STEP [51/134]\n",
      "Total Loss G: 1.1801095008850098\n",
      "EPOCH [25/200], STEP [61/134]\n",
      "Total Loss G: 0.338814914226532\n",
      "EPOCH [25/200], STEP [71/134]\n",
      "Total Loss G: 0.49865540862083435\n",
      "EPOCH [25/200], STEP [81/134]\n",
      "Total Loss G: 0.9408407807350159\n",
      "EPOCH [25/200], STEP [91/134]\n",
      "Total Loss G: 0.5816065669059753\n",
      "EPOCH [25/200], STEP [101/134]\n",
      "Total Loss G: 0.3411296308040619\n",
      "EPOCH [25/200], STEP [111/134]\n",
      "Total Loss G: 0.27366703748703003\n",
      "EPOCH [25/200], STEP [121/134]\n",
      "Total Loss G: 0.684980034828186\n",
      "EPOCH [25/200], STEP [131/134]\n",
      "Total Loss G: 0.43347617983818054\n",
      "EPOCH [25/200], STEP [141/134]\n",
      "Total Loss G: 0.7762866616249084\n",
      "Training time is  0.8279902855555217 mins\n",
      "Valid: 2-shot EPOCH [25/200], STEP [10/33]\n",
      "Total Loss V: 1.4582493305206299\n",
      "Valid: 2-shot EPOCH [25/200], STEP [20/33]\n",
      "Total Loss V: 0.9320651292800903\n",
      "Valid: 2-shot EPOCH [25/200], STEP [30/33]\n",
      "Total Loss V: 0.33055922389030457\n",
      "EPOCH [26/200], STEP [11/134]\n",
      "Total Loss G: 0.7833706140518188\n",
      "EPOCH [26/200], STEP [21/134]\n",
      "Total Loss G: 0.572547435760498\n",
      "EPOCH [26/200], STEP [31/134]\n",
      "Total Loss G: 0.41856256127357483\n",
      "EPOCH [26/200], STEP [41/134]\n",
      "Total Loss G: 1.1965303421020508\n",
      "EPOCH [26/200], STEP [51/134]\n",
      "Total Loss G: 1.1113545894622803\n",
      "EPOCH [26/200], STEP [61/134]\n",
      "Total Loss G: 0.395295113325119\n",
      "EPOCH [26/200], STEP [71/134]\n",
      "Total Loss G: 0.7130619287490845\n",
      "EPOCH [26/200], STEP [81/134]\n",
      "Total Loss G: 1.137773036956787\n",
      "EPOCH [26/200], STEP [91/134]\n",
      "Total Loss G: 0.3237415552139282\n",
      "EPOCH [26/200], STEP [101/134]\n",
      "Total Loss G: 0.2939980924129486\n",
      "EPOCH [26/200], STEP [111/134]\n",
      "Total Loss G: 0.3506879210472107\n",
      "EPOCH [26/200], STEP [121/134]\n",
      "Total Loss G: 0.8213425874710083\n",
      "EPOCH [26/200], STEP [131/134]\n",
      "Total Loss G: 0.4913178086280823\n",
      "EPOCH [26/200], STEP [141/134]\n",
      "Total Loss G: 0.7871142029762268\n",
      "Training time is  0.8331484079360962 mins\n",
      "Valid: 2-shot EPOCH [26/200], STEP [10/33]\n",
      "Total Loss V: 1.5877422094345093\n",
      "Valid: 2-shot EPOCH [26/200], STEP [20/33]\n",
      "Total Loss V: 1.9022836685180664\n",
      "Valid: 2-shot EPOCH [26/200], STEP [30/33]\n",
      "Total Loss V: 0.3526776134967804\n",
      "EPOCH [27/200], STEP [11/134]\n",
      "Total Loss G: 0.7023284435272217\n",
      "EPOCH [27/200], STEP [21/134]\n",
      "Total Loss G: 0.6609020829200745\n",
      "EPOCH [27/200], STEP [31/134]\n",
      "Total Loss G: 0.517920732498169\n",
      "EPOCH [27/200], STEP [41/134]\n",
      "Total Loss G: 1.2696645259857178\n",
      "EPOCH [27/200], STEP [51/134]\n",
      "Total Loss G: 1.5032962560653687\n",
      "EPOCH [27/200], STEP [61/134]\n",
      "Total Loss G: 0.4409602880477905\n",
      "EPOCH [27/200], STEP [71/134]\n",
      "Total Loss G: 0.5425066351890564\n",
      "EPOCH [27/200], STEP [81/134]\n",
      "Total Loss G: 1.0131947994232178\n",
      "EPOCH [27/200], STEP [91/134]\n",
      "Total Loss G: 0.39820799231529236\n",
      "EPOCH [27/200], STEP [101/134]\n",
      "Total Loss G: 0.3579884171485901\n",
      "EPOCH [27/200], STEP [111/134]\n",
      "Total Loss G: 0.2836054563522339\n",
      "EPOCH [27/200], STEP [121/134]\n",
      "Total Loss G: 0.657374382019043\n",
      "EPOCH [27/200], STEP [131/134]\n",
      "Total Loss G: 0.3955534100532532\n",
      "EPOCH [27/200], STEP [141/134]\n",
      "Total Loss G: 0.6667251586914062\n",
      "Training time is  0.829696269830068 mins\n",
      "Valid: 2-shot EPOCH [27/200], STEP [10/33]\n",
      "Total Loss V: 1.356276512145996\n",
      "Valid: 2-shot EPOCH [27/200], STEP [20/33]\n",
      "Total Loss V: 0.9970141053199768\n",
      "Valid: 2-shot EPOCH [27/200], STEP [30/33]\n",
      "Total Loss V: 0.2773039638996124\n",
      "EPOCH [28/200], STEP [11/134]\n",
      "Total Loss G: 0.8690131306648254\n",
      "EPOCH [28/200], STEP [21/134]\n",
      "Total Loss G: 0.6282753944396973\n",
      "EPOCH [28/200], STEP [31/134]\n",
      "Total Loss G: 0.23454320430755615\n",
      "EPOCH [28/200], STEP [41/134]\n",
      "Total Loss G: 1.1392676830291748\n",
      "EPOCH [28/200], STEP [51/134]\n",
      "Total Loss G: 1.0563631057739258\n",
      "EPOCH [28/200], STEP [61/134]\n",
      "Total Loss G: 0.37485361099243164\n",
      "EPOCH [28/200], STEP [71/134]\n",
      "Total Loss G: 0.38764438033103943\n",
      "EPOCH [28/200], STEP [81/134]\n",
      "Total Loss G: 1.0090854167938232\n",
      "EPOCH [28/200], STEP [91/134]\n",
      "Total Loss G: 0.6185365915298462\n",
      "EPOCH [28/200], STEP [101/134]\n",
      "Total Loss G: 0.3130188584327698\n",
      "EPOCH [28/200], STEP [111/134]\n",
      "Total Loss G: 0.3748306334018707\n",
      "EPOCH [28/200], STEP [121/134]\n",
      "Total Loss G: 0.7345408201217651\n",
      "EPOCH [28/200], STEP [131/134]\n",
      "Total Loss G: 0.4053073227405548\n",
      "EPOCH [28/200], STEP [141/134]\n",
      "Total Loss G: 0.6036401987075806\n",
      "Training time is  0.8301727096239726 mins\n",
      "Valid: 2-shot EPOCH [28/200], STEP [10/33]\n",
      "Total Loss V: 1.2442057132720947\n",
      "Valid: 2-shot EPOCH [28/200], STEP [20/33]\n",
      "Total Loss V: 1.0458061695098877\n",
      "Valid: 2-shot EPOCH [28/200], STEP [30/33]\n",
      "Total Loss V: 0.2674993574619293\n",
      "EPOCH [29/200], STEP [11/134]\n",
      "Total Loss G: 0.9198265671730042\n",
      "EPOCH [29/200], STEP [21/134]\n",
      "Total Loss G: 0.5215708017349243\n",
      "EPOCH [29/200], STEP [31/134]\n",
      "Total Loss G: 0.29298874735832214\n",
      "EPOCH [29/200], STEP [41/134]\n",
      "Total Loss G: 0.9437033534049988\n",
      "EPOCH [29/200], STEP [51/134]\n",
      "Total Loss G: 1.3478320837020874\n",
      "EPOCH [29/200], STEP [61/134]\n",
      "Total Loss G: 0.35269391536712646\n",
      "EPOCH [29/200], STEP [71/134]\n",
      "Total Loss G: 0.32107657194137573\n",
      "EPOCH [29/200], STEP [81/134]\n",
      "Total Loss G: 0.8851765394210815\n",
      "EPOCH [29/200], STEP [91/134]\n",
      "Total Loss G: 0.3917483687400818\n",
      "EPOCH [29/200], STEP [101/134]\n",
      "Total Loss G: 0.4825063645839691\n",
      "EPOCH [29/200], STEP [111/134]\n",
      "Total Loss G: 0.3868631422519684\n",
      "EPOCH [29/200], STEP [121/134]\n",
      "Total Loss G: 0.6823904514312744\n",
      "EPOCH [29/200], STEP [131/134]\n",
      "Total Loss G: 0.437787264585495\n",
      "EPOCH [29/200], STEP [141/134]\n",
      "Total Loss G: 0.6612278819084167\n",
      "Training time is  0.8418996016184489 mins\n",
      "Valid: 2-shot EPOCH [29/200], STEP [10/33]\n",
      "Total Loss V: 1.4049108028411865\n",
      "Valid: 2-shot EPOCH [29/200], STEP [20/33]\n",
      "Total Loss V: 0.8230385780334473\n",
      "Valid: 2-shot EPOCH [29/200], STEP [30/33]\n",
      "Total Loss V: 0.22984862327575684\n",
      "EPOCH [30/200], STEP [11/134]\n",
      "Total Loss G: 0.8250647783279419\n",
      "EPOCH [30/200], STEP [21/134]\n",
      "Total Loss G: 0.5852963328361511\n",
      "EPOCH [30/200], STEP [31/134]\n",
      "Total Loss G: 0.34928619861602783\n",
      "EPOCH [30/200], STEP [41/134]\n",
      "Total Loss G: 0.9553366303443909\n",
      "EPOCH [30/200], STEP [51/134]\n",
      "Total Loss G: 0.9785433411598206\n",
      "EPOCH [30/200], STEP [61/134]\n",
      "Total Loss G: 0.38740357756614685\n",
      "EPOCH [30/200], STEP [71/134]\n",
      "Total Loss G: 0.2733539640903473\n",
      "EPOCH [30/200], STEP [81/134]\n",
      "Total Loss G: 0.8894975185394287\n",
      "EPOCH [30/200], STEP [91/134]\n",
      "Total Loss G: 0.5264380574226379\n",
      "EPOCH [30/200], STEP [101/134]\n",
      "Total Loss G: 0.3312702476978302\n",
      "EPOCH [30/200], STEP [111/134]\n",
      "Total Loss G: 0.3136764466762543\n",
      "EPOCH [30/200], STEP [121/134]\n",
      "Total Loss G: 0.7162543535232544\n",
      "EPOCH [30/200], STEP [131/134]\n",
      "Total Loss G: 0.5038095712661743\n",
      "EPOCH [30/200], STEP [141/134]\n",
      "Total Loss G: 0.6005738973617554\n",
      "Training time is  0.8310617645581563 mins\n",
      "Valid: 2-shot EPOCH [30/200], STEP [10/33]\n",
      "Total Loss V: 1.3028693199157715\n",
      "Valid: 2-shot EPOCH [30/200], STEP [20/33]\n",
      "Total Loss V: 0.7942494750022888\n",
      "Valid: 2-shot EPOCH [30/200], STEP [30/33]\n",
      "Total Loss V: 0.24421299993991852\n",
      "EPOCH [31/200], STEP [11/134]\n",
      "Total Loss G: 1.0602178573608398\n",
      "EPOCH [31/200], STEP [21/134]\n",
      "Total Loss G: 0.6325319409370422\n",
      "EPOCH [31/200], STEP [31/134]\n",
      "Total Loss G: 0.2559007704257965\n",
      "EPOCH [31/200], STEP [41/134]\n",
      "Total Loss G: 1.0040154457092285\n",
      "EPOCH [31/200], STEP [51/134]\n",
      "Total Loss G: 1.038975477218628\n",
      "EPOCH [31/200], STEP [61/134]\n",
      "Total Loss G: 0.37200427055358887\n",
      "EPOCH [31/200], STEP [71/134]\n",
      "Total Loss G: 0.4454156458377838\n",
      "EPOCH [31/200], STEP [81/134]\n",
      "Total Loss G: 0.9236191511154175\n",
      "EPOCH [31/200], STEP [91/134]\n",
      "Total Loss G: 0.39517080783843994\n",
      "EPOCH [31/200], STEP [101/134]\n",
      "Total Loss G: 0.28852587938308716\n",
      "EPOCH [31/200], STEP [111/134]\n",
      "Total Loss G: 0.35283270478248596\n",
      "EPOCH [31/200], STEP [121/134]\n",
      "Total Loss G: 0.6629396677017212\n",
      "EPOCH [31/200], STEP [131/134]\n",
      "Total Loss G: 0.5277172327041626\n",
      "EPOCH [31/200], STEP [141/134]\n",
      "Total Loss G: 0.44548308849334717\n",
      "Training time is  0.8253288388252258 mins\n",
      "Valid: 2-shot EPOCH [31/200], STEP [10/33]\n",
      "Total Loss V: 1.069839358329773\n",
      "Valid: 2-shot EPOCH [31/200], STEP [20/33]\n",
      "Total Loss V: 1.0756604671478271\n",
      "Valid: 2-shot EPOCH [31/200], STEP [30/33]\n",
      "Total Loss V: 0.2683810591697693\n",
      "EPOCH [32/200], STEP [11/134]\n",
      "Total Loss G: 1.2599819898605347\n",
      "EPOCH [32/200], STEP [21/134]\n",
      "Total Loss G: 0.6679796576499939\n",
      "EPOCH [32/200], STEP [31/134]\n",
      "Total Loss G: 0.19694900512695312\n",
      "EPOCH [32/200], STEP [41/134]\n",
      "Total Loss G: 0.9848244190216064\n",
      "EPOCH [32/200], STEP [51/134]\n",
      "Total Loss G: 1.0614851713180542\n",
      "EPOCH [32/200], STEP [61/134]\n",
      "Total Loss G: 0.4939497709274292\n",
      "EPOCH [32/200], STEP [71/134]\n",
      "Total Loss G: 0.3467816710472107\n",
      "EPOCH [32/200], STEP [81/134]\n",
      "Total Loss G: 0.8763540983200073\n",
      "EPOCH [32/200], STEP [91/134]\n",
      "Total Loss G: 0.30744630098342896\n",
      "EPOCH [32/200], STEP [101/134]\n",
      "Total Loss G: 0.276179701089859\n",
      "EPOCH [32/200], STEP [111/134]\n",
      "Total Loss G: 0.350231409072876\n",
      "EPOCH [32/200], STEP [121/134]\n",
      "Total Loss G: 0.6925760507583618\n",
      "EPOCH [32/200], STEP [131/134]\n",
      "Total Loss G: 0.46465861797332764\n",
      "EPOCH [32/200], STEP [141/134]\n",
      "Total Loss G: 0.49002933502197266\n",
      "Training time is  0.8275143345197041 mins\n",
      "Valid: 2-shot EPOCH [32/200], STEP [10/33]\n",
      "Total Loss V: 0.964174211025238\n",
      "Valid: 2-shot EPOCH [32/200], STEP [20/33]\n",
      "Total Loss V: 0.8152520656585693\n",
      "Valid: 2-shot EPOCH [32/200], STEP [30/33]\n",
      "Total Loss V: 0.3129771649837494\n",
      "EPOCH [33/200], STEP [11/134]\n",
      "Total Loss G: 1.3624430894851685\n",
      "EPOCH [33/200], STEP [21/134]\n",
      "Total Loss G: 0.8024550080299377\n",
      "EPOCH [33/200], STEP [31/134]\n",
      "Total Loss G: 0.2522265911102295\n",
      "EPOCH [33/200], STEP [41/134]\n",
      "Total Loss G: 0.971878170967102\n",
      "EPOCH [33/200], STEP [51/134]\n",
      "Total Loss G: 1.355130672454834\n",
      "EPOCH [33/200], STEP [61/134]\n",
      "Total Loss G: 0.4037458300590515\n",
      "EPOCH [33/200], STEP [71/134]\n",
      "Total Loss G: 0.32972973585128784\n",
      "EPOCH [33/200], STEP [81/134]\n",
      "Total Loss G: 0.9472973346710205\n",
      "EPOCH [33/200], STEP [91/134]\n",
      "Total Loss G: 0.40498653054237366\n",
      "EPOCH [33/200], STEP [101/134]\n",
      "Total Loss G: 0.31096023321151733\n",
      "EPOCH [33/200], STEP [111/134]\n",
      "Total Loss G: 0.32774466276168823\n",
      "EPOCH [33/200], STEP [121/134]\n",
      "Total Loss G: 0.7234365940093994\n",
      "EPOCH [33/200], STEP [131/134]\n",
      "Total Loss G: 0.45388782024383545\n",
      "EPOCH [33/200], STEP [141/134]\n",
      "Total Loss G: 0.5299261212348938\n",
      "Training time is  0.8262415091196696 mins\n",
      "Valid: 2-shot EPOCH [33/200], STEP [10/33]\n",
      "Total Loss V: 1.009441614151001\n",
      "Valid: 2-shot EPOCH [33/200], STEP [20/33]\n",
      "Total Loss V: 1.0320937633514404\n",
      "Valid: 2-shot EPOCH [33/200], STEP [30/33]\n",
      "Total Loss V: 0.2622779607772827\n",
      "EPOCH [34/200], STEP [11/134]\n",
      "Total Loss G: 1.797985553741455\n",
      "EPOCH [34/200], STEP [21/134]\n",
      "Total Loss G: 0.679975688457489\n",
      "EPOCH [34/200], STEP [31/134]\n",
      "Total Loss G: 0.21965482831001282\n",
      "EPOCH [34/200], STEP [41/134]\n",
      "Total Loss G: 0.9083372950553894\n",
      "EPOCH [34/200], STEP [51/134]\n",
      "Total Loss G: 1.1316190958023071\n",
      "EPOCH [34/200], STEP [61/134]\n",
      "Total Loss G: 0.38745978474617004\n",
      "EPOCH [34/200], STEP [71/134]\n",
      "Total Loss G: 0.2883944809436798\n",
      "EPOCH [34/200], STEP [81/134]\n",
      "Total Loss G: 0.8085390329360962\n",
      "EPOCH [34/200], STEP [91/134]\n",
      "Total Loss G: 0.338603138923645\n",
      "EPOCH [34/200], STEP [101/134]\n",
      "Total Loss G: 0.29668596386909485\n",
      "EPOCH [34/200], STEP [111/134]\n",
      "Total Loss G: 0.3629171848297119\n",
      "EPOCH [34/200], STEP [121/134]\n",
      "Total Loss G: 0.6609073877334595\n",
      "EPOCH [34/200], STEP [131/134]\n",
      "Total Loss G: 0.45354601740837097\n",
      "EPOCH [34/200], STEP [141/134]\n",
      "Total Loss G: 0.5078144073486328\n",
      "Training time is  0.8272387862205506 mins\n",
      "Valid: 2-shot EPOCH [34/200], STEP [10/33]\n",
      "Total Loss V: 1.0479261875152588\n",
      "Valid: 2-shot EPOCH [34/200], STEP [20/33]\n",
      "Total Loss V: 0.8183956146240234\n",
      "Valid: 2-shot EPOCH [34/200], STEP [30/33]\n",
      "Total Loss V: 0.1957072764635086\n",
      "EPOCH [35/200], STEP [11/134]\n",
      "Total Loss G: 1.5559533834457397\n",
      "EPOCH [35/200], STEP [21/134]\n",
      "Total Loss G: 0.6266751289367676\n",
      "EPOCH [35/200], STEP [31/134]\n",
      "Total Loss G: 0.18780264258384705\n",
      "EPOCH [35/200], STEP [41/134]\n",
      "Total Loss G: 0.9714269042015076\n",
      "EPOCH [35/200], STEP [51/134]\n",
      "Total Loss G: 1.0424014329910278\n",
      "EPOCH [35/200], STEP [61/134]\n",
      "Total Loss G: 0.3880709111690521\n",
      "EPOCH [35/200], STEP [71/134]\n",
      "Total Loss G: 0.30513954162597656\n",
      "EPOCH [35/200], STEP [81/134]\n",
      "Total Loss G: 0.8094044327735901\n",
      "EPOCH [35/200], STEP [91/134]\n",
      "Total Loss G: 0.3426267206668854\n",
      "EPOCH [35/200], STEP [101/134]\n",
      "Total Loss G: 0.2868331968784332\n",
      "EPOCH [35/200], STEP [111/134]\n",
      "Total Loss G: 0.44415760040283203\n",
      "EPOCH [35/200], STEP [121/134]\n",
      "Total Loss G: 0.6904097199440002\n",
      "EPOCH [35/200], STEP [131/134]\n",
      "Total Loss G: 0.4620504081249237\n",
      "EPOCH [35/200], STEP [141/134]\n",
      "Total Loss G: 0.4748730957508087\n",
      "Training time is  0.8301809430122375 mins\n",
      "Valid: 2-shot EPOCH [35/200], STEP [10/33]\n",
      "Total Loss V: 0.8804141879081726\n",
      "Valid: 2-shot EPOCH [35/200], STEP [20/33]\n",
      "Total Loss V: 0.6696413159370422\n",
      "Valid: 2-shot EPOCH [35/200], STEP [30/33]\n",
      "Total Loss V: 0.2393048107624054\n",
      "EPOCH [36/200], STEP [11/134]\n",
      "Total Loss G: 2.2406017780303955\n",
      "EPOCH [36/200], STEP [21/134]\n",
      "Total Loss G: 0.7070742845535278\n",
      "EPOCH [36/200], STEP [31/134]\n",
      "Total Loss G: 0.2714109420776367\n",
      "EPOCH [36/200], STEP [41/134]\n",
      "Total Loss G: 0.9861083626747131\n",
      "EPOCH [36/200], STEP [51/134]\n",
      "Total Loss G: 0.845129132270813\n",
      "EPOCH [36/200], STEP [61/134]\n",
      "Total Loss G: 0.3305216133594513\n",
      "EPOCH [36/200], STEP [71/134]\n",
      "Total Loss G: 0.3323169946670532\n",
      "EPOCH [36/200], STEP [81/134]\n",
      "Total Loss G: 0.6907498240470886\n",
      "EPOCH [36/200], STEP [91/134]\n",
      "Total Loss G: 0.5376021265983582\n",
      "EPOCH [36/200], STEP [101/134]\n",
      "Total Loss G: 0.29784727096557617\n",
      "EPOCH [36/200], STEP [111/134]\n",
      "Total Loss G: 0.3746313154697418\n",
      "EPOCH [36/200], STEP [121/134]\n",
      "Total Loss G: 0.6437911987304688\n",
      "EPOCH [36/200], STEP [131/134]\n",
      "Total Loss G: 0.42365097999572754\n",
      "EPOCH [36/200], STEP [141/134]\n",
      "Total Loss G: 0.5294772386550903\n",
      "Training time is  0.8258591969807942 mins\n",
      "Valid: 2-shot EPOCH [36/200], STEP [10/33]\n",
      "Total Loss V: 0.9966357350349426\n",
      "Valid: 2-shot EPOCH [36/200], STEP [20/33]\n",
      "Total Loss V: 0.6413124203681946\n",
      "Valid: 2-shot EPOCH [36/200], STEP [30/33]\n",
      "Total Loss V: 0.2662060558795929\n",
      "EPOCH [37/200], STEP [11/134]\n",
      "Total Loss G: 1.3989378213882446\n",
      "EPOCH [37/200], STEP [21/134]\n",
      "Total Loss G: 0.6469331979751587\n",
      "EPOCH [37/200], STEP [31/134]\n",
      "Total Loss G: 0.4174763560295105\n",
      "EPOCH [37/200], STEP [41/134]\n",
      "Total Loss G: 1.0288411378860474\n",
      "EPOCH [37/200], STEP [51/134]\n",
      "Total Loss G: 0.7776795625686646\n",
      "EPOCH [37/200], STEP [61/134]\n",
      "Total Loss G: 0.5755886435508728\n",
      "EPOCH [37/200], STEP [71/134]\n",
      "Total Loss G: 0.3114584982395172\n",
      "EPOCH [37/200], STEP [81/134]\n",
      "Total Loss G: 0.8456169962882996\n",
      "EPOCH [37/200], STEP [91/134]\n",
      "Total Loss G: 0.3790958523750305\n",
      "EPOCH [37/200], STEP [101/134]\n",
      "Total Loss G: 0.32945722341537476\n",
      "EPOCH [37/200], STEP [111/134]\n",
      "Total Loss G: 0.34194207191467285\n",
      "EPOCH [37/200], STEP [121/134]\n",
      "Total Loss G: 0.6499014496803284\n",
      "EPOCH [37/200], STEP [131/134]\n",
      "Total Loss G: 0.4487711191177368\n",
      "EPOCH [37/200], STEP [141/134]\n",
      "Total Loss G: 0.3716740310192108\n",
      "Training time is  0.8240626136461894 mins\n",
      "Valid: 2-shot EPOCH [37/200], STEP [10/33]\n",
      "Total Loss V: 0.8812687397003174\n",
      "Valid: 2-shot EPOCH [37/200], STEP [20/33]\n",
      "Total Loss V: 0.6105989813804626\n",
      "Valid: 2-shot EPOCH [37/200], STEP [30/33]\n",
      "Total Loss V: 0.26241523027420044\n",
      "EPOCH [38/200], STEP [11/134]\n",
      "Total Loss G: 1.1876006126403809\n",
      "EPOCH [38/200], STEP [21/134]\n",
      "Total Loss G: 0.6977240443229675\n",
      "EPOCH [38/200], STEP [31/134]\n",
      "Total Loss G: 0.6033489108085632\n",
      "EPOCH [38/200], STEP [41/134]\n",
      "Total Loss G: 1.1519179344177246\n",
      "EPOCH [38/200], STEP [51/134]\n",
      "Total Loss G: 1.00899076461792\n",
      "EPOCH [38/200], STEP [61/134]\n",
      "Total Loss G: 0.40278834104537964\n",
      "EPOCH [38/200], STEP [71/134]\n",
      "Total Loss G: 0.4088408350944519\n",
      "EPOCH [38/200], STEP [81/134]\n",
      "Total Loss G: 1.161303162574768\n",
      "EPOCH [38/200], STEP [91/134]\n",
      "Total Loss G: 0.3832366466522217\n",
      "EPOCH [38/200], STEP [101/134]\n",
      "Total Loss G: 0.3144111633300781\n",
      "EPOCH [38/200], STEP [111/134]\n",
      "Total Loss G: 0.30818459391593933\n",
      "EPOCH [38/200], STEP [121/134]\n",
      "Total Loss G: 0.8373359441757202\n",
      "EPOCH [38/200], STEP [131/134]\n",
      "Total Loss G: 0.4294242858886719\n",
      "EPOCH [38/200], STEP [141/134]\n",
      "Total Loss G: 0.5389142632484436\n",
      "Training time is  0.8225431760152181 mins\n",
      "Valid: 2-shot EPOCH [38/200], STEP [10/33]\n",
      "Total Loss V: 1.1012239456176758\n",
      "Valid: 2-shot EPOCH [38/200], STEP [20/33]\n",
      "Total Loss V: 1.1481934785842896\n",
      "Valid: 2-shot EPOCH [38/200], STEP [30/33]\n",
      "Total Loss V: 0.26309287548065186\n",
      "EPOCH [39/200], STEP [11/134]\n",
      "Total Loss G: 1.0075832605361938\n",
      "EPOCH [39/200], STEP [21/134]\n",
      "Total Loss G: 0.7889710068702698\n",
      "EPOCH [39/200], STEP [31/134]\n",
      "Total Loss G: 0.2394123375415802\n",
      "EPOCH [39/200], STEP [41/134]\n",
      "Total Loss G: 0.9780999422073364\n",
      "EPOCH [39/200], STEP [51/134]\n",
      "Total Loss G: 0.9283641576766968\n",
      "EPOCH [39/200], STEP [61/134]\n",
      "Total Loss G: 0.39010369777679443\n",
      "EPOCH [39/200], STEP [71/134]\n",
      "Total Loss G: 0.46045494079589844\n",
      "EPOCH [39/200], STEP [81/134]\n",
      "Total Loss G: 0.5003759264945984\n",
      "EPOCH [39/200], STEP [91/134]\n",
      "Total Loss G: 0.34894588589668274\n",
      "EPOCH [39/200], STEP [101/134]\n",
      "Total Loss G: 0.3544882833957672\n",
      "EPOCH [39/200], STEP [111/134]\n",
      "Total Loss G: 0.3842414617538452\n",
      "EPOCH [39/200], STEP [121/134]\n",
      "Total Loss G: 0.7261715531349182\n",
      "EPOCH [39/200], STEP [131/134]\n",
      "Total Loss G: 0.4162657558917999\n",
      "EPOCH [39/200], STEP [141/134]\n",
      "Total Loss G: 0.3725234866142273\n",
      "Training time is  0.82399795850118 mins\n",
      "Valid: 2-shot EPOCH [39/200], STEP [10/33]\n",
      "Total Loss V: 0.5660648345947266\n",
      "Valid: 2-shot EPOCH [39/200], STEP [20/33]\n",
      "Total Loss V: 0.7811601758003235\n",
      "Valid: 2-shot EPOCH [39/200], STEP [30/33]\n",
      "Total Loss V: 0.25859561562538147\n",
      "EPOCH [40/200], STEP [11/134]\n",
      "Total Loss G: 1.359004259109497\n",
      "EPOCH [40/200], STEP [21/134]\n",
      "Total Loss G: 0.5681392550468445\n",
      "EPOCH [40/200], STEP [31/134]\n",
      "Total Loss G: 0.322866827249527\n",
      "EPOCH [40/200], STEP [41/134]\n",
      "Total Loss G: 1.0747528076171875\n",
      "EPOCH [40/200], STEP [51/134]\n",
      "Total Loss G: 0.7129335999488831\n",
      "EPOCH [40/200], STEP [61/134]\n",
      "Total Loss G: 0.3414559066295624\n",
      "EPOCH [40/200], STEP [71/134]\n",
      "Total Loss G: 0.6051661372184753\n",
      "EPOCH [40/200], STEP [81/134]\n",
      "Total Loss G: 0.8367039561271667\n",
      "EPOCH [40/200], STEP [91/134]\n",
      "Total Loss G: 0.2772539258003235\n",
      "EPOCH [40/200], STEP [101/134]\n",
      "Total Loss G: 0.34549587965011597\n",
      "EPOCH [40/200], STEP [111/134]\n",
      "Total Loss G: 0.27424001693725586\n",
      "EPOCH [40/200], STEP [121/134]\n",
      "Total Loss G: 0.6765515208244324\n",
      "EPOCH [40/200], STEP [131/134]\n",
      "Total Loss G: 0.4662960469722748\n",
      "EPOCH [40/200], STEP [141/134]\n",
      "Total Loss G: 0.31448113918304443\n",
      "Training time is  0.8210885604222615 mins\n",
      "Valid: 2-shot EPOCH [40/200], STEP [10/33]\n",
      "Total Loss V: 0.5709843635559082\n",
      "Valid: 2-shot EPOCH [40/200], STEP [20/33]\n",
      "Total Loss V: 0.6412600874900818\n",
      "Valid: 2-shot EPOCH [40/200], STEP [30/33]\n",
      "Total Loss V: 0.18925102055072784\n",
      "EPOCH [41/200], STEP [11/134]\n",
      "Total Loss G: 1.565874695777893\n",
      "EPOCH [41/200], STEP [21/134]\n",
      "Total Loss G: 0.7789364457130432\n",
      "EPOCH [41/200], STEP [31/134]\n",
      "Total Loss G: 0.35021957755088806\n",
      "EPOCH [41/200], STEP [41/134]\n",
      "Total Loss G: 1.1504530906677246\n",
      "EPOCH [41/200], STEP [51/134]\n",
      "Total Loss G: 0.8026801347732544\n",
      "EPOCH [41/200], STEP [61/134]\n",
      "Total Loss G: 0.32911956310272217\n",
      "EPOCH [41/200], STEP [71/134]\n",
      "Total Loss G: 0.7429805994033813\n",
      "EPOCH [41/200], STEP [81/134]\n",
      "Total Loss G: 0.6403709650039673\n",
      "EPOCH [41/200], STEP [91/134]\n",
      "Total Loss G: 0.22770163416862488\n",
      "EPOCH [41/200], STEP [101/134]\n",
      "Total Loss G: 0.3659839332103729\n",
      "EPOCH [41/200], STEP [111/134]\n",
      "Total Loss G: 0.33938366174697876\n",
      "EPOCH [41/200], STEP [121/134]\n",
      "Total Loss G: 0.729763925075531\n",
      "EPOCH [41/200], STEP [131/134]\n",
      "Total Loss G: 0.47474992275238037\n",
      "EPOCH [41/200], STEP [141/134]\n",
      "Total Loss G: 0.3884715139865875\n",
      "Training time is  0.8243631958961487 mins\n",
      "Valid: 2-shot EPOCH [41/200], STEP [10/33]\n",
      "Total Loss V: 0.6559397578239441\n",
      "Valid: 2-shot EPOCH [41/200], STEP [20/33]\n",
      "Total Loss V: 0.7130361795425415\n",
      "Valid: 2-shot EPOCH [41/200], STEP [30/33]\n",
      "Total Loss V: 0.1909479796886444\n",
      "EPOCH [42/200], STEP [11/134]\n",
      "Total Loss G: 0.712661623954773\n",
      "EPOCH [42/200], STEP [21/134]\n",
      "Total Loss G: 0.7198619246482849\n",
      "EPOCH [42/200], STEP [31/134]\n",
      "Total Loss G: 0.3666808605194092\n",
      "EPOCH [42/200], STEP [41/134]\n",
      "Total Loss G: 1.0185775756835938\n",
      "EPOCH [42/200], STEP [51/134]\n",
      "Total Loss G: 0.8834786415100098\n",
      "EPOCH [42/200], STEP [61/134]\n",
      "Total Loss G: 0.3709615468978882\n",
      "EPOCH [42/200], STEP [71/134]\n",
      "Total Loss G: 0.5237488150596619\n",
      "EPOCH [42/200], STEP [81/134]\n",
      "Total Loss G: 0.46629396080970764\n",
      "EPOCH [42/200], STEP [91/134]\n",
      "Total Loss G: 0.3389919400215149\n",
      "EPOCH [42/200], STEP [101/134]\n",
      "Total Loss G: 0.3005876839160919\n",
      "EPOCH [42/200], STEP [111/134]\n",
      "Total Loss G: 0.2766711115837097\n",
      "EPOCH [42/200], STEP [121/134]\n",
      "Total Loss G: 0.8509541153907776\n",
      "EPOCH [42/200], STEP [131/134]\n",
      "Total Loss G: 0.5273081660270691\n",
      "EPOCH [42/200], STEP [141/134]\n",
      "Total Loss G: 0.4323961138725281\n",
      "Training time is  0.8267844359079997 mins\n",
      "Valid: 2-shot EPOCH [42/200], STEP [10/33]\n",
      "Total Loss V: 0.8397203683853149\n",
      "Valid: 2-shot EPOCH [42/200], STEP [20/33]\n",
      "Total Loss V: 0.5614976286888123\n",
      "Valid: 2-shot EPOCH [42/200], STEP [30/33]\n",
      "Total Loss V: 0.37862783670425415\n",
      "EPOCH [43/200], STEP [11/134]\n",
      "Total Loss G: 0.7421970367431641\n",
      "EPOCH [43/200], STEP [21/134]\n",
      "Total Loss G: 0.6863106489181519\n",
      "EPOCH [43/200], STEP [31/134]\n",
      "Total Loss G: 0.39154252409935\n",
      "EPOCH [43/200], STEP [41/134]\n",
      "Total Loss G: 1.0310269594192505\n",
      "EPOCH [43/200], STEP [51/134]\n",
      "Total Loss G: 0.8575963377952576\n",
      "EPOCH [43/200], STEP [61/134]\n",
      "Total Loss G: 0.454824298620224\n",
      "EPOCH [43/200], STEP [71/134]\n",
      "Total Loss G: 0.4071256220340729\n",
      "EPOCH [43/200], STEP [81/134]\n",
      "Total Loss G: 0.7365116477012634\n",
      "EPOCH [43/200], STEP [91/134]\n",
      "Total Loss G: 0.23261278867721558\n",
      "EPOCH [43/200], STEP [101/134]\n",
      "Total Loss G: 0.3336169421672821\n",
      "EPOCH [43/200], STEP [111/134]\n",
      "Total Loss G: 0.36840343475341797\n",
      "EPOCH [43/200], STEP [121/134]\n",
      "Total Loss G: 0.6526122093200684\n",
      "EPOCH [43/200], STEP [131/134]\n",
      "Total Loss G: 0.5047956705093384\n",
      "EPOCH [43/200], STEP [141/134]\n",
      "Total Loss G: 0.35078227519989014\n",
      "Training time is  0.8255129456520081 mins\n",
      "Valid: 2-shot EPOCH [43/200], STEP [10/33]\n",
      "Total Loss V: 0.6288385987281799\n",
      "Valid: 2-shot EPOCH [43/200], STEP [20/33]\n",
      "Total Loss V: 0.49981310963630676\n",
      "Valid: 2-shot EPOCH [43/200], STEP [30/33]\n",
      "Total Loss V: 0.24502427875995636\n",
      "EPOCH [44/200], STEP [11/134]\n",
      "Total Loss G: 0.6339711546897888\n",
      "EPOCH [44/200], STEP [21/134]\n",
      "Total Loss G: 0.6488673090934753\n",
      "EPOCH [44/200], STEP [31/134]\n",
      "Total Loss G: 0.28280743956565857\n",
      "EPOCH [44/200], STEP [41/134]\n",
      "Total Loss G: 0.9659640789031982\n",
      "EPOCH [44/200], STEP [51/134]\n",
      "Total Loss G: 0.7602986693382263\n",
      "EPOCH [44/200], STEP [61/134]\n",
      "Total Loss G: 0.36879897117614746\n",
      "EPOCH [44/200], STEP [71/134]\n",
      "Total Loss G: 0.5467621088027954\n",
      "EPOCH [44/200], STEP [81/134]\n",
      "Total Loss G: 0.43089115619659424\n",
      "EPOCH [44/200], STEP [91/134]\n",
      "Total Loss G: 0.3087107539176941\n",
      "EPOCH [44/200], STEP [101/134]\n",
      "Total Loss G: 0.3729507029056549\n",
      "EPOCH [44/200], STEP [111/134]\n",
      "Total Loss G: 0.256740927696228\n",
      "EPOCH [44/200], STEP [121/134]\n",
      "Total Loss G: 0.6671581864356995\n",
      "EPOCH [44/200], STEP [131/134]\n",
      "Total Loss G: 0.4073942303657532\n",
      "EPOCH [44/200], STEP [141/134]\n",
      "Total Loss G: 0.3248693346977234\n",
      "Training time is  0.8234655419985454 mins\n",
      "Valid: 2-shot EPOCH [44/200], STEP [10/33]\n",
      "Total Loss V: 0.7232436537742615\n",
      "Valid: 2-shot EPOCH [44/200], STEP [20/33]\n",
      "Total Loss V: 0.5112512111663818\n",
      "Valid: 2-shot EPOCH [44/200], STEP [30/33]\n",
      "Total Loss V: 0.22048671543598175\n",
      "EPOCH [45/200], STEP [11/134]\n",
      "Total Loss G: 0.7782310843467712\n",
      "EPOCH [45/200], STEP [21/134]\n",
      "Total Loss G: 0.5972334742546082\n",
      "EPOCH [45/200], STEP [31/134]\n",
      "Total Loss G: 0.26956748962402344\n",
      "EPOCH [45/200], STEP [41/134]\n",
      "Total Loss G: 0.8918740153312683\n",
      "EPOCH [45/200], STEP [51/134]\n",
      "Total Loss G: 0.8665604591369629\n",
      "EPOCH [45/200], STEP [61/134]\n",
      "Total Loss G: 0.42588892579078674\n",
      "EPOCH [45/200], STEP [71/134]\n",
      "Total Loss G: 0.6788845062255859\n",
      "EPOCH [45/200], STEP [81/134]\n",
      "Total Loss G: 0.3174703121185303\n",
      "EPOCH [45/200], STEP [91/134]\n",
      "Total Loss G: 0.21707302331924438\n",
      "EPOCH [45/200], STEP [101/134]\n",
      "Total Loss G: 0.3769857585430145\n",
      "EPOCH [45/200], STEP [111/134]\n",
      "Total Loss G: 0.33886945247650146\n",
      "EPOCH [45/200], STEP [121/134]\n",
      "Total Loss G: 0.6389925479888916\n",
      "EPOCH [45/200], STEP [131/134]\n",
      "Total Loss G: 0.3971942067146301\n",
      "EPOCH [45/200], STEP [141/134]\n",
      "Total Loss G: 0.348357617855072\n",
      "Training time is  0.8277873635292053 mins\n",
      "Valid: 2-shot EPOCH [45/200], STEP [10/33]\n",
      "Total Loss V: 0.7233447432518005\n",
      "Valid: 2-shot EPOCH [45/200], STEP [20/33]\n",
      "Total Loss V: 0.56651371717453\n",
      "Valid: 2-shot EPOCH [45/200], STEP [30/33]\n",
      "Total Loss V: 0.25191530585289\n",
      "EPOCH [46/200], STEP [11/134]\n",
      "Total Loss G: 0.8083756566047668\n",
      "EPOCH [46/200], STEP [21/134]\n",
      "Total Loss G: 0.6438519358634949\n",
      "EPOCH [46/200], STEP [31/134]\n",
      "Total Loss G: 0.24679072201251984\n",
      "EPOCH [46/200], STEP [41/134]\n",
      "Total Loss G: 1.0059722661972046\n",
      "EPOCH [46/200], STEP [51/134]\n",
      "Total Loss G: 0.7945249676704407\n",
      "EPOCH [46/200], STEP [61/134]\n",
      "Total Loss G: 0.3127818703651428\n",
      "EPOCH [46/200], STEP [71/134]\n",
      "Total Loss G: 0.6562060117721558\n",
      "EPOCH [46/200], STEP [81/134]\n",
      "Total Loss G: 0.47274914383888245\n",
      "EPOCH [46/200], STEP [91/134]\n",
      "Total Loss G: 0.36541905999183655\n",
      "EPOCH [46/200], STEP [101/134]\n",
      "Total Loss G: 0.40695011615753174\n",
      "EPOCH [46/200], STEP [111/134]\n",
      "Total Loss G: 0.2779727280139923\n",
      "EPOCH [46/200], STEP [121/134]\n",
      "Total Loss G: 0.6794830560684204\n",
      "EPOCH [46/200], STEP [131/134]\n",
      "Total Loss G: 0.3987082540988922\n",
      "EPOCH [46/200], STEP [141/134]\n",
      "Total Loss G: 0.3521674871444702\n",
      "Training time is  0.83480224609375 mins\n",
      "Valid: 2-shot EPOCH [46/200], STEP [10/33]\n",
      "Total Loss V: 0.6408597826957703\n",
      "Valid: 2-shot EPOCH [46/200], STEP [20/33]\n",
      "Total Loss V: 0.7692444920539856\n",
      "Valid: 2-shot EPOCH [46/200], STEP [30/33]\n",
      "Total Loss V: 0.261642724275589\n",
      "EPOCH [47/200], STEP [11/134]\n",
      "Total Loss G: 0.9046708941459656\n",
      "EPOCH [47/200], STEP [21/134]\n",
      "Total Loss G: 0.8015787601470947\n",
      "EPOCH [47/200], STEP [31/134]\n",
      "Total Loss G: 0.24975092709064484\n",
      "EPOCH [47/200], STEP [41/134]\n",
      "Total Loss G: 0.7855011224746704\n",
      "EPOCH [47/200], STEP [51/134]\n",
      "Total Loss G: 0.6822471618652344\n",
      "EPOCH [47/200], STEP [61/134]\n",
      "Total Loss G: 0.41217485070228577\n",
      "EPOCH [47/200], STEP [71/134]\n",
      "Total Loss G: 0.4583195149898529\n",
      "EPOCH [47/200], STEP [81/134]\n",
      "Total Loss G: 0.6084333658218384\n",
      "EPOCH [47/200], STEP [91/134]\n",
      "Total Loss G: 0.22259342670440674\n",
      "EPOCH [47/200], STEP [101/134]\n",
      "Total Loss G: 0.3356218934059143\n",
      "EPOCH [47/200], STEP [111/134]\n",
      "Total Loss G: 0.40383872389793396\n",
      "EPOCH [47/200], STEP [121/134]\n",
      "Total Loss G: 0.7539607286453247\n",
      "EPOCH [47/200], STEP [131/134]\n",
      "Total Loss G: 0.462868332862854\n",
      "EPOCH [47/200], STEP [141/134]\n",
      "Total Loss G: 0.30487391352653503\n",
      "Training time is  0.8245211442311605 mins\n",
      "Valid: 2-shot EPOCH [47/200], STEP [10/33]\n",
      "Total Loss V: 0.6378902792930603\n",
      "Valid: 2-shot EPOCH [47/200], STEP [20/33]\n",
      "Total Loss V: 0.5510004758834839\n",
      "Valid: 2-shot EPOCH [47/200], STEP [30/33]\n",
      "Total Loss V: 0.24767930805683136\n",
      "EPOCH [48/200], STEP [11/134]\n",
      "Total Loss G: 0.5304319858551025\n",
      "EPOCH [48/200], STEP [21/134]\n",
      "Total Loss G: 0.5249655246734619\n",
      "EPOCH [48/200], STEP [31/134]\n",
      "Total Loss G: 0.2712915539741516\n",
      "EPOCH [48/200], STEP [41/134]\n",
      "Total Loss G: 0.8817073106765747\n",
      "EPOCH [48/200], STEP [51/134]\n",
      "Total Loss G: 0.854500949382782\n",
      "EPOCH [48/200], STEP [61/134]\n",
      "Total Loss G: 0.40906208753585815\n",
      "EPOCH [48/200], STEP [71/134]\n",
      "Total Loss G: 0.33205845952033997\n",
      "EPOCH [48/200], STEP [81/134]\n",
      "Total Loss G: 0.38755926489830017\n",
      "EPOCH [48/200], STEP [91/134]\n",
      "Total Loss G: 0.32681161165237427\n",
      "EPOCH [48/200], STEP [101/134]\n",
      "Total Loss G: 0.2580091953277588\n",
      "EPOCH [48/200], STEP [111/134]\n",
      "Total Loss G: 0.2279830127954483\n",
      "EPOCH [48/200], STEP [121/134]\n",
      "Total Loss G: 0.6826631426811218\n",
      "EPOCH [48/200], STEP [131/134]\n",
      "Total Loss G: 0.43836358189582825\n",
      "EPOCH [48/200], STEP [141/134]\n",
      "Total Loss G: 0.23859372735023499\n",
      "Training time is  0.8278371930122376 mins\n",
      "Valid: 2-shot EPOCH [48/200], STEP [10/33]\n",
      "Total Loss V: 0.5169056057929993\n",
      "Valid: 2-shot EPOCH [48/200], STEP [20/33]\n",
      "Total Loss V: 0.5577149987220764\n",
      "Valid: 2-shot EPOCH [48/200], STEP [30/33]\n",
      "Total Loss V: 0.17857536673545837\n",
      "EPOCH [49/200], STEP [11/134]\n",
      "Total Loss G: 0.6417466998100281\n",
      "EPOCH [49/200], STEP [21/134]\n",
      "Total Loss G: 0.5130466222763062\n",
      "EPOCH [49/200], STEP [31/134]\n",
      "Total Loss G: 0.17401471734046936\n",
      "EPOCH [49/200], STEP [41/134]\n",
      "Total Loss G: 0.9336417317390442\n",
      "EPOCH [49/200], STEP [51/134]\n",
      "Total Loss G: 0.750135064125061\n",
      "EPOCH [49/200], STEP [61/134]\n",
      "Total Loss G: 0.39755961298942566\n",
      "EPOCH [49/200], STEP [71/134]\n",
      "Total Loss G: 0.3662845194339752\n",
      "EPOCH [49/200], STEP [81/134]\n",
      "Total Loss G: 0.2408793717622757\n",
      "EPOCH [49/200], STEP [91/134]\n",
      "Total Loss G: 0.30255377292633057\n",
      "EPOCH [49/200], STEP [101/134]\n",
      "Total Loss G: 0.2901748716831207\n",
      "EPOCH [49/200], STEP [111/134]\n",
      "Total Loss G: 0.3027612864971161\n",
      "EPOCH [49/200], STEP [121/134]\n",
      "Total Loss G: 0.6749267578125\n",
      "EPOCH [49/200], STEP [131/134]\n",
      "Total Loss G: 0.461288183927536\n",
      "EPOCH [49/200], STEP [141/134]\n",
      "Total Loss G: 0.2827177047729492\n",
      "Training time is  0.8297321200370789 mins\n",
      "Valid: 2-shot EPOCH [49/200], STEP [10/33]\n",
      "Total Loss V: 0.5656129121780396\n",
      "Valid: 2-shot EPOCH [49/200], STEP [20/33]\n",
      "Total Loss V: 0.8063902258872986\n",
      "Valid: 2-shot EPOCH [49/200], STEP [30/33]\n",
      "Total Loss V: 0.3042505085468292\n",
      "EPOCH [50/200], STEP [11/134]\n",
      "Total Loss G: 0.5836249589920044\n",
      "EPOCH [50/200], STEP [21/134]\n",
      "Total Loss G: 0.5100584626197815\n",
      "EPOCH [50/200], STEP [31/134]\n",
      "Total Loss G: 0.3517128527164459\n",
      "EPOCH [50/200], STEP [41/134]\n",
      "Total Loss G: 1.0082311630249023\n",
      "EPOCH [50/200], STEP [51/134]\n",
      "Total Loss G: 0.6448376178741455\n",
      "EPOCH [50/200], STEP [61/134]\n",
      "Total Loss G: 0.3051811456680298\n",
      "EPOCH [50/200], STEP [71/134]\n",
      "Total Loss G: 0.5256202220916748\n",
      "EPOCH [50/200], STEP [81/134]\n",
      "Total Loss G: 0.30352193117141724\n",
      "EPOCH [50/200], STEP [91/134]\n",
      "Total Loss G: 0.26390790939331055\n",
      "EPOCH [50/200], STEP [101/134]\n",
      "Total Loss G: 0.33754223585128784\n",
      "EPOCH [50/200], STEP [111/134]\n",
      "Total Loss G: 0.24546681344509125\n",
      "EPOCH [50/200], STEP [121/134]\n",
      "Total Loss G: 0.6910816431045532\n",
      "EPOCH [50/200], STEP [131/134]\n",
      "Total Loss G: 0.4170682728290558\n",
      "EPOCH [50/200], STEP [141/134]\n",
      "Total Loss G: 0.2697310447692871\n",
      "Training time is  0.8510660290718078 mins\n",
      "Valid: 2-shot EPOCH [50/200], STEP [10/33]\n",
      "Total Loss V: 0.44518330693244934\n",
      "Valid: 2-shot EPOCH [50/200], STEP [20/33]\n",
      "Total Loss V: 0.6325964331626892\n",
      "Valid: 2-shot EPOCH [50/200], STEP [30/33]\n",
      "Total Loss V: 0.15804260969161987\n",
      "EPOCH [51/200], STEP [11/134]\n",
      "Total Loss G: 0.6876543164253235\n",
      "EPOCH [51/200], STEP [21/134]\n",
      "Total Loss G: 0.4181491434574127\n",
      "EPOCH [51/200], STEP [31/134]\n",
      "Total Loss G: 0.21232236921787262\n",
      "EPOCH [51/200], STEP [41/134]\n",
      "Total Loss G: 0.9197601675987244\n",
      "EPOCH [51/200], STEP [51/134]\n",
      "Total Loss G: 0.5032093524932861\n",
      "EPOCH [51/200], STEP [61/134]\n",
      "Total Loss G: 0.3819883465766907\n",
      "EPOCH [51/200], STEP [71/134]\n",
      "Total Loss G: 0.21956302225589752\n",
      "EPOCH [51/200], STEP [81/134]\n",
      "Total Loss G: 0.541694700717926\n",
      "EPOCH [51/200], STEP [91/134]\n",
      "Total Loss G: 0.2851884961128235\n",
      "EPOCH [51/200], STEP [101/134]\n",
      "Total Loss G: 0.32126671075820923\n",
      "EPOCH [51/200], STEP [111/134]\n",
      "Total Loss G: 0.26310524344444275\n",
      "EPOCH [51/200], STEP [121/134]\n",
      "Total Loss G: 0.6375791430473328\n",
      "EPOCH [51/200], STEP [131/134]\n",
      "Total Loss G: 0.5042562484741211\n",
      "EPOCH [51/200], STEP [141/134]\n",
      "Total Loss G: 0.2157425731420517\n",
      "Training time is  0.8359596172968546 mins\n",
      "Valid: 2-shot EPOCH [51/200], STEP [10/33]\n",
      "Total Loss V: 0.4169907569885254\n",
      "Valid: 2-shot EPOCH [51/200], STEP [20/33]\n",
      "Total Loss V: 0.6452609300613403\n",
      "Valid: 2-shot EPOCH [51/200], STEP [30/33]\n",
      "Total Loss V: 0.21303094923496246\n",
      "EPOCH [52/200], STEP [11/134]\n",
      "Total Loss G: 0.539794921875\n",
      "EPOCH [52/200], STEP [21/134]\n",
      "Total Loss G: 0.7407666444778442\n",
      "EPOCH [52/200], STEP [31/134]\n",
      "Total Loss G: 0.17981353402137756\n",
      "EPOCH [52/200], STEP [41/134]\n",
      "Total Loss G: 0.854489803314209\n",
      "EPOCH [52/200], STEP [51/134]\n",
      "Total Loss G: 0.679707407951355\n",
      "EPOCH [52/200], STEP [61/134]\n",
      "Total Loss G: 0.28411903977394104\n",
      "EPOCH [52/200], STEP [71/134]\n",
      "Total Loss G: 0.8619192838668823\n",
      "EPOCH [52/200], STEP [81/134]\n",
      "Total Loss G: 0.6239096522331238\n",
      "EPOCH [52/200], STEP [91/134]\n",
      "Total Loss G: 0.2800087630748749\n",
      "EPOCH [52/200], STEP [101/134]\n",
      "Total Loss G: 0.3027534782886505\n",
      "EPOCH [52/200], STEP [111/134]\n",
      "Total Loss G: 0.21606974303722382\n",
      "EPOCH [52/200], STEP [121/134]\n",
      "Total Loss G: 0.6490925550460815\n",
      "EPOCH [52/200], STEP [131/134]\n",
      "Total Loss G: 0.5563681721687317\n",
      "EPOCH [52/200], STEP [141/134]\n",
      "Total Loss G: 0.23386280238628387\n",
      "Training time is  0.8317355275154114 mins\n",
      "Valid: 2-shot EPOCH [52/200], STEP [10/33]\n",
      "Total Loss V: 0.38962823152542114\n",
      "Valid: 2-shot EPOCH [52/200], STEP [20/33]\n",
      "Total Loss V: 0.6942621469497681\n",
      "Valid: 2-shot EPOCH [52/200], STEP [30/33]\n",
      "Total Loss V: 0.19694945216178894\n",
      "EPOCH [53/200], STEP [11/134]\n",
      "Total Loss G: 0.482235312461853\n",
      "EPOCH [53/200], STEP [21/134]\n",
      "Total Loss G: 0.5526968240737915\n",
      "EPOCH [53/200], STEP [31/134]\n",
      "Total Loss G: 0.2628127634525299\n",
      "EPOCH [53/200], STEP [41/134]\n",
      "Total Loss G: 0.9929214715957642\n",
      "EPOCH [53/200], STEP [51/134]\n",
      "Total Loss G: 0.7723134756088257\n",
      "EPOCH [53/200], STEP [61/134]\n",
      "Total Loss G: 0.2681708037853241\n",
      "EPOCH [53/200], STEP [71/134]\n",
      "Total Loss G: 0.7054772973060608\n",
      "EPOCH [53/200], STEP [81/134]\n",
      "Total Loss G: 0.2680225968360901\n",
      "EPOCH [53/200], STEP [91/134]\n",
      "Total Loss G: 0.2718685269355774\n",
      "EPOCH [53/200], STEP [101/134]\n",
      "Total Loss G: 0.4065476953983307\n",
      "EPOCH [53/200], STEP [111/134]\n",
      "Total Loss G: 0.22894106805324554\n",
      "EPOCH [53/200], STEP [121/134]\n",
      "Total Loss G: 0.6450039744377136\n",
      "EPOCH [53/200], STEP [131/134]\n",
      "Total Loss G: 0.48174700140953064\n",
      "EPOCH [53/200], STEP [141/134]\n",
      "Total Loss G: 0.27705055475234985\n",
      "Training time is  0.8331271966298421 mins\n",
      "Valid: 2-shot EPOCH [53/200], STEP [10/33]\n",
      "Total Loss V: 0.4384239912033081\n",
      "Valid: 2-shot EPOCH [53/200], STEP [20/33]\n",
      "Total Loss V: 0.5884037613868713\n",
      "Valid: 2-shot EPOCH [53/200], STEP [30/33]\n",
      "Total Loss V: 0.1449628323316574\n",
      "EPOCH [54/200], STEP [11/134]\n",
      "Total Loss G: 0.5687119364738464\n",
      "EPOCH [54/200], STEP [21/134]\n",
      "Total Loss G: 0.581869900226593\n",
      "EPOCH [54/200], STEP [31/134]\n",
      "Total Loss G: 0.28687313199043274\n",
      "EPOCH [54/200], STEP [41/134]\n",
      "Total Loss G: 0.896155834197998\n",
      "EPOCH [54/200], STEP [51/134]\n",
      "Total Loss G: 0.5978028178215027\n",
      "EPOCH [54/200], STEP [61/134]\n",
      "Total Loss G: 0.33480554819107056\n",
      "EPOCH [54/200], STEP [71/134]\n",
      "Total Loss G: 0.44235309958457947\n",
      "EPOCH [54/200], STEP [81/134]\n",
      "Total Loss G: 0.4577401280403137\n",
      "EPOCH [54/200], STEP [91/134]\n",
      "Total Loss G: 0.3223772943019867\n",
      "EPOCH [54/200], STEP [101/134]\n",
      "Total Loss G: 0.41395270824432373\n",
      "EPOCH [54/200], STEP [111/134]\n",
      "Total Loss G: 0.23522111773490906\n",
      "EPOCH [54/200], STEP [121/134]\n",
      "Total Loss G: 0.6319996118545532\n",
      "EPOCH [54/200], STEP [131/134]\n",
      "Total Loss G: 0.6843276023864746\n",
      "EPOCH [54/200], STEP [141/134]\n",
      "Total Loss G: 0.23215153813362122\n",
      "Training time is  0.8334288477897644 mins\n",
      "Valid: 2-shot EPOCH [54/200], STEP [10/33]\n",
      "Total Loss V: 0.33785733580589294\n",
      "Valid: 2-shot EPOCH [54/200], STEP [20/33]\n",
      "Total Loss V: 0.6230975389480591\n",
      "Valid: 2-shot EPOCH [54/200], STEP [30/33]\n",
      "Total Loss V: 0.3763265311717987\n",
      "EPOCH [55/200], STEP [11/134]\n",
      "Total Loss G: 0.5647069215774536\n",
      "EPOCH [55/200], STEP [21/134]\n",
      "Total Loss G: 0.4579687714576721\n",
      "EPOCH [55/200], STEP [31/134]\n",
      "Total Loss G: 0.34310176968574524\n",
      "EPOCH [55/200], STEP [41/134]\n",
      "Total Loss G: 0.9342057108879089\n",
      "EPOCH [55/200], STEP [51/134]\n",
      "Total Loss G: 0.6772317290306091\n",
      "EPOCH [55/200], STEP [61/134]\n",
      "Total Loss G: 0.25148311257362366\n",
      "EPOCH [55/200], STEP [71/134]\n",
      "Total Loss G: 0.7671165466308594\n",
      "EPOCH [55/200], STEP [81/134]\n",
      "Total Loss G: 0.4801391363143921\n",
      "EPOCH [55/200], STEP [91/134]\n",
      "Total Loss G: 0.31778186559677124\n",
      "EPOCH [55/200], STEP [101/134]\n",
      "Total Loss G: 0.3950274586677551\n",
      "EPOCH [55/200], STEP [111/134]\n",
      "Total Loss G: 0.2187655121088028\n",
      "EPOCH [55/200], STEP [121/134]\n",
      "Total Loss G: 0.6268203258514404\n",
      "EPOCH [55/200], STEP [131/134]\n",
      "Total Loss G: 0.4387698173522949\n",
      "EPOCH [55/200], STEP [141/134]\n",
      "Total Loss G: 0.23874850571155548\n",
      "Training time is  0.8284424146016439 mins\n",
      "Valid: 2-shot EPOCH [55/200], STEP [10/33]\n",
      "Total Loss V: 0.4318123161792755\n",
      "Valid: 2-shot EPOCH [55/200], STEP [20/33]\n",
      "Total Loss V: 0.5743482708930969\n",
      "Valid: 2-shot EPOCH [55/200], STEP [30/33]\n",
      "Total Loss V: 0.26172590255737305\n",
      "EPOCH [56/200], STEP [11/134]\n",
      "Total Loss G: 0.9527055025100708\n",
      "EPOCH [56/200], STEP [21/134]\n",
      "Total Loss G: 0.6001253128051758\n",
      "EPOCH [56/200], STEP [31/134]\n",
      "Total Loss G: 0.16326381266117096\n",
      "EPOCH [56/200], STEP [41/134]\n",
      "Total Loss G: 0.9514017701148987\n",
      "EPOCH [56/200], STEP [51/134]\n",
      "Total Loss G: 0.6325610876083374\n",
      "EPOCH [56/200], STEP [61/134]\n",
      "Total Loss G: 0.4461061358451843\n",
      "EPOCH [56/200], STEP [71/134]\n",
      "Total Loss G: 0.5848111510276794\n",
      "EPOCH [56/200], STEP [81/134]\n",
      "Total Loss G: 0.30904969573020935\n",
      "EPOCH [56/200], STEP [91/134]\n",
      "Total Loss G: 0.3658301830291748\n",
      "EPOCH [56/200], STEP [101/134]\n",
      "Total Loss G: 0.35444217920303345\n",
      "EPOCH [56/200], STEP [111/134]\n",
      "Total Loss G: 0.3203897774219513\n",
      "EPOCH [56/200], STEP [121/134]\n",
      "Total Loss G: 0.6761772632598877\n",
      "EPOCH [56/200], STEP [131/134]\n",
      "Total Loss G: 0.38129350543022156\n",
      "EPOCH [56/200], STEP [141/134]\n",
      "Total Loss G: 0.22644969820976257\n",
      "Training time is  0.8353668173154195 mins\n",
      "Valid: 2-shot EPOCH [56/200], STEP [10/33]\n",
      "Total Loss V: 0.44431304931640625\n",
      "Valid: 2-shot EPOCH [56/200], STEP [20/33]\n",
      "Total Loss V: 0.4883001744747162\n",
      "Valid: 2-shot EPOCH [56/200], STEP [30/33]\n",
      "Total Loss V: 0.18673093616962433\n",
      "EPOCH [57/200], STEP [11/134]\n",
      "Total Loss G: 0.6370253562927246\n",
      "EPOCH [57/200], STEP [21/134]\n",
      "Total Loss G: 0.46155431866645813\n",
      "EPOCH [57/200], STEP [31/134]\n",
      "Total Loss G: 0.2703454792499542\n",
      "EPOCH [57/200], STEP [41/134]\n",
      "Total Loss G: 0.9329400062561035\n",
      "EPOCH [57/200], STEP [51/134]\n",
      "Total Loss G: 0.5267080068588257\n",
      "EPOCH [57/200], STEP [61/134]\n",
      "Total Loss G: 0.44392532110214233\n",
      "EPOCH [57/200], STEP [71/134]\n",
      "Total Loss G: 0.4178810119628906\n",
      "EPOCH [57/200], STEP [81/134]\n",
      "Total Loss G: 0.3157918155193329\n",
      "EPOCH [57/200], STEP [91/134]\n",
      "Total Loss G: 0.2597444951534271\n",
      "EPOCH [57/200], STEP [101/134]\n",
      "Total Loss G: 0.37162357568740845\n",
      "EPOCH [57/200], STEP [111/134]\n",
      "Total Loss G: 0.25687652826309204\n",
      "EPOCH [57/200], STEP [121/134]\n",
      "Total Loss G: 0.6664615273475647\n",
      "EPOCH [57/200], STEP [131/134]\n",
      "Total Loss G: 0.5315383672714233\n",
      "EPOCH [57/200], STEP [141/134]\n",
      "Total Loss G: 0.22301147878170013\n",
      "Training time is  0.8346764326095581 mins\n",
      "Valid: 2-shot EPOCH [57/200], STEP [10/33]\n",
      "Total Loss V: 0.5336955189704895\n",
      "Valid: 2-shot EPOCH [57/200], STEP [20/33]\n",
      "Total Loss V: 0.4703505039215088\n",
      "Valid: 2-shot EPOCH [57/200], STEP [30/33]\n",
      "Total Loss V: 0.34607312083244324\n",
      "EPOCH [58/200], STEP [11/134]\n",
      "Total Loss G: 0.4798571467399597\n",
      "EPOCH [58/200], STEP [21/134]\n",
      "Total Loss G: 0.4383332431316376\n",
      "EPOCH [58/200], STEP [31/134]\n",
      "Total Loss G: 0.3501204252243042\n",
      "EPOCH [58/200], STEP [41/134]\n",
      "Total Loss G: 0.912138044834137\n",
      "EPOCH [58/200], STEP [51/134]\n",
      "Total Loss G: 0.6167862415313721\n",
      "EPOCH [58/200], STEP [61/134]\n",
      "Total Loss G: 0.3918333053588867\n",
      "EPOCH [58/200], STEP [71/134]\n",
      "Total Loss G: 0.47562190890312195\n",
      "EPOCH [58/200], STEP [81/134]\n",
      "Total Loss G: 0.26603424549102783\n",
      "EPOCH [58/200], STEP [91/134]\n",
      "Total Loss G: 0.34136953949928284\n",
      "EPOCH [58/200], STEP [101/134]\n",
      "Total Loss G: 0.34411513805389404\n",
      "EPOCH [58/200], STEP [111/134]\n",
      "Total Loss G: 0.21710893511772156\n",
      "EPOCH [58/200], STEP [121/134]\n",
      "Total Loss G: 0.6642007827758789\n",
      "EPOCH [58/200], STEP [131/134]\n",
      "Total Loss G: 0.5408978462219238\n",
      "EPOCH [58/200], STEP [141/134]\n",
      "Total Loss G: 0.24198786914348602\n",
      "Training time is  0.8331090450286865 mins\n",
      "Valid: 2-shot EPOCH [58/200], STEP [10/33]\n",
      "Total Loss V: 0.4890841543674469\n",
      "Valid: 2-shot EPOCH [58/200], STEP [20/33]\n",
      "Total Loss V: 0.5146166682243347\n",
      "Valid: 2-shot EPOCH [58/200], STEP [30/33]\n",
      "Total Loss V: 0.22118255496025085\n",
      "EPOCH [59/200], STEP [11/134]\n",
      "Total Loss G: 0.5680826902389526\n",
      "EPOCH [59/200], STEP [21/134]\n",
      "Total Loss G: 0.5252360105514526\n",
      "EPOCH [59/200], STEP [31/134]\n",
      "Total Loss G: 0.14066198468208313\n",
      "EPOCH [59/200], STEP [41/134]\n",
      "Total Loss G: 0.8582534193992615\n",
      "EPOCH [59/200], STEP [51/134]\n",
      "Total Loss G: 0.5381078124046326\n",
      "EPOCH [59/200], STEP [61/134]\n",
      "Total Loss G: 0.2728531062602997\n",
      "EPOCH [59/200], STEP [71/134]\n",
      "Total Loss G: 0.5677887201309204\n",
      "EPOCH [59/200], STEP [81/134]\n",
      "Total Loss G: 0.2301243096590042\n",
      "EPOCH [59/200], STEP [91/134]\n",
      "Total Loss G: 0.36297842860221863\n",
      "EPOCH [59/200], STEP [101/134]\n",
      "Total Loss G: 0.2967551648616791\n",
      "EPOCH [59/200], STEP [111/134]\n",
      "Total Loss G: 0.33197179436683655\n",
      "EPOCH [59/200], STEP [121/134]\n",
      "Total Loss G: 0.8310238122940063\n",
      "EPOCH [59/200], STEP [131/134]\n",
      "Total Loss G: 0.6897627115249634\n",
      "EPOCH [59/200], STEP [141/134]\n",
      "Total Loss G: 0.2336367517709732\n",
      "Training time is  0.8332475503285726 mins\n",
      "Valid: 2-shot EPOCH [59/200], STEP [10/33]\n",
      "Total Loss V: 0.3948751389980316\n",
      "Valid: 2-shot EPOCH [59/200], STEP [20/33]\n",
      "Total Loss V: 0.5536721348762512\n",
      "Valid: 2-shot EPOCH [59/200], STEP [30/33]\n",
      "Total Loss V: 0.21323710680007935\n",
      "EPOCH [60/200], STEP [11/134]\n",
      "Total Loss G: 0.5724350214004517\n",
      "EPOCH [60/200], STEP [21/134]\n",
      "Total Loss G: 0.4711333215236664\n",
      "EPOCH [60/200], STEP [31/134]\n",
      "Total Loss G: 0.2152353972196579\n",
      "EPOCH [60/200], STEP [41/134]\n",
      "Total Loss G: 0.8778819441795349\n",
      "EPOCH [60/200], STEP [51/134]\n",
      "Total Loss G: 0.4365832209587097\n",
      "EPOCH [60/200], STEP [61/134]\n",
      "Total Loss G: 0.23277759552001953\n",
      "EPOCH [60/200], STEP [71/134]\n",
      "Total Loss G: 0.42939630150794983\n",
      "EPOCH [60/200], STEP [81/134]\n",
      "Total Loss G: 0.3568836748600006\n",
      "EPOCH [60/200], STEP [91/134]\n",
      "Total Loss G: 0.3387850522994995\n",
      "EPOCH [60/200], STEP [101/134]\n",
      "Total Loss G: 0.3329133093357086\n",
      "EPOCH [60/200], STEP [111/134]\n",
      "Total Loss G: 0.18394722044467926\n",
      "EPOCH [60/200], STEP [121/134]\n",
      "Total Loss G: 0.8030177354812622\n",
      "EPOCH [60/200], STEP [131/134]\n",
      "Total Loss G: 0.46143800020217896\n",
      "EPOCH [60/200], STEP [141/134]\n",
      "Total Loss G: 0.1910550743341446\n",
      "Training time is  0.8336266120274861 mins\n",
      "Valid: 2-shot EPOCH [60/200], STEP [10/33]\n",
      "Total Loss V: 0.3383309543132782\n",
      "Valid: 2-shot EPOCH [60/200], STEP [20/33]\n",
      "Total Loss V: 0.42204713821411133\n",
      "Valid: 2-shot EPOCH [60/200], STEP [30/33]\n",
      "Total Loss V: 0.3400287926197052\n",
      "EPOCH [61/200], STEP [11/134]\n",
      "Total Loss G: 0.5521137118339539\n",
      "EPOCH [61/200], STEP [21/134]\n",
      "Total Loss G: 0.3869558572769165\n",
      "EPOCH [61/200], STEP [31/134]\n",
      "Total Loss G: 0.15093697607517242\n",
      "EPOCH [61/200], STEP [41/134]\n",
      "Total Loss G: 0.9088882803916931\n",
      "EPOCH [61/200], STEP [51/134]\n",
      "Total Loss G: 0.6269974708557129\n",
      "EPOCH [61/200], STEP [61/134]\n",
      "Total Loss G: 0.3138405382633209\n",
      "EPOCH [61/200], STEP [71/134]\n",
      "Total Loss G: 0.5864114761352539\n",
      "EPOCH [61/200], STEP [81/134]\n",
      "Total Loss G: 0.28644177317619324\n",
      "EPOCH [61/200], STEP [91/134]\n",
      "Total Loss G: 0.3207753300666809\n",
      "EPOCH [61/200], STEP [101/134]\n",
      "Total Loss G: 0.2978212535381317\n",
      "EPOCH [61/200], STEP [111/134]\n",
      "Total Loss G: 0.235006183385849\n",
      "EPOCH [61/200], STEP [121/134]\n",
      "Total Loss G: 0.6495952606201172\n",
      "EPOCH [61/200], STEP [131/134]\n",
      "Total Loss G: 0.5453692078590393\n",
      "EPOCH [61/200], STEP [141/134]\n",
      "Total Loss G: 0.22762329876422882\n",
      "Training time is  0.8522908329963684 mins\n",
      "Valid: 2-shot EPOCH [61/200], STEP [10/33]\n",
      "Total Loss V: 0.37947484850883484\n",
      "Valid: 2-shot EPOCH [61/200], STEP [20/33]\n",
      "Total Loss V: 0.5194249749183655\n",
      "Valid: 2-shot EPOCH [61/200], STEP [30/33]\n",
      "Total Loss V: 0.21843752264976501\n",
      "EPOCH [62/200], STEP [11/134]\n",
      "Total Loss G: 0.4246487319469452\n",
      "EPOCH [62/200], STEP [21/134]\n",
      "Total Loss G: 0.44367262721061707\n",
      "EPOCH [62/200], STEP [31/134]\n",
      "Total Loss G: 0.25998714566230774\n",
      "EPOCH [62/200], STEP [41/134]\n",
      "Total Loss G: 0.9329342842102051\n",
      "EPOCH [62/200], STEP [51/134]\n",
      "Total Loss G: 0.578609049320221\n",
      "EPOCH [62/200], STEP [61/134]\n",
      "Total Loss G: 0.3257318139076233\n",
      "EPOCH [62/200], STEP [71/134]\n",
      "Total Loss G: 0.6241539716720581\n",
      "EPOCH [62/200], STEP [81/134]\n",
      "Total Loss G: 0.39226171374320984\n",
      "EPOCH [62/200], STEP [91/134]\n",
      "Total Loss G: 0.42621520161628723\n",
      "EPOCH [62/200], STEP [101/134]\n",
      "Total Loss G: 0.3362572491168976\n",
      "EPOCH [62/200], STEP [111/134]\n",
      "Total Loss G: 0.17131264507770538\n",
      "EPOCH [62/200], STEP [121/134]\n",
      "Total Loss G: 0.6516902446746826\n",
      "EPOCH [62/200], STEP [131/134]\n",
      "Total Loss G: 0.6425827145576477\n",
      "EPOCH [62/200], STEP [141/134]\n",
      "Total Loss G: 0.20386332273483276\n",
      "Training time is  0.8287172754605611 mins\n",
      "Valid: 2-shot EPOCH [62/200], STEP [10/33]\n",
      "Total Loss V: 0.3668958842754364\n",
      "Valid: 2-shot EPOCH [62/200], STEP [20/33]\n",
      "Total Loss V: 0.40632444620132446\n",
      "Valid: 2-shot EPOCH [62/200], STEP [30/33]\n",
      "Total Loss V: 0.18614497780799866\n",
      "EPOCH [63/200], STEP [11/134]\n",
      "Total Loss G: 0.5197252035140991\n",
      "EPOCH [63/200], STEP [21/134]\n",
      "Total Loss G: 0.39813119173049927\n",
      "EPOCH [63/200], STEP [31/134]\n",
      "Total Loss G: 0.1937299519777298\n",
      "EPOCH [63/200], STEP [41/134]\n",
      "Total Loss G: 0.9017499089241028\n",
      "EPOCH [63/200], STEP [51/134]\n",
      "Total Loss G: 0.46720585227012634\n",
      "EPOCH [63/200], STEP [61/134]\n",
      "Total Loss G: 0.2772146165370941\n",
      "EPOCH [63/200], STEP [71/134]\n",
      "Total Loss G: 0.42553451657295227\n",
      "EPOCH [63/200], STEP [81/134]\n",
      "Total Loss G: 0.2645449638366699\n",
      "EPOCH [63/200], STEP [91/134]\n",
      "Total Loss G: 0.3455336391925812\n",
      "EPOCH [63/200], STEP [101/134]\n",
      "Total Loss G: 0.35093140602111816\n",
      "EPOCH [63/200], STEP [111/134]\n",
      "Total Loss G: 0.2616247534751892\n",
      "EPOCH [63/200], STEP [121/134]\n",
      "Total Loss G: 0.6649649739265442\n",
      "EPOCH [63/200], STEP [131/134]\n",
      "Total Loss G: 0.575930118560791\n",
      "EPOCH [63/200], STEP [141/134]\n",
      "Total Loss G: 0.280670702457428\n",
      "Training time is  0.8267229874928792 mins\n",
      "Valid: 2-shot EPOCH [63/200], STEP [10/33]\n",
      "Total Loss V: 0.555404007434845\n",
      "Valid: 2-shot EPOCH [63/200], STEP [20/33]\n",
      "Total Loss V: 0.25369471311569214\n",
      "Valid: 2-shot EPOCH [63/200], STEP [30/33]\n",
      "Total Loss V: 0.3655332028865814\n",
      "EPOCH [64/200], STEP [11/134]\n",
      "Total Loss G: 0.5016141533851624\n",
      "EPOCH [64/200], STEP [21/134]\n",
      "Total Loss G: 0.5750969052314758\n",
      "EPOCH [64/200], STEP [31/134]\n",
      "Total Loss G: 0.16511724889278412\n",
      "EPOCH [64/200], STEP [41/134]\n",
      "Total Loss G: 0.9161485433578491\n",
      "EPOCH [64/200], STEP [51/134]\n",
      "Total Loss G: 0.5152808427810669\n",
      "EPOCH [64/200], STEP [61/134]\n",
      "Total Loss G: 0.2806445062160492\n",
      "EPOCH [64/200], STEP [71/134]\n",
      "Total Loss G: 0.2391497939825058\n",
      "EPOCH [64/200], STEP [81/134]\n",
      "Total Loss G: 0.3484804928302765\n",
      "EPOCH [64/200], STEP [91/134]\n",
      "Total Loss G: 0.4348700940608978\n",
      "EPOCH [64/200], STEP [101/134]\n",
      "Total Loss G: 0.4392409026622772\n",
      "EPOCH [64/200], STEP [111/134]\n",
      "Total Loss G: 0.19601169228553772\n",
      "EPOCH [64/200], STEP [121/134]\n",
      "Total Loss G: 0.6194929480552673\n",
      "EPOCH [64/200], STEP [131/134]\n",
      "Total Loss G: 0.7028625011444092\n",
      "EPOCH [64/200], STEP [141/134]\n",
      "Total Loss G: 0.1898154765367508\n",
      "Training time is  0.8282533049583435 mins\n",
      "Valid: 2-shot EPOCH [64/200], STEP [10/33]\n",
      "Total Loss V: 0.45764440298080444\n",
      "Valid: 2-shot EPOCH [64/200], STEP [20/33]\n",
      "Total Loss V: 0.34360378980636597\n",
      "Valid: 2-shot EPOCH [64/200], STEP [30/33]\n",
      "Total Loss V: 0.3869924247264862\n",
      "EPOCH [65/200], STEP [11/134]\n",
      "Total Loss G: 0.42684388160705566\n",
      "EPOCH [65/200], STEP [21/134]\n",
      "Total Loss G: 0.4132484197616577\n",
      "EPOCH [65/200], STEP [31/134]\n",
      "Total Loss G: 0.30068498849868774\n",
      "EPOCH [65/200], STEP [41/134]\n",
      "Total Loss G: 0.7591404318809509\n",
      "EPOCH [65/200], STEP [51/134]\n",
      "Total Loss G: 0.5714054703712463\n",
      "EPOCH [65/200], STEP [61/134]\n",
      "Total Loss G: 0.23147152364253998\n",
      "EPOCH [65/200], STEP [71/134]\n",
      "Total Loss G: 0.5120469927787781\n",
      "EPOCH [65/200], STEP [81/134]\n",
      "Total Loss G: 0.2259158492088318\n",
      "EPOCH [65/200], STEP [91/134]\n",
      "Total Loss G: 0.4027681052684784\n",
      "EPOCH [65/200], STEP [101/134]\n",
      "Total Loss G: 0.35724008083343506\n",
      "EPOCH [65/200], STEP [111/134]\n",
      "Total Loss G: 0.1869419813156128\n",
      "EPOCH [65/200], STEP [121/134]\n",
      "Total Loss G: 0.6297602653503418\n",
      "EPOCH [65/200], STEP [131/134]\n",
      "Total Loss G: 0.5551676750183105\n",
      "EPOCH [65/200], STEP [141/134]\n",
      "Total Loss G: 0.19477581977844238\n",
      "Training time is  0.855948023001353 mins\n",
      "Valid: 2-shot EPOCH [65/200], STEP [10/33]\n",
      "Total Loss V: 0.3093830347061157\n",
      "Valid: 2-shot EPOCH [65/200], STEP [20/33]\n",
      "Total Loss V: 0.3918335735797882\n",
      "Valid: 2-shot EPOCH [65/200], STEP [30/33]\n",
      "Total Loss V: 0.2839844822883606\n",
      "EPOCH [66/200], STEP [11/134]\n",
      "Total Loss G: 0.883785605430603\n",
      "EPOCH [66/200], STEP [21/134]\n",
      "Total Loss G: 0.4731515645980835\n",
      "EPOCH [66/200], STEP [31/134]\n",
      "Total Loss G: 0.17961692810058594\n",
      "EPOCH [66/200], STEP [41/134]\n",
      "Total Loss G: 0.827420711517334\n",
      "EPOCH [66/200], STEP [51/134]\n",
      "Total Loss G: 0.6044172048568726\n",
      "EPOCH [66/200], STEP [61/134]\n",
      "Total Loss G: 0.2782053053379059\n",
      "EPOCH [66/200], STEP [71/134]\n",
      "Total Loss G: 0.4670923054218292\n",
      "EPOCH [66/200], STEP [81/134]\n",
      "Total Loss G: 0.4063566029071808\n",
      "EPOCH [66/200], STEP [91/134]\n",
      "Total Loss G: 0.26797813177108765\n",
      "EPOCH [66/200], STEP [101/134]\n",
      "Total Loss G: 0.31190747022628784\n",
      "EPOCH [66/200], STEP [111/134]\n",
      "Total Loss G: 0.22007732093334198\n",
      "EPOCH [66/200], STEP [121/134]\n",
      "Total Loss G: 0.6291670799255371\n",
      "EPOCH [66/200], STEP [131/134]\n",
      "Total Loss G: 0.47488030791282654\n",
      "EPOCH [66/200], STEP [141/134]\n",
      "Total Loss G: 0.1875697821378708\n",
      "Training time is  0.8360818227132162 mins\n",
      "Valid: 2-shot EPOCH [66/200], STEP [10/33]\n",
      "Total Loss V: 0.3480956554412842\n",
      "Valid: 2-shot EPOCH [66/200], STEP [20/33]\n",
      "Total Loss V: 0.6596428751945496\n",
      "Valid: 2-shot EPOCH [66/200], STEP [30/33]\n",
      "Total Loss V: 0.2620425522327423\n",
      "EPOCH [67/200], STEP [11/134]\n",
      "Total Loss G: 0.29202979803085327\n",
      "EPOCH [67/200], STEP [21/134]\n",
      "Total Loss G: 0.44807639718055725\n",
      "EPOCH [67/200], STEP [31/134]\n",
      "Total Loss G: 0.21979857981204987\n",
      "EPOCH [67/200], STEP [41/134]\n",
      "Total Loss G: 0.9026802182197571\n",
      "EPOCH [67/200], STEP [51/134]\n",
      "Total Loss G: 0.5639711022377014\n",
      "EPOCH [67/200], STEP [61/134]\n",
      "Total Loss G: 0.38196298480033875\n",
      "EPOCH [67/200], STEP [71/134]\n",
      "Total Loss G: 0.270511656999588\n",
      "EPOCH [67/200], STEP [81/134]\n",
      "Total Loss G: 0.5498707890510559\n",
      "EPOCH [67/200], STEP [91/134]\n",
      "Total Loss G: 0.3302428126335144\n",
      "EPOCH [67/200], STEP [101/134]\n",
      "Total Loss G: 0.31468579173088074\n",
      "EPOCH [67/200], STEP [111/134]\n",
      "Total Loss G: 0.24019621312618256\n",
      "EPOCH [67/200], STEP [121/134]\n",
      "Total Loss G: 0.5828953385353088\n",
      "EPOCH [67/200], STEP [131/134]\n",
      "Total Loss G: 0.5062751173973083\n",
      "EPOCH [67/200], STEP [141/134]\n",
      "Total Loss G: 0.1996440440416336\n",
      "Training time is  0.8284384369850158 mins\n",
      "Valid: 2-shot EPOCH [67/200], STEP [10/33]\n",
      "Total Loss V: 0.3230883479118347\n",
      "Valid: 2-shot EPOCH [67/200], STEP [20/33]\n",
      "Total Loss V: 0.42395472526550293\n",
      "Valid: 2-shot EPOCH [67/200], STEP [30/33]\n",
      "Total Loss V: 0.14782732725143433\n",
      "EPOCH [68/200], STEP [11/134]\n",
      "Total Loss G: 0.3124319016933441\n",
      "EPOCH [68/200], STEP [21/134]\n",
      "Total Loss G: 0.3423245847225189\n",
      "EPOCH [68/200], STEP [31/134]\n",
      "Total Loss G: 0.1764317899942398\n",
      "EPOCH [68/200], STEP [41/134]\n",
      "Total Loss G: 0.9773552417755127\n",
      "EPOCH [68/200], STEP [51/134]\n",
      "Total Loss G: 0.43589285016059875\n",
      "EPOCH [68/200], STEP [61/134]\n",
      "Total Loss G: 0.24793414771556854\n",
      "EPOCH [68/200], STEP [71/134]\n",
      "Total Loss G: 0.4950520098209381\n",
      "EPOCH [68/200], STEP [81/134]\n",
      "Total Loss G: 0.30160966515541077\n",
      "EPOCH [68/200], STEP [91/134]\n",
      "Total Loss G: 0.3568055331707001\n",
      "EPOCH [68/200], STEP [101/134]\n",
      "Total Loss G: 0.32933536171913147\n",
      "EPOCH [68/200], STEP [111/134]\n",
      "Total Loss G: 0.22673556208610535\n",
      "EPOCH [68/200], STEP [121/134]\n",
      "Total Loss G: 0.6507245302200317\n",
      "EPOCH [68/200], STEP [131/134]\n",
      "Total Loss G: 0.5862628221511841\n",
      "EPOCH [68/200], STEP [141/134]\n",
      "Total Loss G: 0.2384997010231018\n",
      "Training time is  0.8327270348866781 mins\n",
      "Valid: 2-shot EPOCH [68/200], STEP [10/33]\n",
      "Total Loss V: 0.2952614724636078\n",
      "Valid: 2-shot EPOCH [68/200], STEP [20/33]\n",
      "Total Loss V: 0.44504064321517944\n",
      "Valid: 2-shot EPOCH [68/200], STEP [30/33]\n",
      "Total Loss V: 0.22797150909900665\n",
      "EPOCH [69/200], STEP [11/134]\n",
      "Total Loss G: 0.4397597908973694\n",
      "EPOCH [69/200], STEP [21/134]\n",
      "Total Loss G: 0.4842681884765625\n",
      "EPOCH [69/200], STEP [31/134]\n",
      "Total Loss G: 0.14089396595954895\n",
      "EPOCH [69/200], STEP [41/134]\n",
      "Total Loss G: 0.7527726888656616\n",
      "EPOCH [69/200], STEP [51/134]\n",
      "Total Loss G: 0.4666701853275299\n",
      "EPOCH [69/200], STEP [61/134]\n",
      "Total Loss G: 0.273517370223999\n",
      "EPOCH [69/200], STEP [71/134]\n",
      "Total Loss G: 0.35311999917030334\n",
      "EPOCH [69/200], STEP [81/134]\n",
      "Total Loss G: 0.4979008436203003\n",
      "EPOCH [69/200], STEP [91/134]\n",
      "Total Loss G: 0.3017730712890625\n",
      "EPOCH [69/200], STEP [101/134]\n",
      "Total Loss G: 0.34782475233078003\n",
      "EPOCH [69/200], STEP [111/134]\n",
      "Total Loss G: 0.2268524467945099\n",
      "EPOCH [69/200], STEP [121/134]\n",
      "Total Loss G: 0.6247945427894592\n",
      "EPOCH [69/200], STEP [131/134]\n",
      "Total Loss G: 0.4769566059112549\n",
      "EPOCH [69/200], STEP [141/134]\n",
      "Total Loss G: 0.2083660215139389\n",
      "Training time is  0.8277540683746338 mins\n",
      "Valid: 2-shot EPOCH [69/200], STEP [10/33]\n",
      "Total Loss V: 0.3574816584587097\n",
      "Valid: 2-shot EPOCH [69/200], STEP [20/33]\n",
      "Total Loss V: 0.6465818881988525\n",
      "Valid: 2-shot EPOCH [69/200], STEP [30/33]\n",
      "Total Loss V: 0.28539127111434937\n",
      "EPOCH [70/200], STEP [11/134]\n",
      "Total Loss G: 0.41797834634780884\n",
      "EPOCH [70/200], STEP [21/134]\n",
      "Total Loss G: 0.4047023057937622\n",
      "EPOCH [70/200], STEP [31/134]\n",
      "Total Loss G: 0.183803528547287\n",
      "EPOCH [70/200], STEP [41/134]\n",
      "Total Loss G: 0.8164076805114746\n",
      "EPOCH [70/200], STEP [51/134]\n",
      "Total Loss G: 0.5264577269554138\n",
      "EPOCH [70/200], STEP [61/134]\n",
      "Total Loss G: 0.34710732102394104\n",
      "EPOCH [70/200], STEP [71/134]\n",
      "Total Loss G: 0.35982540249824524\n",
      "EPOCH [70/200], STEP [81/134]\n",
      "Total Loss G: 0.26564204692840576\n",
      "EPOCH [70/200], STEP [91/134]\n",
      "Total Loss G: 0.3234606385231018\n",
      "EPOCH [70/200], STEP [101/134]\n",
      "Total Loss G: 0.33919671177864075\n",
      "EPOCH [70/200], STEP [111/134]\n",
      "Total Loss G: 0.26411738991737366\n",
      "EPOCH [70/200], STEP [121/134]\n",
      "Total Loss G: 0.604142427444458\n",
      "EPOCH [70/200], STEP [131/134]\n",
      "Total Loss G: 0.5602237582206726\n",
      "EPOCH [70/200], STEP [141/134]\n",
      "Total Loss G: 0.20415589213371277\n",
      "Training time is  0.8297986507415771 mins\n",
      "Valid: 2-shot EPOCH [70/200], STEP [10/33]\n",
      "Total Loss V: 0.4609842896461487\n",
      "Valid: 2-shot EPOCH [70/200], STEP [20/33]\n",
      "Total Loss V: 0.3910095691680908\n",
      "Valid: 2-shot EPOCH [70/200], STEP [30/33]\n",
      "Total Loss V: 0.2793947160243988\n",
      "EPOCH [71/200], STEP [11/134]\n",
      "Total Loss G: 0.7750966548919678\n",
      "EPOCH [71/200], STEP [21/134]\n",
      "Total Loss G: 0.49994516372680664\n",
      "EPOCH [71/200], STEP [31/134]\n",
      "Total Loss G: 0.2960264980792999\n",
      "EPOCH [71/200], STEP [41/134]\n",
      "Total Loss G: 0.8760910034179688\n",
      "EPOCH [71/200], STEP [51/134]\n",
      "Total Loss G: 0.5630887150764465\n",
      "EPOCH [71/200], STEP [61/134]\n",
      "Total Loss G: 0.5055351853370667\n",
      "EPOCH [71/200], STEP [71/134]\n",
      "Total Loss G: 0.31365081667900085\n",
      "EPOCH [71/200], STEP [81/134]\n",
      "Total Loss G: 0.23603448271751404\n",
      "EPOCH [71/200], STEP [91/134]\n",
      "Total Loss G: 0.37297841906547546\n",
      "EPOCH [71/200], STEP [101/134]\n",
      "Total Loss G: 0.3539432883262634\n",
      "EPOCH [71/200], STEP [111/134]\n",
      "Total Loss G: 0.18597503006458282\n",
      "EPOCH [71/200], STEP [121/134]\n",
      "Total Loss G: 0.6466930508613586\n",
      "EPOCH [71/200], STEP [131/134]\n",
      "Total Loss G: 0.7035009264945984\n",
      "EPOCH [71/200], STEP [141/134]\n",
      "Total Loss G: 0.17904996871948242\n",
      "Training time is  0.8359682202339173 mins\n",
      "Valid: 2-shot EPOCH [71/200], STEP [10/33]\n",
      "Total Loss V: 0.39772719144821167\n",
      "Valid: 2-shot EPOCH [71/200], STEP [20/33]\n",
      "Total Loss V: 0.47058460116386414\n",
      "Valid: 2-shot EPOCH [71/200], STEP [30/33]\n",
      "Total Loss V: 0.35591569542884827\n",
      "EPOCH [72/200], STEP [11/134]\n",
      "Total Loss G: 0.23477165400981903\n",
      "EPOCH [72/200], STEP [21/134]\n",
      "Total Loss G: 0.38366591930389404\n",
      "EPOCH [72/200], STEP [31/134]\n",
      "Total Loss G: 0.23129461705684662\n",
      "EPOCH [72/200], STEP [41/134]\n",
      "Total Loss G: 0.7791153192520142\n",
      "EPOCH [72/200], STEP [51/134]\n",
      "Total Loss G: 0.4223015308380127\n",
      "EPOCH [72/200], STEP [61/134]\n",
      "Total Loss G: 0.24238091707229614\n",
      "EPOCH [72/200], STEP [71/134]\n",
      "Total Loss G: 0.35982465744018555\n",
      "EPOCH [72/200], STEP [81/134]\n",
      "Total Loss G: 0.3179018199443817\n",
      "EPOCH [72/200], STEP [91/134]\n",
      "Total Loss G: 0.2670493721961975\n",
      "EPOCH [72/200], STEP [101/134]\n",
      "Total Loss G: 0.3200125992298126\n",
      "EPOCH [72/200], STEP [111/134]\n",
      "Total Loss G: 0.17164729535579681\n",
      "EPOCH [72/200], STEP [121/134]\n",
      "Total Loss G: 0.6295266151428223\n",
      "EPOCH [72/200], STEP [131/134]\n",
      "Total Loss G: 0.45038214325904846\n",
      "EPOCH [72/200], STEP [141/134]\n",
      "Total Loss G: 0.20018984377384186\n",
      "Training time is  0.83346529006958 mins\n",
      "Valid: 2-shot EPOCH [72/200], STEP [10/33]\n",
      "Total Loss V: 0.4242675006389618\n",
      "Valid: 2-shot EPOCH [72/200], STEP [20/33]\n",
      "Total Loss V: 0.684468150138855\n",
      "Valid: 2-shot EPOCH [72/200], STEP [30/33]\n",
      "Total Loss V: 0.28493475914001465\n",
      "EPOCH [73/200], STEP [11/134]\n",
      "Total Loss G: 0.4111129939556122\n",
      "EPOCH [73/200], STEP [21/134]\n",
      "Total Loss G: 0.3908592760562897\n",
      "EPOCH [73/200], STEP [31/134]\n",
      "Total Loss G: 0.15876443684101105\n",
      "EPOCH [73/200], STEP [41/134]\n",
      "Total Loss G: 0.789454460144043\n",
      "EPOCH [73/200], STEP [51/134]\n",
      "Total Loss G: 0.463544100522995\n",
      "EPOCH [73/200], STEP [61/134]\n",
      "Total Loss G: 0.4488618075847626\n",
      "EPOCH [73/200], STEP [71/134]\n",
      "Total Loss G: 0.5056496858596802\n",
      "EPOCH [73/200], STEP [81/134]\n",
      "Total Loss G: 0.22923466563224792\n",
      "EPOCH [73/200], STEP [91/134]\n",
      "Total Loss G: 0.26147520542144775\n",
      "EPOCH [73/200], STEP [101/134]\n",
      "Total Loss G: 0.2776429355144501\n",
      "EPOCH [73/200], STEP [111/134]\n",
      "Total Loss G: 0.16400553286075592\n",
      "EPOCH [73/200], STEP [121/134]\n",
      "Total Loss G: 0.6087661385536194\n",
      "EPOCH [73/200], STEP [131/134]\n",
      "Total Loss G: 0.7393045425415039\n",
      "EPOCH [73/200], STEP [141/134]\n",
      "Total Loss G: 0.24456720054149628\n",
      "Training time is  0.8296160340309143 mins\n",
      "Valid: 2-shot EPOCH [73/200], STEP [10/33]\n",
      "Total Loss V: 0.33925876021385193\n",
      "Valid: 2-shot EPOCH [73/200], STEP [20/33]\n",
      "Total Loss V: 0.3968810439109802\n",
      "Valid: 2-shot EPOCH [73/200], STEP [30/33]\n",
      "Total Loss V: 0.38676419854164124\n",
      "EPOCH [74/200], STEP [11/134]\n",
      "Total Loss G: 0.20987370610237122\n",
      "EPOCH [74/200], STEP [21/134]\n",
      "Total Loss G: 0.4200148284435272\n",
      "EPOCH [74/200], STEP [31/134]\n",
      "Total Loss G: 0.22907236218452454\n",
      "EPOCH [74/200], STEP [41/134]\n",
      "Total Loss G: 0.7397980093955994\n",
      "EPOCH [74/200], STEP [51/134]\n",
      "Total Loss G: 0.4186559021472931\n",
      "EPOCH [74/200], STEP [61/134]\n",
      "Total Loss G: 0.3213196098804474\n",
      "EPOCH [74/200], STEP [71/134]\n",
      "Total Loss G: 0.2916666269302368\n",
      "EPOCH [74/200], STEP [81/134]\n",
      "Total Loss G: 0.545793354511261\n",
      "EPOCH [74/200], STEP [91/134]\n",
      "Total Loss G: 0.2259414792060852\n",
      "EPOCH [74/200], STEP [101/134]\n",
      "Total Loss G: 0.309370219707489\n",
      "EPOCH [74/200], STEP [111/134]\n",
      "Total Loss G: 0.18239322304725647\n",
      "EPOCH [74/200], STEP [121/134]\n",
      "Total Loss G: 0.6742566823959351\n",
      "EPOCH [74/200], STEP [131/134]\n",
      "Total Loss G: 0.383573055267334\n",
      "EPOCH [74/200], STEP [141/134]\n",
      "Total Loss G: 0.2004857212305069\n",
      "Training time is  0.8272477825482686 mins\n",
      "Valid: 2-shot EPOCH [74/200], STEP [10/33]\n",
      "Total Loss V: 0.3434009552001953\n",
      "Valid: 2-shot EPOCH [74/200], STEP [20/33]\n",
      "Total Loss V: 0.44982773065567017\n",
      "Valid: 2-shot EPOCH [74/200], STEP [30/33]\n",
      "Total Loss V: 0.16246312856674194\n",
      "EPOCH [75/200], STEP [11/134]\n",
      "Total Loss G: 0.23862549662590027\n",
      "EPOCH [75/200], STEP [21/134]\n",
      "Total Loss G: 0.42357197403907776\n",
      "EPOCH [75/200], STEP [31/134]\n",
      "Total Loss G: 0.2432691901922226\n",
      "EPOCH [75/200], STEP [41/134]\n",
      "Total Loss G: 0.7866039872169495\n",
      "EPOCH [75/200], STEP [51/134]\n",
      "Total Loss G: 0.5585167407989502\n",
      "EPOCH [75/200], STEP [61/134]\n",
      "Total Loss G: 0.3763343095779419\n",
      "EPOCH [75/200], STEP [71/134]\n",
      "Total Loss G: 0.2940749526023865\n",
      "EPOCH [75/200], STEP [81/134]\n",
      "Total Loss G: 0.2767871618270874\n",
      "EPOCH [75/200], STEP [91/134]\n",
      "Total Loss G: 0.3030209243297577\n",
      "EPOCH [75/200], STEP [101/134]\n",
      "Total Loss G: 0.37315472960472107\n",
      "EPOCH [75/200], STEP [111/134]\n",
      "Total Loss G: 0.15004685521125793\n",
      "EPOCH [75/200], STEP [121/134]\n",
      "Total Loss G: 0.5647724270820618\n",
      "EPOCH [75/200], STEP [131/134]\n",
      "Total Loss G: 0.4784886837005615\n",
      "EPOCH [75/200], STEP [141/134]\n",
      "Total Loss G: 0.17558713257312775\n",
      "Training time is  0.8304813702901205 mins\n",
      "Valid: 2-shot EPOCH [75/200], STEP [10/33]\n",
      "Total Loss V: 0.31863635778427124\n",
      "Valid: 2-shot EPOCH [75/200], STEP [20/33]\n",
      "Total Loss V: 0.511573314666748\n",
      "Valid: 2-shot EPOCH [75/200], STEP [30/33]\n",
      "Total Loss V: 0.36314356327056885\n",
      "EPOCH [76/200], STEP [11/134]\n",
      "Total Loss G: 0.5684204697608948\n",
      "EPOCH [76/200], STEP [21/134]\n",
      "Total Loss G: 0.34989210963249207\n",
      "EPOCH [76/200], STEP [31/134]\n",
      "Total Loss G: 0.13791976869106293\n",
      "EPOCH [76/200], STEP [41/134]\n",
      "Total Loss G: 0.8840436935424805\n",
      "EPOCH [76/200], STEP [51/134]\n",
      "Total Loss G: 0.46769654750823975\n",
      "EPOCH [76/200], STEP [61/134]\n",
      "Total Loss G: 0.2549896538257599\n",
      "EPOCH [76/200], STEP [71/134]\n",
      "Total Loss G: 0.2626296877861023\n",
      "EPOCH [76/200], STEP [81/134]\n",
      "Total Loss G: 0.24952460825443268\n",
      "EPOCH [76/200], STEP [91/134]\n",
      "Total Loss G: 0.31389862298965454\n",
      "EPOCH [76/200], STEP [101/134]\n",
      "Total Loss G: 0.3022843599319458\n",
      "EPOCH [76/200], STEP [111/134]\n",
      "Total Loss G: 0.28891387581825256\n",
      "EPOCH [76/200], STEP [121/134]\n",
      "Total Loss G: 0.6397221684455872\n",
      "EPOCH [76/200], STEP [131/134]\n",
      "Total Loss G: 0.6137700080871582\n",
      "EPOCH [76/200], STEP [141/134]\n",
      "Total Loss G: 0.17900510132312775\n",
      "Training time is  0.8312612692515056 mins\n",
      "Valid: 2-shot EPOCH [76/200], STEP [10/33]\n",
      "Total Loss V: 0.4665237069129944\n",
      "Valid: 2-shot EPOCH [76/200], STEP [20/33]\n",
      "Total Loss V: 0.4160388708114624\n",
      "Valid: 2-shot EPOCH [76/200], STEP [30/33]\n",
      "Total Loss V: 0.2222190797328949\n",
      "EPOCH [77/200], STEP [11/134]\n",
      "Total Loss G: 0.3073829412460327\n",
      "EPOCH [77/200], STEP [21/134]\n",
      "Total Loss G: 0.42519447207450867\n",
      "EPOCH [77/200], STEP [31/134]\n",
      "Total Loss G: 0.1401851922273636\n",
      "EPOCH [77/200], STEP [41/134]\n",
      "Total Loss G: 0.8400677442550659\n",
      "EPOCH [77/200], STEP [51/134]\n",
      "Total Loss G: 0.5043165683746338\n",
      "EPOCH [77/200], STEP [61/134]\n",
      "Total Loss G: 0.394059956073761\n",
      "EPOCH [77/200], STEP [71/134]\n",
      "Total Loss G: 0.6286669373512268\n",
      "EPOCH [77/200], STEP [81/134]\n",
      "Total Loss G: 0.2501235902309418\n",
      "EPOCH [77/200], STEP [91/134]\n",
      "Total Loss G: 0.35411542654037476\n",
      "EPOCH [77/200], STEP [101/134]\n",
      "Total Loss G: 0.2786816656589508\n",
      "EPOCH [77/200], STEP [111/134]\n",
      "Total Loss G: 0.23887194693088531\n",
      "EPOCH [77/200], STEP [121/134]\n",
      "Total Loss G: 0.6104581952095032\n",
      "EPOCH [77/200], STEP [131/134]\n",
      "Total Loss G: 0.5800224542617798\n",
      "EPOCH [77/200], STEP [141/134]\n",
      "Total Loss G: 0.20303958654403687\n",
      "Training time is  0.832090167204539 mins\n",
      "Valid: 2-shot EPOCH [77/200], STEP [10/33]\n",
      "Total Loss V: 0.3497970998287201\n",
      "Valid: 2-shot EPOCH [77/200], STEP [20/33]\n",
      "Total Loss V: 0.4367522597312927\n",
      "Valid: 2-shot EPOCH [77/200], STEP [30/33]\n",
      "Total Loss V: 0.42047351598739624\n",
      "EPOCH [78/200], STEP [11/134]\n",
      "Total Loss G: 0.39640483260154724\n",
      "EPOCH [78/200], STEP [21/134]\n",
      "Total Loss G: 0.48580971360206604\n",
      "EPOCH [78/200], STEP [31/134]\n",
      "Total Loss G: 0.1770801842212677\n",
      "EPOCH [78/200], STEP [41/134]\n",
      "Total Loss G: 0.8296663761138916\n",
      "EPOCH [78/200], STEP [51/134]\n",
      "Total Loss G: 0.39991259574890137\n",
      "EPOCH [78/200], STEP [61/134]\n",
      "Total Loss G: 0.21731533110141754\n",
      "EPOCH [78/200], STEP [71/134]\n",
      "Total Loss G: 0.3530433177947998\n",
      "EPOCH [78/200], STEP [81/134]\n",
      "Total Loss G: 0.3933793902397156\n",
      "EPOCH [78/200], STEP [91/134]\n",
      "Total Loss G: 0.39397454261779785\n",
      "EPOCH [78/200], STEP [101/134]\n",
      "Total Loss G: 0.36417922377586365\n",
      "EPOCH [78/200], STEP [111/134]\n",
      "Total Loss G: 0.15898214280605316\n",
      "EPOCH [78/200], STEP [121/134]\n",
      "Total Loss G: 0.6124797463417053\n",
      "EPOCH [78/200], STEP [131/134]\n",
      "Total Loss G: 0.5258306860923767\n",
      "EPOCH [78/200], STEP [141/134]\n",
      "Total Loss G: 0.178109809756279\n",
      "Training time is  0.8311532060305278 mins\n",
      "Valid: 2-shot EPOCH [78/200], STEP [10/33]\n",
      "Total Loss V: 0.415782630443573\n",
      "Valid: 2-shot EPOCH [78/200], STEP [20/33]\n",
      "Total Loss V: 0.2614498734474182\n",
      "Valid: 2-shot EPOCH [78/200], STEP [30/33]\n",
      "Total Loss V: 0.2242523580789566\n",
      "EPOCH [79/200], STEP [11/134]\n",
      "Total Loss G: 0.470020055770874\n",
      "EPOCH [79/200], STEP [21/134]\n",
      "Total Loss G: 0.618024468421936\n",
      "EPOCH [79/200], STEP [31/134]\n",
      "Total Loss G: 0.1366419494152069\n",
      "EPOCH [79/200], STEP [41/134]\n",
      "Total Loss G: 0.7781165838241577\n",
      "EPOCH [79/200], STEP [51/134]\n",
      "Total Loss G: 0.5937454700469971\n",
      "EPOCH [79/200], STEP [61/134]\n",
      "Total Loss G: 0.3595714569091797\n",
      "EPOCH [79/200], STEP [71/134]\n",
      "Total Loss G: 0.3995693027973175\n",
      "EPOCH [79/200], STEP [81/134]\n",
      "Total Loss G: 0.20372366905212402\n",
      "EPOCH [79/200], STEP [91/134]\n",
      "Total Loss G: 0.35491707921028137\n",
      "EPOCH [79/200], STEP [101/134]\n",
      "Total Loss G: 0.2610187828540802\n",
      "EPOCH [79/200], STEP [111/134]\n",
      "Total Loss G: 0.16947253048419952\n",
      "EPOCH [79/200], STEP [121/134]\n",
      "Total Loss G: 0.5756444931030273\n",
      "EPOCH [79/200], STEP [131/134]\n",
      "Total Loss G: 0.5461122989654541\n",
      "EPOCH [79/200], STEP [141/134]\n",
      "Total Loss G: 0.18851138651371002\n",
      "Training time is  0.8299818913141886 mins\n",
      "Valid: 2-shot EPOCH [79/200], STEP [10/33]\n",
      "Total Loss V: 0.36872777342796326\n",
      "Valid: 2-shot EPOCH [79/200], STEP [20/33]\n",
      "Total Loss V: 0.3731788992881775\n",
      "Valid: 2-shot EPOCH [79/200], STEP [30/33]\n",
      "Total Loss V: 0.2399595081806183\n",
      "EPOCH [80/200], STEP [11/134]\n",
      "Total Loss G: 0.4753190875053406\n",
      "EPOCH [80/200], STEP [21/134]\n",
      "Total Loss G: 0.46689632534980774\n",
      "EPOCH [80/200], STEP [31/134]\n",
      "Total Loss G: 0.2055179476737976\n",
      "EPOCH [80/200], STEP [41/134]\n",
      "Total Loss G: 0.7570976614952087\n",
      "EPOCH [80/200], STEP [51/134]\n",
      "Total Loss G: 0.4749666750431061\n",
      "EPOCH [80/200], STEP [61/134]\n",
      "Total Loss G: 0.24033915996551514\n",
      "EPOCH [80/200], STEP [71/134]\n",
      "Total Loss G: 0.30817681550979614\n",
      "EPOCH [80/200], STEP [81/134]\n",
      "Total Loss G: 0.4627695381641388\n",
      "EPOCH [80/200], STEP [91/134]\n",
      "Total Loss G: 0.31211963295936584\n",
      "EPOCH [80/200], STEP [101/134]\n",
      "Total Loss G: 0.2589976489543915\n",
      "EPOCH [80/200], STEP [111/134]\n",
      "Total Loss G: 0.15420128405094147\n",
      "EPOCH [80/200], STEP [121/134]\n",
      "Total Loss G: 0.5643338561058044\n",
      "EPOCH [80/200], STEP [131/134]\n",
      "Total Loss G: 0.5221453309059143\n",
      "EPOCH [80/200], STEP [141/134]\n",
      "Total Loss G: 0.17147740721702576\n",
      "Training time is  0.8295807600021362 mins\n",
      "Valid: 2-shot EPOCH [80/200], STEP [10/33]\n",
      "Total Loss V: 0.37868380546569824\n",
      "Valid: 2-shot EPOCH [80/200], STEP [20/33]\n",
      "Total Loss V: 0.2875257134437561\n",
      "Valid: 2-shot EPOCH [80/200], STEP [30/33]\n",
      "Total Loss V: 0.5978863835334778\n",
      "EPOCH [81/200], STEP [11/134]\n",
      "Total Loss G: 0.5784544348716736\n",
      "EPOCH [81/200], STEP [21/134]\n",
      "Total Loss G: 0.40744373202323914\n",
      "EPOCH [81/200], STEP [31/134]\n",
      "Total Loss G: 0.25856631994247437\n",
      "EPOCH [81/200], STEP [41/134]\n",
      "Total Loss G: 0.7993745803833008\n",
      "EPOCH [81/200], STEP [51/134]\n",
      "Total Loss G: 0.5342240929603577\n",
      "EPOCH [81/200], STEP [61/134]\n",
      "Total Loss G: 0.3622048795223236\n",
      "EPOCH [81/200], STEP [71/134]\n",
      "Total Loss G: 0.3152731657028198\n",
      "EPOCH [81/200], STEP [81/134]\n",
      "Total Loss G: 0.29118824005126953\n",
      "EPOCH [81/200], STEP [91/134]\n",
      "Total Loss G: 0.30354034900665283\n",
      "EPOCH [81/200], STEP [101/134]\n",
      "Total Loss G: 0.31169527769088745\n",
      "EPOCH [81/200], STEP [111/134]\n",
      "Total Loss G: 0.16676688194274902\n",
      "EPOCH [81/200], STEP [121/134]\n",
      "Total Loss G: 0.5956846475601196\n",
      "EPOCH [81/200], STEP [131/134]\n",
      "Total Loss G: 0.615797758102417\n",
      "EPOCH [81/200], STEP [141/134]\n",
      "Total Loss G: 0.21791599690914154\n",
      "Training time is  0.8330488721529643 mins\n",
      "Valid: 2-shot EPOCH [81/200], STEP [10/33]\n",
      "Total Loss V: 0.30509230494499207\n",
      "Valid: 2-shot EPOCH [81/200], STEP [20/33]\n",
      "Total Loss V: 0.46539852023124695\n",
      "Valid: 2-shot EPOCH [81/200], STEP [30/33]\n",
      "Total Loss V: 0.2093740552663803\n",
      "EPOCH [82/200], STEP [11/134]\n",
      "Total Loss G: 0.21285398304462433\n",
      "EPOCH [82/200], STEP [21/134]\n",
      "Total Loss G: 0.4097069203853607\n",
      "EPOCH [82/200], STEP [31/134]\n",
      "Total Loss G: 0.1254958212375641\n",
      "EPOCH [82/200], STEP [41/134]\n",
      "Total Loss G: 0.7827322483062744\n",
      "EPOCH [82/200], STEP [51/134]\n",
      "Total Loss G: 0.410258412361145\n",
      "EPOCH [82/200], STEP [61/134]\n",
      "Total Loss G: 0.2743246257305145\n",
      "EPOCH [82/200], STEP [71/134]\n",
      "Total Loss G: 0.3826706111431122\n",
      "EPOCH [82/200], STEP [81/134]\n",
      "Total Loss G: 0.24449901282787323\n",
      "EPOCH [82/200], STEP [91/134]\n",
      "Total Loss G: 0.2664176821708679\n",
      "EPOCH [82/200], STEP [101/134]\n",
      "Total Loss G: 0.265831857919693\n",
      "EPOCH [82/200], STEP [111/134]\n",
      "Total Loss G: 0.1818748414516449\n",
      "EPOCH [82/200], STEP [121/134]\n",
      "Total Loss G: 0.6264248490333557\n",
      "EPOCH [82/200], STEP [131/134]\n",
      "Total Loss G: 0.45601528882980347\n",
      "EPOCH [82/200], STEP [141/134]\n",
      "Total Loss G: 0.19997349381446838\n",
      "Training time is  0.8287104407946269 mins\n",
      "Valid: 2-shot EPOCH [82/200], STEP [10/33]\n",
      "Total Loss V: 0.5213618874549866\n",
      "Valid: 2-shot EPOCH [82/200], STEP [20/33]\n",
      "Total Loss V: 0.5946921110153198\n",
      "Valid: 2-shot EPOCH [82/200], STEP [30/33]\n",
      "Total Loss V: 0.34091031551361084\n",
      "EPOCH [83/200], STEP [11/134]\n",
      "Total Loss G: 0.40273478627204895\n",
      "EPOCH [83/200], STEP [21/134]\n",
      "Total Loss G: 0.35439351201057434\n",
      "EPOCH [83/200], STEP [31/134]\n",
      "Total Loss G: 0.24091963469982147\n",
      "EPOCH [83/200], STEP [41/134]\n",
      "Total Loss G: 0.856842577457428\n",
      "EPOCH [83/200], STEP [51/134]\n",
      "Total Loss G: 0.4302271902561188\n",
      "EPOCH [83/200], STEP [61/134]\n",
      "Total Loss G: 0.2930348813533783\n",
      "EPOCH [83/200], STEP [71/134]\n",
      "Total Loss G: 0.27082395553588867\n",
      "EPOCH [83/200], STEP [81/134]\n",
      "Total Loss G: 0.33747345209121704\n",
      "EPOCH [83/200], STEP [91/134]\n",
      "Total Loss G: 0.2705481946468353\n",
      "EPOCH [83/200], STEP [101/134]\n",
      "Total Loss G: 0.34497344493865967\n",
      "EPOCH [83/200], STEP [111/134]\n",
      "Total Loss G: 0.12278328835964203\n",
      "EPOCH [83/200], STEP [121/134]\n",
      "Total Loss G: 0.5650380849838257\n",
      "EPOCH [83/200], STEP [131/134]\n",
      "Total Loss G: 0.6928040981292725\n",
      "EPOCH [83/200], STEP [141/134]\n",
      "Total Loss G: 0.23657844960689545\n",
      "Training time is  0.829459834098816 mins\n",
      "Valid: 2-shot EPOCH [83/200], STEP [10/33]\n",
      "Total Loss V: 0.280038058757782\n",
      "Valid: 2-shot EPOCH [83/200], STEP [20/33]\n",
      "Total Loss V: 0.4154117703437805\n",
      "Valid: 2-shot EPOCH [83/200], STEP [30/33]\n",
      "Total Loss V: 0.1644747406244278\n",
      "EPOCH [84/200], STEP [11/134]\n",
      "Total Loss G: 0.22217623889446259\n",
      "EPOCH [84/200], STEP [21/134]\n",
      "Total Loss G: 0.4512685239315033\n",
      "EPOCH [84/200], STEP [31/134]\n",
      "Total Loss G: 0.1301782876253128\n",
      "EPOCH [84/200], STEP [41/134]\n",
      "Total Loss G: 0.7807579040527344\n",
      "EPOCH [84/200], STEP [51/134]\n",
      "Total Loss G: 0.3592433035373688\n",
      "EPOCH [84/200], STEP [61/134]\n",
      "Total Loss G: 0.5138266682624817\n",
      "EPOCH [84/200], STEP [71/134]\n",
      "Total Loss G: 0.29204532504081726\n",
      "EPOCH [84/200], STEP [81/134]\n",
      "Total Loss G: 0.26928186416625977\n",
      "EPOCH [84/200], STEP [91/134]\n",
      "Total Loss G: 0.2693254053592682\n",
      "EPOCH [84/200], STEP [101/134]\n",
      "Total Loss G: 0.254648894071579\n",
      "EPOCH [84/200], STEP [111/134]\n",
      "Total Loss G: 0.15850891172885895\n",
      "EPOCH [84/200], STEP [121/134]\n",
      "Total Loss G: 0.5930495262145996\n",
      "EPOCH [84/200], STEP [131/134]\n",
      "Total Loss G: 0.4731377363204956\n",
      "EPOCH [84/200], STEP [141/134]\n",
      "Total Loss G: 0.20631802082061768\n",
      "Training time is  0.8307468215624492 mins\n",
      "Valid: 2-shot EPOCH [84/200], STEP [10/33]\n",
      "Total Loss V: 0.3400433361530304\n",
      "Valid: 2-shot EPOCH [84/200], STEP [20/33]\n",
      "Total Loss V: 0.41015946865081787\n",
      "Valid: 2-shot EPOCH [84/200], STEP [30/33]\n",
      "Total Loss V: 0.2371954768896103\n",
      "EPOCH [85/200], STEP [11/134]\n",
      "Total Loss G: 0.20937667787075043\n",
      "EPOCH [85/200], STEP [21/134]\n",
      "Total Loss G: 0.38325390219688416\n",
      "EPOCH [85/200], STEP [31/134]\n",
      "Total Loss G: 0.19951167702674866\n",
      "EPOCH [85/200], STEP [41/134]\n",
      "Total Loss G: 0.7444313764572144\n",
      "EPOCH [85/200], STEP [51/134]\n",
      "Total Loss G: 0.40130311250686646\n",
      "EPOCH [85/200], STEP [61/134]\n",
      "Total Loss G: 0.2762310206890106\n",
      "EPOCH [85/200], STEP [71/134]\n",
      "Total Loss G: 0.34402748942375183\n",
      "EPOCH [85/200], STEP [81/134]\n",
      "Total Loss G: 0.32453078031539917\n",
      "EPOCH [85/200], STEP [91/134]\n",
      "Total Loss G: 0.34476789832115173\n",
      "EPOCH [85/200], STEP [101/134]\n",
      "Total Loss G: 0.30071064829826355\n",
      "EPOCH [85/200], STEP [111/134]\n",
      "Total Loss G: 0.16422976553440094\n",
      "EPOCH [85/200], STEP [121/134]\n",
      "Total Loss G: 0.5693526268005371\n",
      "EPOCH [85/200], STEP [131/134]\n",
      "Total Loss G: 0.4651132822036743\n",
      "EPOCH [85/200], STEP [141/134]\n",
      "Total Loss G: 0.18189987540245056\n",
      "Training time is  0.8294822812080384 mins\n",
      "Valid: 2-shot EPOCH [85/200], STEP [10/33]\n",
      "Total Loss V: 0.3933350741863251\n",
      "Valid: 2-shot EPOCH [85/200], STEP [20/33]\n",
      "Total Loss V: 0.48401227593421936\n",
      "Valid: 2-shot EPOCH [85/200], STEP [30/33]\n",
      "Total Loss V: 0.42846643924713135\n",
      "EPOCH [86/200], STEP [11/134]\n",
      "Total Loss G: 0.6503597497940063\n",
      "EPOCH [86/200], STEP [21/134]\n",
      "Total Loss G: 0.3699885308742523\n",
      "EPOCH [86/200], STEP [31/134]\n",
      "Total Loss G: 0.13568314909934998\n",
      "EPOCH [86/200], STEP [41/134]\n",
      "Total Loss G: 0.7374982833862305\n",
      "EPOCH [86/200], STEP [51/134]\n",
      "Total Loss G: 0.38356712460517883\n",
      "EPOCH [86/200], STEP [61/134]\n",
      "Total Loss G: 0.48934099078178406\n",
      "EPOCH [86/200], STEP [71/134]\n",
      "Total Loss G: 0.4330054819583893\n",
      "EPOCH [86/200], STEP [81/134]\n",
      "Total Loss G: 0.23394152522087097\n",
      "EPOCH [86/200], STEP [91/134]\n",
      "Total Loss G: 0.25274598598480225\n",
      "EPOCH [86/200], STEP [101/134]\n",
      "Total Loss G: 0.24998901784420013\n",
      "EPOCH [86/200], STEP [111/134]\n",
      "Total Loss G: 0.1679312139749527\n",
      "EPOCH [86/200], STEP [121/134]\n",
      "Total Loss G: 0.6404981017112732\n",
      "EPOCH [86/200], STEP [131/134]\n",
      "Total Loss G: 0.5674057006835938\n",
      "EPOCH [86/200], STEP [141/134]\n",
      "Total Loss G: 0.18230921030044556\n",
      "Training time is  0.8285436669985453 mins\n",
      "Valid: 2-shot EPOCH [86/200], STEP [10/33]\n",
      "Total Loss V: 0.4729102849960327\n",
      "Valid: 2-shot EPOCH [86/200], STEP [20/33]\n",
      "Total Loss V: 0.2690666913986206\n",
      "Valid: 2-shot EPOCH [86/200], STEP [30/33]\n",
      "Total Loss V: 0.5269389152526855\n",
      "EPOCH [87/200], STEP [11/134]\n",
      "Total Loss G: 0.28049343824386597\n",
      "EPOCH [87/200], STEP [21/134]\n",
      "Total Loss G: 0.42570436000823975\n",
      "EPOCH [87/200], STEP [31/134]\n",
      "Total Loss G: 0.2910810112953186\n",
      "EPOCH [87/200], STEP [41/134]\n",
      "Total Loss G: 0.7479541897773743\n",
      "EPOCH [87/200], STEP [51/134]\n",
      "Total Loss G: 0.45387372374534607\n",
      "EPOCH [87/200], STEP [61/134]\n",
      "Total Loss G: 0.24103890359401703\n",
      "EPOCH [87/200], STEP [71/134]\n",
      "Total Loss G: 0.35827547311782837\n",
      "EPOCH [87/200], STEP [81/134]\n",
      "Total Loss G: 0.18642358481884003\n",
      "EPOCH [87/200], STEP [91/134]\n",
      "Total Loss G: 0.4112946689128876\n",
      "EPOCH [87/200], STEP [101/134]\n",
      "Total Loss G: 0.2448209524154663\n",
      "EPOCH [87/200], STEP [111/134]\n",
      "Total Loss G: 0.15545672178268433\n",
      "EPOCH [87/200], STEP [121/134]\n",
      "Total Loss G: 0.5581144690513611\n",
      "EPOCH [87/200], STEP [131/134]\n",
      "Total Loss G: 0.4605816602706909\n",
      "EPOCH [87/200], STEP [141/134]\n",
      "Total Loss G: 0.1633412092924118\n",
      "Training time is  0.8311742107073467 mins\n",
      "Valid: 2-shot EPOCH [87/200], STEP [10/33]\n",
      "Total Loss V: 0.4537213444709778\n",
      "Valid: 2-shot EPOCH [87/200], STEP [20/33]\n",
      "Total Loss V: 0.49710872769355774\n",
      "Valid: 2-shot EPOCH [87/200], STEP [30/33]\n",
      "Total Loss V: 0.2289295643568039\n",
      "EPOCH [88/200], STEP [11/134]\n",
      "Total Loss G: 0.25925418734550476\n",
      "EPOCH [88/200], STEP [21/134]\n",
      "Total Loss G: 0.326646625995636\n",
      "EPOCH [88/200], STEP [31/134]\n",
      "Total Loss G: 0.2253362536430359\n",
      "EPOCH [88/200], STEP [41/134]\n",
      "Total Loss G: 0.7612106800079346\n",
      "EPOCH [88/200], STEP [51/134]\n",
      "Total Loss G: 0.37450510263442993\n",
      "EPOCH [88/200], STEP [61/134]\n",
      "Total Loss G: 0.25264772772789\n",
      "EPOCH [88/200], STEP [71/134]\n",
      "Total Loss G: 0.3737572729587555\n",
      "EPOCH [88/200], STEP [81/134]\n",
      "Total Loss G: 0.3293927013874054\n",
      "EPOCH [88/200], STEP [91/134]\n",
      "Total Loss G: 0.2489459365606308\n",
      "EPOCH [88/200], STEP [101/134]\n",
      "Total Loss G: 0.30336612462997437\n",
      "EPOCH [88/200], STEP [111/134]\n",
      "Total Loss G: 0.14084139466285706\n",
      "EPOCH [88/200], STEP [121/134]\n",
      "Total Loss G: 0.7302412390708923\n",
      "EPOCH [88/200], STEP [131/134]\n",
      "Total Loss G: 0.6029943227767944\n",
      "EPOCH [88/200], STEP [141/134]\n",
      "Total Loss G: 0.20947645604610443\n",
      "Training time is  0.8310139139493307 mins\n",
      "Valid: 2-shot EPOCH [88/200], STEP [10/33]\n",
      "Total Loss V: 0.37269824743270874\n",
      "Valid: 2-shot EPOCH [88/200], STEP [20/33]\n",
      "Total Loss V: 0.5115817785263062\n",
      "Valid: 2-shot EPOCH [88/200], STEP [30/33]\n",
      "Total Loss V: 0.27829039096832275\n",
      "EPOCH [89/200], STEP [11/134]\n",
      "Total Loss G: 0.6907030344009399\n",
      "EPOCH [89/200], STEP [21/134]\n",
      "Total Loss G: 0.6675242781639099\n",
      "EPOCH [89/200], STEP [31/134]\n",
      "Total Loss G: 0.1761125773191452\n",
      "EPOCH [89/200], STEP [41/134]\n",
      "Total Loss G: 0.7392030954360962\n",
      "EPOCH [89/200], STEP [51/134]\n",
      "Total Loss G: 0.44103482365608215\n",
      "EPOCH [89/200], STEP [61/134]\n",
      "Total Loss G: 0.2311607152223587\n",
      "EPOCH [89/200], STEP [71/134]\n",
      "Total Loss G: 0.5239065885543823\n",
      "EPOCH [89/200], STEP [81/134]\n",
      "Total Loss G: 0.2197374701499939\n",
      "EPOCH [89/200], STEP [91/134]\n",
      "Total Loss G: 0.4018760323524475\n",
      "EPOCH [89/200], STEP [101/134]\n",
      "Total Loss G: 0.28523528575897217\n",
      "EPOCH [89/200], STEP [111/134]\n",
      "Total Loss G: 0.184001162648201\n",
      "EPOCH [89/200], STEP [121/134]\n",
      "Total Loss G: 0.5958613157272339\n",
      "EPOCH [89/200], STEP [131/134]\n",
      "Total Loss G: 0.5612228512763977\n",
      "EPOCH [89/200], STEP [141/134]\n",
      "Total Loss G: 0.17458635568618774\n",
      "Training time is  0.8288018465042114 mins\n",
      "Valid: 2-shot EPOCH [89/200], STEP [10/33]\n",
      "Total Loss V: 0.3611234724521637\n",
      "Valid: 2-shot EPOCH [89/200], STEP [20/33]\n",
      "Total Loss V: 0.41684573888778687\n",
      "Valid: 2-shot EPOCH [89/200], STEP [30/33]\n",
      "Total Loss V: 0.604925811290741\n",
      "EPOCH [90/200], STEP [11/134]\n",
      "Total Loss G: 0.2156994491815567\n",
      "EPOCH [90/200], STEP [21/134]\n",
      "Total Loss G: 0.36001941561698914\n",
      "EPOCH [90/200], STEP [31/134]\n",
      "Total Loss G: 0.16834600269794464\n",
      "EPOCH [90/200], STEP [41/134]\n",
      "Total Loss G: 0.7877365946769714\n",
      "EPOCH [90/200], STEP [51/134]\n",
      "Total Loss G: 0.5401384830474854\n",
      "EPOCH [90/200], STEP [61/134]\n",
      "Total Loss G: 0.23573864996433258\n",
      "EPOCH [90/200], STEP [71/134]\n",
      "Total Loss G: 0.24216172099113464\n",
      "EPOCH [90/200], STEP [81/134]\n",
      "Total Loss G: 0.22657659649848938\n",
      "EPOCH [90/200], STEP [91/134]\n",
      "Total Loss G: 0.2815198302268982\n",
      "EPOCH [90/200], STEP [101/134]\n",
      "Total Loss G: 0.33514082431793213\n",
      "EPOCH [90/200], STEP [111/134]\n",
      "Total Loss G: 0.14363229274749756\n",
      "EPOCH [90/200], STEP [121/134]\n",
      "Total Loss G: 0.5641881227493286\n",
      "EPOCH [90/200], STEP [131/134]\n",
      "Total Loss G: 0.4253857731819153\n",
      "EPOCH [90/200], STEP [141/134]\n",
      "Total Loss G: 0.18246735632419586\n",
      "Training time is  0.8299477656682333 mins\n",
      "Valid: 2-shot EPOCH [90/200], STEP [10/33]\n",
      "Total Loss V: 0.4082909822463989\n",
      "Valid: 2-shot EPOCH [90/200], STEP [20/33]\n",
      "Total Loss V: 0.2937467694282532\n",
      "Valid: 2-shot EPOCH [90/200], STEP [30/33]\n",
      "Total Loss V: 0.6365258693695068\n",
      "EPOCH [91/200], STEP [11/134]\n",
      "Total Loss G: 0.28458765149116516\n",
      "EPOCH [91/200], STEP [21/134]\n",
      "Total Loss G: 0.3531574606895447\n",
      "EPOCH [91/200], STEP [31/134]\n",
      "Total Loss G: 0.1659892052412033\n",
      "EPOCH [91/200], STEP [41/134]\n",
      "Total Loss G: 0.7890884280204773\n",
      "EPOCH [91/200], STEP [51/134]\n",
      "Total Loss G: 0.4502716660499573\n",
      "EPOCH [91/200], STEP [61/134]\n",
      "Total Loss G: 0.5062476396560669\n",
      "EPOCH [91/200], STEP [71/134]\n",
      "Total Loss G: 0.25402241945266724\n",
      "EPOCH [91/200], STEP [81/134]\n",
      "Total Loss G: 0.2577372193336487\n",
      "EPOCH [91/200], STEP [91/134]\n",
      "Total Loss G: 0.21972624957561493\n",
      "EPOCH [91/200], STEP [101/134]\n",
      "Total Loss G: 0.272747278213501\n",
      "EPOCH [91/200], STEP [111/134]\n",
      "Total Loss G: 0.14989233016967773\n",
      "EPOCH [91/200], STEP [121/134]\n",
      "Total Loss G: 0.5910444259643555\n",
      "EPOCH [91/200], STEP [131/134]\n",
      "Total Loss G: 0.4056757688522339\n",
      "EPOCH [91/200], STEP [141/134]\n",
      "Total Loss G: 0.1788402497768402\n",
      "Training time is  0.8306137681007385 mins\n",
      "Valid: 2-shot EPOCH [91/200], STEP [10/33]\n",
      "Total Loss V: 0.4141448736190796\n",
      "Valid: 2-shot EPOCH [91/200], STEP [20/33]\n",
      "Total Loss V: 0.3123522400856018\n",
      "Valid: 2-shot EPOCH [91/200], STEP [30/33]\n",
      "Total Loss V: 0.489152729511261\n",
      "EPOCH [92/200], STEP [11/134]\n",
      "Total Loss G: 0.4686671197414398\n",
      "EPOCH [92/200], STEP [21/134]\n",
      "Total Loss G: 0.3820933699607849\n",
      "EPOCH [92/200], STEP [31/134]\n",
      "Total Loss G: 0.20277173817157745\n",
      "EPOCH [92/200], STEP [41/134]\n",
      "Total Loss G: 0.7344037294387817\n",
      "EPOCH [92/200], STEP [51/134]\n",
      "Total Loss G: 0.36419567465782166\n",
      "EPOCH [92/200], STEP [61/134]\n",
      "Total Loss G: 0.2409692108631134\n",
      "EPOCH [92/200], STEP [71/134]\n",
      "Total Loss G: 0.22800005972385406\n",
      "EPOCH [92/200], STEP [81/134]\n",
      "Total Loss G: 0.22124506533145905\n",
      "EPOCH [92/200], STEP [91/134]\n",
      "Total Loss G: 0.2327791303396225\n",
      "EPOCH [92/200], STEP [101/134]\n",
      "Total Loss G: 0.2500845193862915\n",
      "EPOCH [92/200], STEP [111/134]\n",
      "Total Loss G: 0.15630781650543213\n",
      "EPOCH [92/200], STEP [121/134]\n",
      "Total Loss G: 0.5750484466552734\n",
      "EPOCH [92/200], STEP [131/134]\n",
      "Total Loss G: 0.4309684932231903\n",
      "EPOCH [92/200], STEP [141/134]\n",
      "Total Loss G: 0.16730046272277832\n",
      "Training time is  0.8289508740107219 mins\n",
      "Valid: 2-shot EPOCH [92/200], STEP [10/33]\n",
      "Total Loss V: 0.3473215401172638\n",
      "Valid: 2-shot EPOCH [92/200], STEP [20/33]\n",
      "Total Loss V: 0.3378779888153076\n",
      "Valid: 2-shot EPOCH [92/200], STEP [30/33]\n",
      "Total Loss V: 0.42367586493492126\n",
      "EPOCH [93/200], STEP [11/134]\n",
      "Total Loss G: 0.31216490268707275\n",
      "EPOCH [93/200], STEP [21/134]\n",
      "Total Loss G: 0.37363436818122864\n",
      "EPOCH [93/200], STEP [31/134]\n",
      "Total Loss G: 0.15045835077762604\n",
      "EPOCH [93/200], STEP [41/134]\n",
      "Total Loss G: 0.7040261030197144\n",
      "EPOCH [93/200], STEP [51/134]\n",
      "Total Loss G: 0.3252127170562744\n",
      "EPOCH [93/200], STEP [61/134]\n",
      "Total Loss G: 0.22380749881267548\n",
      "EPOCH [93/200], STEP [71/134]\n",
      "Total Loss G: 0.5443931818008423\n",
      "EPOCH [93/200], STEP [81/134]\n",
      "Total Loss G: 0.19983921945095062\n",
      "EPOCH [93/200], STEP [91/134]\n",
      "Total Loss G: 0.39818549156188965\n",
      "EPOCH [93/200], STEP [101/134]\n",
      "Total Loss G: 0.2841795086860657\n",
      "EPOCH [93/200], STEP [111/134]\n",
      "Total Loss G: 0.18987062573432922\n",
      "EPOCH [93/200], STEP [121/134]\n",
      "Total Loss G: 0.6388502717018127\n",
      "EPOCH [93/200], STEP [131/134]\n",
      "Total Loss G: 0.42530539631843567\n",
      "EPOCH [93/200], STEP [141/134]\n",
      "Total Loss G: 0.1721847802400589\n",
      "Training time is  0.8278367757797241 mins\n",
      "Valid: 2-shot EPOCH [93/200], STEP [10/33]\n",
      "Total Loss V: 0.49483928084373474\n",
      "Valid: 2-shot EPOCH [93/200], STEP [20/33]\n",
      "Total Loss V: 0.5579697489738464\n",
      "Valid: 2-shot EPOCH [93/200], STEP [30/33]\n",
      "Total Loss V: 0.5688440203666687\n",
      "EPOCH [94/200], STEP [11/134]\n",
      "Total Loss G: 0.7432723045349121\n",
      "EPOCH [94/200], STEP [21/134]\n",
      "Total Loss G: 0.445782870054245\n",
      "EPOCH [94/200], STEP [31/134]\n",
      "Total Loss G: 0.16805769503116608\n",
      "EPOCH [94/200], STEP [41/134]\n",
      "Total Loss G: 0.704867959022522\n",
      "EPOCH [94/200], STEP [51/134]\n",
      "Total Loss G: 0.4982999265193939\n",
      "EPOCH [94/200], STEP [61/134]\n",
      "Total Loss G: 0.4102279245853424\n",
      "EPOCH [94/200], STEP [71/134]\n",
      "Total Loss G: 0.291368693113327\n",
      "EPOCH [94/200], STEP [81/134]\n",
      "Total Loss G: 0.1696971356868744\n",
      "EPOCH [94/200], STEP [91/134]\n",
      "Total Loss G: 0.26693639159202576\n",
      "EPOCH [94/200], STEP [101/134]\n",
      "Total Loss G: 0.3316766321659088\n",
      "EPOCH [94/200], STEP [111/134]\n",
      "Total Loss G: 0.24198321998119354\n",
      "EPOCH [94/200], STEP [121/134]\n",
      "Total Loss G: 0.6151697635650635\n",
      "EPOCH [94/200], STEP [131/134]\n",
      "Total Loss G: 0.42139801383018494\n",
      "EPOCH [94/200], STEP [141/134]\n",
      "Total Loss G: 0.16489915549755096\n",
      "Training time is  0.8306629657745361 mins\n",
      "Valid: 2-shot EPOCH [94/200], STEP [10/33]\n",
      "Total Loss V: 0.46312886476516724\n",
      "Valid: 2-shot EPOCH [94/200], STEP [20/33]\n",
      "Total Loss V: 0.2862269878387451\n",
      "Valid: 2-shot EPOCH [94/200], STEP [30/33]\n",
      "Total Loss V: 0.5515208840370178\n",
      "EPOCH [95/200], STEP [11/134]\n",
      "Total Loss G: 0.23340046405792236\n",
      "EPOCH [95/200], STEP [21/134]\n",
      "Total Loss G: 0.4190165102481842\n",
      "EPOCH [95/200], STEP [31/134]\n",
      "Total Loss G: 0.12187725305557251\n",
      "EPOCH [95/200], STEP [41/134]\n",
      "Total Loss G: 0.6895002722740173\n",
      "EPOCH [95/200], STEP [51/134]\n",
      "Total Loss G: 0.30715084075927734\n",
      "EPOCH [95/200], STEP [61/134]\n",
      "Total Loss G: 0.1990031599998474\n",
      "EPOCH [95/200], STEP [71/134]\n",
      "Total Loss G: 0.2513093054294586\n",
      "EPOCH [95/200], STEP [81/134]\n",
      "Total Loss G: 0.2761259377002716\n",
      "EPOCH [95/200], STEP [91/134]\n",
      "Total Loss G: 0.24175618588924408\n",
      "EPOCH [95/200], STEP [101/134]\n",
      "Total Loss G: 0.253219336271286\n",
      "EPOCH [95/200], STEP [111/134]\n",
      "Total Loss G: 0.14923980832099915\n",
      "EPOCH [95/200], STEP [121/134]\n",
      "Total Loss G: 0.5623213052749634\n",
      "EPOCH [95/200], STEP [131/134]\n",
      "Total Loss G: 0.3391578495502472\n",
      "EPOCH [95/200], STEP [141/134]\n",
      "Total Loss G: 0.18306884169578552\n",
      "Training time is  0.830161714553833 mins\n",
      "Valid: 2-shot EPOCH [95/200], STEP [10/33]\n",
      "Total Loss V: 0.4621797502040863\n",
      "Valid: 2-shot EPOCH [95/200], STEP [20/33]\n",
      "Total Loss V: 0.39635077118873596\n",
      "Valid: 2-shot EPOCH [95/200], STEP [30/33]\n",
      "Total Loss V: 0.5219136476516724\n",
      "EPOCH [96/200], STEP [11/134]\n",
      "Total Loss G: 0.21969527006149292\n",
      "EPOCH [96/200], STEP [21/134]\n",
      "Total Loss G: 0.3970521092414856\n",
      "EPOCH [96/200], STEP [31/134]\n",
      "Total Loss G: 0.16211040318012238\n",
      "EPOCH [96/200], STEP [41/134]\n",
      "Total Loss G: 0.67566978931427\n",
      "EPOCH [96/200], STEP [51/134]\n",
      "Total Loss G: 0.4589144289493561\n",
      "EPOCH [96/200], STEP [61/134]\n",
      "Total Loss G: 0.2136639505624771\n",
      "EPOCH [96/200], STEP [71/134]\n",
      "Total Loss G: 0.23762600123882294\n",
      "EPOCH [96/200], STEP [81/134]\n",
      "Total Loss G: 0.19943511486053467\n",
      "EPOCH [96/200], STEP [91/134]\n",
      "Total Loss G: 0.29208365082740784\n",
      "EPOCH [96/200], STEP [101/134]\n",
      "Total Loss G: 0.2679087817668915\n",
      "EPOCH [96/200], STEP [111/134]\n",
      "Total Loss G: 0.17701514065265656\n",
      "EPOCH [96/200], STEP [121/134]\n",
      "Total Loss G: 0.633779764175415\n",
      "EPOCH [96/200], STEP [131/134]\n",
      "Total Loss G: 0.32309362292289734\n",
      "EPOCH [96/200], STEP [141/134]\n",
      "Total Loss G: 0.22189515829086304\n",
      "Training time is  0.8316643436749777 mins\n",
      "Valid: 2-shot EPOCH [96/200], STEP [10/33]\n",
      "Total Loss V: 0.44112589955329895\n",
      "Valid: 2-shot EPOCH [96/200], STEP [20/33]\n",
      "Total Loss V: 0.2539449632167816\n",
      "Valid: 2-shot EPOCH [96/200], STEP [30/33]\n",
      "Total Loss V: 0.7318429350852966\n",
      "EPOCH [97/200], STEP [11/134]\n",
      "Total Loss G: 0.28299424052238464\n",
      "EPOCH [97/200], STEP [21/134]\n",
      "Total Loss G: 0.3356705904006958\n",
      "EPOCH [97/200], STEP [31/134]\n",
      "Total Loss G: 0.49270617961883545\n",
      "EPOCH [97/200], STEP [41/134]\n",
      "Total Loss G: 0.8128378391265869\n",
      "EPOCH [97/200], STEP [51/134]\n",
      "Total Loss G: 0.3710792064666748\n",
      "EPOCH [97/200], STEP [61/134]\n",
      "Total Loss G: 0.2250535786151886\n",
      "EPOCH [97/200], STEP [71/134]\n",
      "Total Loss G: 0.3773309886455536\n",
      "EPOCH [97/200], STEP [81/134]\n",
      "Total Loss G: 0.2048189342021942\n",
      "EPOCH [97/200], STEP [91/134]\n",
      "Total Loss G: 0.27847054600715637\n",
      "EPOCH [97/200], STEP [101/134]\n",
      "Total Loss G: 0.23384539783000946\n",
      "EPOCH [97/200], STEP [111/134]\n",
      "Total Loss G: 0.17409470677375793\n",
      "EPOCH [97/200], STEP [121/134]\n",
      "Total Loss G: 0.582144021987915\n",
      "EPOCH [97/200], STEP [131/134]\n",
      "Total Loss G: 0.4044150412082672\n",
      "EPOCH [97/200], STEP [141/134]\n",
      "Total Loss G: 0.1649075299501419\n",
      "Training time is  0.829658297697703 mins\n",
      "Valid: 2-shot EPOCH [97/200], STEP [10/33]\n",
      "Total Loss V: 0.4495706856250763\n",
      "Valid: 2-shot EPOCH [97/200], STEP [20/33]\n",
      "Total Loss V: 0.35795751214027405\n",
      "Valid: 2-shot EPOCH [97/200], STEP [30/33]\n",
      "Total Loss V: 0.404199481010437\n",
      "EPOCH [98/200], STEP [11/134]\n",
      "Total Loss G: 0.22043761610984802\n",
      "EPOCH [98/200], STEP [21/134]\n",
      "Total Loss G: 0.4454409182071686\n",
      "EPOCH [98/200], STEP [31/134]\n",
      "Total Loss G: 0.2227562963962555\n",
      "EPOCH [98/200], STEP [41/134]\n",
      "Total Loss G: 0.7868099808692932\n",
      "EPOCH [98/200], STEP [51/134]\n",
      "Total Loss G: 0.2833290696144104\n",
      "EPOCH [98/200], STEP [61/134]\n",
      "Total Loss G: 0.1905468851327896\n",
      "EPOCH [98/200], STEP [71/134]\n",
      "Total Loss G: 0.29483628273010254\n",
      "EPOCH [98/200], STEP [81/134]\n",
      "Total Loss G: 0.18113572895526886\n",
      "EPOCH [98/200], STEP [91/134]\n",
      "Total Loss G: 0.22159920632839203\n",
      "EPOCH [98/200], STEP [101/134]\n",
      "Total Loss G: 0.24583101272583008\n",
      "EPOCH [98/200], STEP [111/134]\n",
      "Total Loss G: 0.17235073447227478\n",
      "EPOCH [98/200], STEP [121/134]\n",
      "Total Loss G: 0.6755444407463074\n",
      "EPOCH [98/200], STEP [131/134]\n",
      "Total Loss G: 0.4019494354724884\n",
      "EPOCH [98/200], STEP [141/134]\n",
      "Total Loss G: 0.1527400016784668\n",
      "Training time is  0.8379797140757242 mins\n",
      "Valid: 2-shot EPOCH [98/200], STEP [10/33]\n",
      "Total Loss V: 0.38672128319740295\n",
      "Valid: 2-shot EPOCH [98/200], STEP [20/33]\n",
      "Total Loss V: 0.2692447602748871\n",
      "Valid: 2-shot EPOCH [98/200], STEP [30/33]\n",
      "Total Loss V: 0.5081467032432556\n",
      "EPOCH [99/200], STEP [11/134]\n",
      "Total Loss G: 0.361226886510849\n",
      "EPOCH [99/200], STEP [21/134]\n",
      "Total Loss G: 0.3913596570491791\n",
      "EPOCH [99/200], STEP [31/134]\n",
      "Total Loss G: 0.10498421639204025\n",
      "EPOCH [99/200], STEP [41/134]\n",
      "Total Loss G: 0.6424225568771362\n",
      "EPOCH [99/200], STEP [51/134]\n",
      "Total Loss G: 0.33392903208732605\n",
      "EPOCH [99/200], STEP [61/134]\n",
      "Total Loss G: 0.24756035208702087\n",
      "EPOCH [99/200], STEP [71/134]\n",
      "Total Loss G: 0.3415388762950897\n",
      "EPOCH [99/200], STEP [81/134]\n",
      "Total Loss G: 0.15608768165111542\n",
      "EPOCH [99/200], STEP [91/134]\n",
      "Total Loss G: 0.369184672832489\n",
      "EPOCH [99/200], STEP [101/134]\n",
      "Total Loss G: 0.23812423646450043\n",
      "EPOCH [99/200], STEP [111/134]\n",
      "Total Loss G: 0.15330812335014343\n",
      "EPOCH [99/200], STEP [121/134]\n",
      "Total Loss G: 0.5676712393760681\n",
      "EPOCH [99/200], STEP [131/134]\n",
      "Total Loss G: 0.4411236047744751\n",
      "EPOCH [99/200], STEP [141/134]\n",
      "Total Loss G: 0.15898409485816956\n",
      "Training time is  0.8341519713401795 mins\n",
      "Valid: 2-shot EPOCH [99/200], STEP [10/33]\n",
      "Total Loss V: 0.3854108452796936\n",
      "Valid: 2-shot EPOCH [99/200], STEP [20/33]\n",
      "Total Loss V: 0.2712089419364929\n",
      "Valid: 2-shot EPOCH [99/200], STEP [30/33]\n",
      "Total Loss V: 0.7932719588279724\n",
      "EPOCH [100/200], STEP [11/134]\n",
      "Total Loss G: 0.1744060218334198\n",
      "EPOCH [100/200], STEP [21/134]\n",
      "Total Loss G: 0.3715546131134033\n",
      "EPOCH [100/200], STEP [31/134]\n",
      "Total Loss G: 0.2196328192949295\n",
      "EPOCH [100/200], STEP [41/134]\n",
      "Total Loss G: 0.6859508156776428\n",
      "EPOCH [100/200], STEP [51/134]\n",
      "Total Loss G: 0.3499390482902527\n",
      "EPOCH [100/200], STEP [61/134]\n",
      "Total Loss G: 0.21521630883216858\n",
      "EPOCH [100/200], STEP [71/134]\n",
      "Total Loss G: 0.2187444269657135\n",
      "EPOCH [100/200], STEP [81/134]\n",
      "Total Loss G: 0.169021874666214\n",
      "EPOCH [100/200], STEP [91/134]\n",
      "Total Loss G: 0.3174930214881897\n",
      "EPOCH [100/200], STEP [101/134]\n",
      "Total Loss G: 0.23075081408023834\n",
      "EPOCH [100/200], STEP [111/134]\n",
      "Total Loss G: 0.21724934875965118\n",
      "EPOCH [100/200], STEP [121/134]\n",
      "Total Loss G: 0.5571032166481018\n",
      "EPOCH [100/200], STEP [131/134]\n",
      "Total Loss G: 0.3813040256500244\n",
      "EPOCH [100/200], STEP [141/134]\n",
      "Total Loss G: 0.1555211842060089\n",
      "Training time is  0.8339526295661926 mins\n",
      "Valid: 2-shot EPOCH [100/200], STEP [10/33]\n",
      "Total Loss V: 0.4226539134979248\n",
      "Valid: 2-shot EPOCH [100/200], STEP [20/33]\n",
      "Total Loss V: 0.625292181968689\n",
      "Valid: 2-shot EPOCH [100/200], STEP [30/33]\n",
      "Total Loss V: 0.346841424703598\n",
      "EPOCH [101/200], STEP [11/134]\n",
      "Total Loss G: 0.7044020295143127\n",
      "EPOCH [101/200], STEP [21/134]\n",
      "Total Loss G: 0.30803465843200684\n",
      "EPOCH [101/200], STEP [31/134]\n",
      "Total Loss G: 0.1466117948293686\n",
      "EPOCH [101/200], STEP [41/134]\n",
      "Total Loss G: 0.6686394810676575\n",
      "EPOCH [101/200], STEP [51/134]\n",
      "Total Loss G: 0.2739083766937256\n",
      "EPOCH [101/200], STEP [61/134]\n",
      "Total Loss G: 0.25014355778694153\n",
      "EPOCH [101/200], STEP [71/134]\n",
      "Total Loss G: 0.20817728340625763\n",
      "EPOCH [101/200], STEP [81/134]\n",
      "Total Loss G: 0.1651124507188797\n",
      "EPOCH [101/200], STEP [91/134]\n",
      "Total Loss G: 0.210626482963562\n",
      "EPOCH [101/200], STEP [101/134]\n",
      "Total Loss G: 0.2992704510688782\n",
      "EPOCH [101/200], STEP [111/134]\n",
      "Total Loss G: 0.17752480506896973\n",
      "EPOCH [101/200], STEP [121/134]\n",
      "Total Loss G: 0.6245919466018677\n",
      "EPOCH [101/200], STEP [131/134]\n",
      "Total Loss G: 0.38108620047569275\n",
      "EPOCH [101/200], STEP [141/134]\n",
      "Total Loss G: 0.17658071219921112\n",
      "Training time is  0.8351011077562968 mins\n",
      "Valid: 2-shot EPOCH [101/200], STEP [10/33]\n",
      "Total Loss V: 0.47070154547691345\n",
      "Valid: 2-shot EPOCH [101/200], STEP [20/33]\n",
      "Total Loss V: 0.2875271141529083\n",
      "Valid: 2-shot EPOCH [101/200], STEP [30/33]\n",
      "Total Loss V: 0.7723976373672485\n",
      "EPOCH [102/200], STEP [11/134]\n",
      "Total Loss G: 0.18069736659526825\n",
      "EPOCH [102/200], STEP [21/134]\n",
      "Total Loss G: 0.3225884437561035\n",
      "EPOCH [102/200], STEP [31/134]\n",
      "Total Loss G: 0.1400206983089447\n",
      "EPOCH [102/200], STEP [41/134]\n",
      "Total Loss G: 0.7167075872421265\n",
      "EPOCH [102/200], STEP [51/134]\n",
      "Total Loss G: 0.2766059339046478\n",
      "EPOCH [102/200], STEP [61/134]\n",
      "Total Loss G: 0.2008616328239441\n",
      "EPOCH [102/200], STEP [71/134]\n",
      "Total Loss G: 0.26971492171287537\n",
      "EPOCH [102/200], STEP [81/134]\n",
      "Total Loss G: 0.1609489470720291\n",
      "EPOCH [102/200], STEP [91/134]\n",
      "Total Loss G: 0.24075156450271606\n",
      "EPOCH [102/200], STEP [101/134]\n",
      "Total Loss G: 0.24712646007537842\n",
      "EPOCH [102/200], STEP [111/134]\n",
      "Total Loss G: 0.163128063082695\n",
      "EPOCH [102/200], STEP [121/134]\n",
      "Total Loss G: 0.5291481614112854\n",
      "EPOCH [102/200], STEP [131/134]\n",
      "Total Loss G: 0.36394116282463074\n",
      "EPOCH [102/200], STEP [141/134]\n",
      "Total Loss G: 0.1531193107366562\n",
      "Training time is  0.8318433086077373 mins\n",
      "Valid: 2-shot EPOCH [102/200], STEP [10/33]\n",
      "Total Loss V: 0.495979905128479\n",
      "Valid: 2-shot EPOCH [102/200], STEP [20/33]\n",
      "Total Loss V: 0.2696181535720825\n",
      "Valid: 2-shot EPOCH [102/200], STEP [30/33]\n",
      "Total Loss V: 0.9948582649230957\n",
      "EPOCH [103/200], STEP [11/134]\n",
      "Total Loss G: 0.17241047322750092\n",
      "EPOCH [103/200], STEP [21/134]\n",
      "Total Loss G: 0.6707597970962524\n",
      "EPOCH [103/200], STEP [31/134]\n",
      "Total Loss G: 0.11333686858415604\n",
      "EPOCH [103/200], STEP [41/134]\n",
      "Total Loss G: 0.736842930316925\n",
      "EPOCH [103/200], STEP [51/134]\n",
      "Total Loss G: 0.30028876662254333\n",
      "EPOCH [103/200], STEP [61/134]\n",
      "Total Loss G: 0.3138190805912018\n",
      "EPOCH [103/200], STEP [71/134]\n",
      "Total Loss G: 0.21087823808193207\n",
      "EPOCH [103/200], STEP [81/134]\n",
      "Total Loss G: 0.23479557037353516\n",
      "EPOCH [103/200], STEP [91/134]\n",
      "Total Loss G: 0.23539438843727112\n",
      "EPOCH [103/200], STEP [101/134]\n",
      "Total Loss G: 0.26825371384620667\n",
      "EPOCH [103/200], STEP [111/134]\n",
      "Total Loss G: 0.14514373242855072\n",
      "EPOCH [103/200], STEP [121/134]\n",
      "Total Loss G: 0.5380026698112488\n",
      "EPOCH [103/200], STEP [131/134]\n",
      "Total Loss G: 0.5039991140365601\n",
      "EPOCH [103/200], STEP [141/134]\n",
      "Total Loss G: 0.1543956995010376\n",
      "Training time is  0.8327661991119385 mins\n",
      "Valid: 2-shot EPOCH [103/200], STEP [10/33]\n",
      "Total Loss V: 0.4191990792751312\n",
      "Valid: 2-shot EPOCH [103/200], STEP [20/33]\n",
      "Total Loss V: 0.26962506771087646\n",
      "Valid: 2-shot EPOCH [103/200], STEP [30/33]\n",
      "Total Loss V: 0.866773247718811\n",
      "EPOCH [104/200], STEP [11/134]\n",
      "Total Loss G: 0.2629205584526062\n",
      "EPOCH [104/200], STEP [21/134]\n",
      "Total Loss G: 0.5329940319061279\n",
      "EPOCH [104/200], STEP [31/134]\n",
      "Total Loss G: 0.11393171548843384\n",
      "EPOCH [104/200], STEP [41/134]\n",
      "Total Loss G: 0.6790692210197449\n",
      "EPOCH [104/200], STEP [51/134]\n",
      "Total Loss G: 0.31237784028053284\n",
      "EPOCH [104/200], STEP [61/134]\n",
      "Total Loss G: 0.2128070443868637\n",
      "EPOCH [104/200], STEP [71/134]\n",
      "Total Loss G: 0.20166665315628052\n",
      "EPOCH [104/200], STEP [81/134]\n",
      "Total Loss G: 0.15436221659183502\n",
      "EPOCH [104/200], STEP [91/134]\n",
      "Total Loss G: 0.22654016315937042\n",
      "EPOCH [104/200], STEP [101/134]\n",
      "Total Loss G: 0.31850773096084595\n",
      "EPOCH [104/200], STEP [111/134]\n",
      "Total Loss G: 0.1265583336353302\n",
      "EPOCH [104/200], STEP [121/134]\n",
      "Total Loss G: 0.5450261831283569\n",
      "EPOCH [104/200], STEP [131/134]\n",
      "Total Loss G: 0.3612836003303528\n",
      "EPOCH [104/200], STEP [141/134]\n",
      "Total Loss G: 0.14522521197795868\n",
      "Training time is  0.8432865222295125 mins\n",
      "Valid: 2-shot EPOCH [104/200], STEP [10/33]\n",
      "Total Loss V: 0.4237286150455475\n",
      "Valid: 2-shot EPOCH [104/200], STEP [20/33]\n",
      "Total Loss V: 0.3887776732444763\n",
      "Valid: 2-shot EPOCH [104/200], STEP [30/33]\n",
      "Total Loss V: 0.6808461546897888\n",
      "EPOCH [105/200], STEP [11/134]\n",
      "Total Loss G: 0.1765512228012085\n",
      "EPOCH [105/200], STEP [21/134]\n",
      "Total Loss G: 0.38934585452079773\n",
      "EPOCH [105/200], STEP [31/134]\n",
      "Total Loss G: 0.12718646228313446\n",
      "EPOCH [105/200], STEP [41/134]\n",
      "Total Loss G: 0.7120499610900879\n",
      "EPOCH [105/200], STEP [51/134]\n",
      "Total Loss G: 0.35605064034461975\n",
      "EPOCH [105/200], STEP [61/134]\n",
      "Total Loss G: 0.2587522864341736\n",
      "EPOCH [105/200], STEP [71/134]\n",
      "Total Loss G: 0.4364994466304779\n",
      "EPOCH [105/200], STEP [81/134]\n",
      "Total Loss G: 0.15304765105247498\n",
      "EPOCH [105/200], STEP [91/134]\n",
      "Total Loss G: 0.3295760750770569\n",
      "EPOCH [105/200], STEP [101/134]\n",
      "Total Loss G: 0.21397805213928223\n",
      "EPOCH [105/200], STEP [111/134]\n",
      "Total Loss G: 0.12424107640981674\n",
      "EPOCH [105/200], STEP [121/134]\n",
      "Total Loss G: 0.689972996711731\n",
      "EPOCH [105/200], STEP [131/134]\n",
      "Total Loss G: 0.3184213638305664\n",
      "EPOCH [105/200], STEP [141/134]\n",
      "Total Loss G: 0.16555246710777283\n",
      "Training time is  0.8355719725290934 mins\n",
      "Valid: 2-shot EPOCH [105/200], STEP [10/33]\n",
      "Total Loss V: 0.40197882056236267\n",
      "Valid: 2-shot EPOCH [105/200], STEP [20/33]\n",
      "Total Loss V: 0.4365854859352112\n",
      "Valid: 2-shot EPOCH [105/200], STEP [30/33]\n",
      "Total Loss V: 0.7929219603538513\n",
      "EPOCH [106/200], STEP [11/134]\n",
      "Total Loss G: 0.22391316294670105\n",
      "EPOCH [106/200], STEP [21/134]\n",
      "Total Loss G: 0.3513943552970886\n",
      "EPOCH [106/200], STEP [31/134]\n",
      "Total Loss G: 0.22841264307498932\n",
      "EPOCH [106/200], STEP [41/134]\n",
      "Total Loss G: 0.7357456088066101\n",
      "EPOCH [106/200], STEP [51/134]\n",
      "Total Loss G: 0.3333124816417694\n",
      "EPOCH [106/200], STEP [61/134]\n",
      "Total Loss G: 0.2563392221927643\n",
      "EPOCH [106/200], STEP [71/134]\n",
      "Total Loss G: 0.23683246970176697\n",
      "EPOCH [106/200], STEP [81/134]\n",
      "Total Loss G: 0.166601300239563\n",
      "EPOCH [106/200], STEP [91/134]\n",
      "Total Loss G: 0.2029431313276291\n",
      "EPOCH [106/200], STEP [101/134]\n",
      "Total Loss G: 0.2090948224067688\n",
      "EPOCH [106/200], STEP [111/134]\n",
      "Total Loss G: 0.1439943164587021\n",
      "EPOCH [106/200], STEP [121/134]\n",
      "Total Loss G: 0.6629655361175537\n",
      "EPOCH [106/200], STEP [131/134]\n",
      "Total Loss G: 0.545839786529541\n",
      "EPOCH [106/200], STEP [141/134]\n",
      "Total Loss G: 0.15572397410869598\n",
      "Training time is  0.8374351104100545 mins\n",
      "Valid: 2-shot EPOCH [106/200], STEP [10/33]\n",
      "Total Loss V: 0.3108668327331543\n",
      "Valid: 2-shot EPOCH [106/200], STEP [20/33]\n",
      "Total Loss V: 0.5043045878410339\n",
      "Valid: 2-shot EPOCH [106/200], STEP [30/33]\n",
      "Total Loss V: 0.7039046287536621\n",
      "EPOCH [107/200], STEP [11/134]\n",
      "Total Loss G: 0.20298203825950623\n",
      "EPOCH [107/200], STEP [21/134]\n",
      "Total Loss G: 0.6347241401672363\n",
      "EPOCH [107/200], STEP [31/134]\n",
      "Total Loss G: 0.19149118661880493\n",
      "EPOCH [107/200], STEP [41/134]\n",
      "Total Loss G: 0.6399625539779663\n",
      "EPOCH [107/200], STEP [51/134]\n",
      "Total Loss G: 0.24753153324127197\n",
      "EPOCH [107/200], STEP [61/134]\n",
      "Total Loss G: 0.5501894950866699\n",
      "EPOCH [107/200], STEP [71/134]\n",
      "Total Loss G: 0.20204290747642517\n",
      "EPOCH [107/200], STEP [81/134]\n",
      "Total Loss G: 0.4626186192035675\n",
      "EPOCH [107/200], STEP [91/134]\n",
      "Total Loss G: 0.2670697271823883\n",
      "EPOCH [107/200], STEP [101/134]\n",
      "Total Loss G: 0.2018088698387146\n",
      "EPOCH [107/200], STEP [111/134]\n",
      "Total Loss G: 0.15514174103736877\n",
      "EPOCH [107/200], STEP [121/134]\n",
      "Total Loss G: 0.5732759237289429\n",
      "EPOCH [107/200], STEP [131/134]\n",
      "Total Loss G: 0.4121480882167816\n",
      "EPOCH [107/200], STEP [141/134]\n",
      "Total Loss G: 0.14950574934482574\n",
      "Training time is  0.929415229956309 mins\n",
      "Valid: 2-shot EPOCH [107/200], STEP [10/33]\n",
      "Total Loss V: 0.5166829824447632\n",
      "Valid: 2-shot EPOCH [107/200], STEP [20/33]\n",
      "Total Loss V: 0.2876875698566437\n",
      "Valid: 2-shot EPOCH [107/200], STEP [30/33]\n",
      "Total Loss V: 0.5679532289505005\n",
      "EPOCH [108/200], STEP [11/134]\n",
      "Total Loss G: 0.1780584305524826\n",
      "EPOCH [108/200], STEP [21/134]\n",
      "Total Loss G: 0.47008568048477173\n",
      "EPOCH [108/200], STEP [31/134]\n",
      "Total Loss G: 0.40543636679649353\n",
      "EPOCH [108/200], STEP [41/134]\n",
      "Total Loss G: 0.83977210521698\n",
      "EPOCH [108/200], STEP [51/134]\n",
      "Total Loss G: 0.4013374149799347\n",
      "EPOCH [108/200], STEP [61/134]\n",
      "Total Loss G: 0.2831960916519165\n",
      "EPOCH [108/200], STEP [71/134]\n",
      "Total Loss G: 0.4092067778110504\n",
      "EPOCH [108/200], STEP [81/134]\n",
      "Total Loss G: 0.16005797684192657\n",
      "EPOCH [108/200], STEP [91/134]\n",
      "Total Loss G: 0.21538595855236053\n",
      "EPOCH [108/200], STEP [101/134]\n",
      "Total Loss G: 0.2314738780260086\n",
      "EPOCH [108/200], STEP [111/134]\n",
      "Total Loss G: 0.14652767777442932\n",
      "EPOCH [108/200], STEP [121/134]\n",
      "Total Loss G: 0.6198020577430725\n",
      "EPOCH [108/200], STEP [131/134]\n",
      "Total Loss G: 0.43600761890411377\n",
      "EPOCH [108/200], STEP [141/134]\n",
      "Total Loss G: 0.16517342627048492\n",
      "Training time is  0.941250757376353 mins\n",
      "Valid: 2-shot EPOCH [108/200], STEP [10/33]\n",
      "Total Loss V: 0.5124574303627014\n",
      "Valid: 2-shot EPOCH [108/200], STEP [20/33]\n",
      "Total Loss V: 0.33638378977775574\n",
      "Valid: 2-shot EPOCH [108/200], STEP [30/33]\n",
      "Total Loss V: 0.6659647822380066\n",
      "EPOCH [109/200], STEP [11/134]\n",
      "Total Loss G: 0.16714894771575928\n",
      "EPOCH [109/200], STEP [21/134]\n",
      "Total Loss G: 0.3827676773071289\n",
      "EPOCH [109/200], STEP [31/134]\n",
      "Total Loss G: 0.28282323479652405\n",
      "EPOCH [109/200], STEP [41/134]\n",
      "Total Loss G: 0.6533053517341614\n",
      "EPOCH [109/200], STEP [51/134]\n",
      "Total Loss G: 0.522442638874054\n",
      "EPOCH [109/200], STEP [61/134]\n",
      "Total Loss G: 0.2833116352558136\n",
      "EPOCH [109/200], STEP [71/134]\n",
      "Total Loss G: 0.29948532581329346\n",
      "EPOCH [109/200], STEP [81/134]\n",
      "Total Loss G: 0.12800556421279907\n",
      "EPOCH [109/200], STEP [91/134]\n",
      "Total Loss G: 0.2559936046600342\n",
      "EPOCH [109/200], STEP [101/134]\n",
      "Total Loss G: 0.23026131093502045\n",
      "EPOCH [109/200], STEP [111/134]\n",
      "Total Loss G: 0.2904495298862457\n",
      "EPOCH [109/200], STEP [121/134]\n",
      "Total Loss G: 0.5646011233329773\n",
      "EPOCH [109/200], STEP [131/134]\n",
      "Total Loss G: 0.2961418330669403\n",
      "EPOCH [109/200], STEP [141/134]\n",
      "Total Loss G: 0.1666736751794815\n",
      "Training time is  0.9429548541704814 mins\n",
      "Valid: 2-shot EPOCH [109/200], STEP [10/33]\n",
      "Total Loss V: 0.3810870051383972\n",
      "Valid: 2-shot EPOCH [109/200], STEP [20/33]\n",
      "Total Loss V: 0.43919217586517334\n",
      "Valid: 2-shot EPOCH [109/200], STEP [30/33]\n",
      "Total Loss V: 0.2443661093711853\n",
      "EPOCH [110/200], STEP [11/134]\n",
      "Total Loss G: 0.1942419707775116\n",
      "EPOCH [110/200], STEP [21/134]\n",
      "Total Loss G: 0.502741277217865\n",
      "EPOCH [110/200], STEP [31/134]\n",
      "Total Loss G: 0.1420287787914276\n",
      "EPOCH [110/200], STEP [41/134]\n",
      "Total Loss G: 0.6692444086074829\n",
      "EPOCH [110/200], STEP [51/134]\n",
      "Total Loss G: 0.314174085855484\n",
      "EPOCH [110/200], STEP [61/134]\n",
      "Total Loss G: 0.4003627300262451\n",
      "EPOCH [110/200], STEP [71/134]\n",
      "Total Loss G: 0.2675260305404663\n",
      "EPOCH [110/200], STEP [81/134]\n",
      "Total Loss G: 0.1784483641386032\n",
      "EPOCH [110/200], STEP [91/134]\n",
      "Total Loss G: 0.20867982506752014\n",
      "EPOCH [110/200], STEP [101/134]\n",
      "Total Loss G: 0.22848260402679443\n",
      "EPOCH [110/200], STEP [111/134]\n",
      "Total Loss G: 0.15671086311340332\n",
      "EPOCH [110/200], STEP [121/134]\n",
      "Total Loss G: 0.642414927482605\n",
      "EPOCH [110/200], STEP [131/134]\n",
      "Total Loss G: 0.3879280090332031\n",
      "EPOCH [110/200], STEP [141/134]\n",
      "Total Loss G: 0.15267814695835114\n",
      "Training time is  0.8528139074643453 mins\n",
      "Valid: 2-shot EPOCH [110/200], STEP [10/33]\n",
      "Total Loss V: 0.4896750748157501\n",
      "Valid: 2-shot EPOCH [110/200], STEP [20/33]\n",
      "Total Loss V: 0.34993433952331543\n",
      "Valid: 2-shot EPOCH [110/200], STEP [30/33]\n",
      "Total Loss V: 0.21550334990024567\n",
      "EPOCH [111/200], STEP [11/134]\n",
      "Total Loss G: 0.27488166093826294\n",
      "EPOCH [111/200], STEP [21/134]\n",
      "Total Loss G: 0.30546432733535767\n",
      "EPOCH [111/200], STEP [31/134]\n",
      "Total Loss G: 0.3311609923839569\n",
      "EPOCH [111/200], STEP [41/134]\n",
      "Total Loss G: 0.7226201891899109\n",
      "EPOCH [111/200], STEP [51/134]\n",
      "Total Loss G: 0.29421302676200867\n",
      "EPOCH [111/200], STEP [61/134]\n",
      "Total Loss G: 0.21975453197956085\n",
      "EPOCH [111/200], STEP [71/134]\n",
      "Total Loss G: 0.19477450847625732\n",
      "EPOCH [111/200], STEP [81/134]\n",
      "Total Loss G: 0.14175036549568176\n",
      "EPOCH [111/200], STEP [91/134]\n",
      "Total Loss G: 0.2500326931476593\n",
      "EPOCH [111/200], STEP [101/134]\n",
      "Total Loss G: 0.2593672573566437\n",
      "EPOCH [111/200], STEP [111/134]\n",
      "Total Loss G: 0.13936921954154968\n",
      "EPOCH [111/200], STEP [121/134]\n",
      "Total Loss G: 0.5253027081489563\n",
      "EPOCH [111/200], STEP [131/134]\n",
      "Total Loss G: 0.35825157165527344\n",
      "EPOCH [111/200], STEP [141/134]\n",
      "Total Loss G: 0.14859159290790558\n",
      "Training time is  0.826475449403127 mins\n",
      "Valid: 2-shot EPOCH [111/200], STEP [10/33]\n",
      "Total Loss V: 0.5028237104415894\n",
      "Valid: 2-shot EPOCH [111/200], STEP [20/33]\n",
      "Total Loss V: 0.3476358950138092\n",
      "Valid: 2-shot EPOCH [111/200], STEP [30/33]\n",
      "Total Loss V: 0.7963595390319824\n",
      "EPOCH [112/200], STEP [11/134]\n",
      "Total Loss G: 0.18825845420360565\n",
      "EPOCH [112/200], STEP [21/134]\n",
      "Total Loss G: 0.38142919540405273\n",
      "EPOCH [112/200], STEP [31/134]\n",
      "Total Loss G: 0.25035369396209717\n",
      "EPOCH [112/200], STEP [41/134]\n",
      "Total Loss G: 0.7240877151489258\n",
      "EPOCH [112/200], STEP [51/134]\n",
      "Total Loss G: 0.4497222304344177\n",
      "EPOCH [112/200], STEP [61/134]\n",
      "Total Loss G: 0.3259601294994354\n",
      "EPOCH [112/200], STEP [71/134]\n",
      "Total Loss G: 0.19666586816310883\n",
      "EPOCH [112/200], STEP [81/134]\n",
      "Total Loss G: 0.2647058367729187\n",
      "EPOCH [112/200], STEP [91/134]\n",
      "Total Loss G: 0.20278649032115936\n",
      "EPOCH [112/200], STEP [101/134]\n",
      "Total Loss G: 0.25107264518737793\n",
      "EPOCH [112/200], STEP [111/134]\n",
      "Total Loss G: 0.14910760521888733\n",
      "EPOCH [112/200], STEP [121/134]\n",
      "Total Loss G: 0.554240345954895\n",
      "EPOCH [112/200], STEP [131/134]\n",
      "Total Loss G: 0.3365879952907562\n",
      "EPOCH [112/200], STEP [141/134]\n",
      "Total Loss G: 0.1539498120546341\n",
      "Training time is  0.8301981250445049 mins\n",
      "Valid: 2-shot EPOCH [112/200], STEP [10/33]\n",
      "Total Loss V: 0.6762017607688904\n",
      "Valid: 2-shot EPOCH [112/200], STEP [20/33]\n",
      "Total Loss V: 0.3592669367790222\n",
      "Valid: 2-shot EPOCH [112/200], STEP [30/33]\n",
      "Total Loss V: 0.5982285737991333\n",
      "EPOCH [113/200], STEP [11/134]\n",
      "Total Loss G: 0.1714058667421341\n",
      "EPOCH [113/200], STEP [21/134]\n",
      "Total Loss G: 0.3857076168060303\n",
      "EPOCH [113/200], STEP [31/134]\n",
      "Total Loss G: 0.13822899758815765\n",
      "EPOCH [113/200], STEP [41/134]\n",
      "Total Loss G: 0.7120943069458008\n",
      "EPOCH [113/200], STEP [51/134]\n",
      "Total Loss G: 0.2424456924200058\n",
      "EPOCH [113/200], STEP [61/134]\n",
      "Total Loss G: 0.5166935920715332\n",
      "EPOCH [113/200], STEP [71/134]\n",
      "Total Loss G: 0.2084534913301468\n",
      "EPOCH [113/200], STEP [81/134]\n",
      "Total Loss G: 0.4612361788749695\n",
      "EPOCH [113/200], STEP [91/134]\n",
      "Total Loss G: 0.3727344870567322\n",
      "EPOCH [113/200], STEP [101/134]\n",
      "Total Loss G: 0.22766342759132385\n",
      "EPOCH [113/200], STEP [111/134]\n",
      "Total Loss G: 0.28196296095848083\n",
      "EPOCH [113/200], STEP [121/134]\n",
      "Total Loss G: 0.5500311851501465\n",
      "EPOCH [113/200], STEP [131/134]\n",
      "Total Loss G: 0.631509006023407\n",
      "EPOCH [113/200], STEP [141/134]\n",
      "Total Loss G: 0.16792331635951996\n",
      "Training time is  0.8303738633791605 mins\n",
      "Valid: 2-shot EPOCH [113/200], STEP [10/33]\n",
      "Total Loss V: 0.34442055225372314\n",
      "Valid: 2-shot EPOCH [113/200], STEP [20/33]\n",
      "Total Loss V: 0.3139632046222687\n",
      "Valid: 2-shot EPOCH [113/200], STEP [30/33]\n",
      "Total Loss V: 0.47045639157295227\n",
      "EPOCH [114/200], STEP [11/134]\n",
      "Total Loss G: 0.4826499819755554\n",
      "EPOCH [114/200], STEP [21/134]\n",
      "Total Loss G: 0.5265367031097412\n",
      "EPOCH [114/200], STEP [31/134]\n",
      "Total Loss G: 0.2178080976009369\n",
      "EPOCH [114/200], STEP [41/134]\n",
      "Total Loss G: 0.669547975063324\n",
      "EPOCH [114/200], STEP [51/134]\n",
      "Total Loss G: 0.4010073244571686\n",
      "EPOCH [114/200], STEP [61/134]\n",
      "Total Loss G: 0.4687008559703827\n",
      "EPOCH [114/200], STEP [71/134]\n",
      "Total Loss G: 0.33928269147872925\n",
      "EPOCH [114/200], STEP [81/134]\n",
      "Total Loss G: 0.14933031797409058\n",
      "EPOCH [114/200], STEP [91/134]\n",
      "Total Loss G: 0.2571529746055603\n",
      "EPOCH [114/200], STEP [101/134]\n",
      "Total Loss G: 0.23715713620185852\n",
      "EPOCH [114/200], STEP [111/134]\n",
      "Total Loss G: 0.18469049036502838\n",
      "EPOCH [114/200], STEP [121/134]\n",
      "Total Loss G: 0.59449303150177\n",
      "EPOCH [114/200], STEP [131/134]\n",
      "Total Loss G: 0.43583548069000244\n",
      "EPOCH [114/200], STEP [141/134]\n",
      "Total Loss G: 0.15961167216300964\n",
      "Training time is  0.8282859762509663 mins\n",
      "Valid: 2-shot EPOCH [114/200], STEP [10/33]\n",
      "Total Loss V: 0.3861165940761566\n",
      "Valid: 2-shot EPOCH [114/200], STEP [20/33]\n",
      "Total Loss V: 0.29508379101753235\n",
      "Valid: 2-shot EPOCH [114/200], STEP [30/33]\n",
      "Total Loss V: 0.27470046281814575\n",
      "EPOCH [115/200], STEP [11/134]\n",
      "Total Loss G: 0.1644209921360016\n",
      "EPOCH [115/200], STEP [21/134]\n",
      "Total Loss G: 0.3144555389881134\n",
      "EPOCH [115/200], STEP [31/134]\n",
      "Total Loss G: 0.1402575820684433\n",
      "EPOCH [115/200], STEP [41/134]\n",
      "Total Loss G: 0.7072390913963318\n",
      "EPOCH [115/200], STEP [51/134]\n",
      "Total Loss G: 0.2679043412208557\n",
      "EPOCH [115/200], STEP [61/134]\n",
      "Total Loss G: 0.32528528571128845\n",
      "EPOCH [115/200], STEP [71/134]\n",
      "Total Loss G: 0.21349968016147614\n",
      "EPOCH [115/200], STEP [81/134]\n",
      "Total Loss G: 0.2818487882614136\n",
      "EPOCH [115/200], STEP [91/134]\n",
      "Total Loss G: 0.277793288230896\n",
      "EPOCH [115/200], STEP [101/134]\n",
      "Total Loss G: 0.2652566730976105\n",
      "EPOCH [115/200], STEP [111/134]\n",
      "Total Loss G: 0.12818337976932526\n",
      "EPOCH [115/200], STEP [121/134]\n",
      "Total Loss G: 0.6456142663955688\n",
      "EPOCH [115/200], STEP [131/134]\n",
      "Total Loss G: 0.5477872490882874\n",
      "EPOCH [115/200], STEP [141/134]\n",
      "Total Loss G: 0.1534036546945572\n",
      "Training time is  0.8284028609593709 mins\n",
      "Valid: 2-shot EPOCH [115/200], STEP [10/33]\n",
      "Total Loss V: 0.3364650011062622\n",
      "Valid: 2-shot EPOCH [115/200], STEP [20/33]\n",
      "Total Loss V: 0.4672110080718994\n",
      "Valid: 2-shot EPOCH [115/200], STEP [30/33]\n",
      "Total Loss V: 0.4289875328540802\n",
      "EPOCH [116/200], STEP [11/134]\n",
      "Total Loss G: 0.1440781205892563\n",
      "EPOCH [116/200], STEP [21/134]\n",
      "Total Loss G: 0.4458397328853607\n",
      "EPOCH [116/200], STEP [31/134]\n",
      "Total Loss G: 0.14105400443077087\n",
      "EPOCH [116/200], STEP [41/134]\n",
      "Total Loss G: 0.7332096695899963\n",
      "EPOCH [116/200], STEP [51/134]\n",
      "Total Loss G: 0.4874022603034973\n",
      "EPOCH [116/200], STEP [61/134]\n",
      "Total Loss G: 0.5190494060516357\n",
      "EPOCH [116/200], STEP [71/134]\n",
      "Total Loss G: 0.3158186674118042\n",
      "EPOCH [116/200], STEP [81/134]\n",
      "Total Loss G: 0.1837364137172699\n",
      "EPOCH [116/200], STEP [91/134]\n",
      "Total Loss G: 0.22842255234718323\n",
      "EPOCH [116/200], STEP [101/134]\n",
      "Total Loss G: 0.2372589409351349\n",
      "EPOCH [116/200], STEP [111/134]\n",
      "Total Loss G: 0.1306581050157547\n",
      "EPOCH [116/200], STEP [121/134]\n",
      "Total Loss G: 0.5781066417694092\n",
      "EPOCH [116/200], STEP [131/134]\n",
      "Total Loss G: 0.5110489726066589\n",
      "EPOCH [116/200], STEP [141/134]\n",
      "Total Loss G: 0.17473356425762177\n",
      "Training time is  0.8322859525680542 mins\n",
      "Valid: 2-shot EPOCH [116/200], STEP [10/33]\n",
      "Total Loss V: 0.54475337266922\n",
      "Valid: 2-shot EPOCH [116/200], STEP [20/33]\n",
      "Total Loss V: 0.2576563358306885\n",
      "Valid: 2-shot EPOCH [116/200], STEP [30/33]\n",
      "Total Loss V: 0.31204885244369507\n",
      "EPOCH [117/200], STEP [11/134]\n",
      "Total Loss G: 0.14931485056877136\n",
      "EPOCH [117/200], STEP [21/134]\n",
      "Total Loss G: 0.39199796319007874\n",
      "EPOCH [117/200], STEP [31/134]\n",
      "Total Loss G: 0.16336099803447723\n",
      "EPOCH [117/200], STEP [41/134]\n",
      "Total Loss G: 0.7391276955604553\n",
      "EPOCH [117/200], STEP [51/134]\n",
      "Total Loss G: 0.2999916076660156\n",
      "EPOCH [117/200], STEP [61/134]\n",
      "Total Loss G: 0.1889367401599884\n",
      "EPOCH [117/200], STEP [71/134]\n",
      "Total Loss G: 0.3334578573703766\n",
      "EPOCH [117/200], STEP [81/134]\n",
      "Total Loss G: 0.14872868359088898\n",
      "EPOCH [117/200], STEP [91/134]\n",
      "Total Loss G: 0.19231824576854706\n",
      "EPOCH [117/200], STEP [101/134]\n",
      "Total Loss G: 0.2247205674648285\n",
      "EPOCH [117/200], STEP [111/134]\n",
      "Total Loss G: 0.19330348074436188\n",
      "EPOCH [117/200], STEP [121/134]\n",
      "Total Loss G: 0.7441226243972778\n",
      "EPOCH [117/200], STEP [131/134]\n",
      "Total Loss G: 0.41948187351226807\n",
      "EPOCH [117/200], STEP [141/134]\n",
      "Total Loss G: 0.16248099505901337\n",
      "Training time is  0.829967204729716 mins\n",
      "Valid: 2-shot EPOCH [117/200], STEP [10/33]\n",
      "Total Loss V: 0.5455273389816284\n",
      "Valid: 2-shot EPOCH [117/200], STEP [20/33]\n",
      "Total Loss V: 0.38139981031417847\n",
      "Valid: 2-shot EPOCH [117/200], STEP [30/33]\n",
      "Total Loss V: 0.3482379615306854\n",
      "EPOCH [118/200], STEP [11/134]\n",
      "Total Loss G: 0.1719556599855423\n",
      "EPOCH [118/200], STEP [21/134]\n",
      "Total Loss G: 0.31488466262817383\n",
      "EPOCH [118/200], STEP [31/134]\n",
      "Total Loss G: 0.17568954825401306\n",
      "EPOCH [118/200], STEP [41/134]\n",
      "Total Loss G: 0.657656729221344\n",
      "EPOCH [118/200], STEP [51/134]\n",
      "Total Loss G: 0.23134176433086395\n",
      "EPOCH [118/200], STEP [61/134]\n",
      "Total Loss G: 0.2014479637145996\n",
      "EPOCH [118/200], STEP [71/134]\n",
      "Total Loss G: 0.40071356296539307\n",
      "EPOCH [118/200], STEP [81/134]\n",
      "Total Loss G: 0.13850407302379608\n",
      "EPOCH [118/200], STEP [91/134]\n",
      "Total Loss G: 0.22302308678627014\n",
      "EPOCH [118/200], STEP [101/134]\n",
      "Total Loss G: 0.2480756938457489\n",
      "EPOCH [118/200], STEP [111/134]\n",
      "Total Loss G: 0.21108603477478027\n",
      "EPOCH [118/200], STEP [121/134]\n",
      "Total Loss G: 0.6548717617988586\n",
      "EPOCH [118/200], STEP [131/134]\n",
      "Total Loss G: 0.32376977801322937\n",
      "EPOCH [118/200], STEP [141/134]\n",
      "Total Loss G: 0.15278410911560059\n",
      "Training time is  0.82909228404363 mins\n",
      "Valid: 2-shot EPOCH [118/200], STEP [10/33]\n",
      "Total Loss V: 0.5070241689682007\n",
      "Valid: 2-shot EPOCH [118/200], STEP [20/33]\n",
      "Total Loss V: 0.5462253093719482\n",
      "Valid: 2-shot EPOCH [118/200], STEP [30/33]\n",
      "Total Loss V: 0.47634148597717285\n",
      "EPOCH [119/200], STEP [11/134]\n",
      "Total Loss G: 0.20148882269859314\n",
      "EPOCH [119/200], STEP [21/134]\n",
      "Total Loss G: 0.38736584782600403\n",
      "EPOCH [119/200], STEP [31/134]\n",
      "Total Loss G: 0.15721239149570465\n",
      "EPOCH [119/200], STEP [41/134]\n",
      "Total Loss G: 0.6493232250213623\n",
      "EPOCH [119/200], STEP [51/134]\n",
      "Total Loss G: 0.2897856831550598\n",
      "EPOCH [119/200], STEP [61/134]\n",
      "Total Loss G: 0.25477761030197144\n",
      "EPOCH [119/200], STEP [71/134]\n",
      "Total Loss G: 0.26229408383369446\n",
      "EPOCH [119/200], STEP [81/134]\n",
      "Total Loss G: 0.13509894907474518\n",
      "EPOCH [119/200], STEP [91/134]\n",
      "Total Loss G: 0.21560455858707428\n",
      "EPOCH [119/200], STEP [101/134]\n",
      "Total Loss G: 0.2127944827079773\n",
      "EPOCH [119/200], STEP [111/134]\n",
      "Total Loss G: 0.15527407824993134\n",
      "EPOCH [119/200], STEP [121/134]\n",
      "Total Loss G: 0.5266174674034119\n",
      "EPOCH [119/200], STEP [131/134]\n",
      "Total Loss G: 0.3519302308559418\n",
      "EPOCH [119/200], STEP [141/134]\n",
      "Total Loss G: 0.1543799489736557\n",
      "Training time is  0.8326576550801595 mins\n",
      "Valid: 2-shot EPOCH [119/200], STEP [10/33]\n",
      "Total Loss V: 0.585995614528656\n",
      "Valid: 2-shot EPOCH [119/200], STEP [20/33]\n",
      "Total Loss V: 0.3903072774410248\n",
      "Valid: 2-shot EPOCH [119/200], STEP [30/33]\n",
      "Total Loss V: 0.6188908219337463\n",
      "EPOCH [120/200], STEP [11/134]\n",
      "Total Loss G: 0.1728510558605194\n",
      "EPOCH [120/200], STEP [21/134]\n",
      "Total Loss G: 0.3542989492416382\n",
      "EPOCH [120/200], STEP [31/134]\n",
      "Total Loss G: 0.19964179396629333\n",
      "EPOCH [120/200], STEP [41/134]\n",
      "Total Loss G: 0.7039765119552612\n",
      "EPOCH [120/200], STEP [51/134]\n",
      "Total Loss G: 0.3738130033016205\n",
      "EPOCH [120/200], STEP [61/134]\n",
      "Total Loss G: 0.2416994720697403\n",
      "EPOCH [120/200], STEP [71/134]\n",
      "Total Loss G: 0.284644216299057\n",
      "EPOCH [120/200], STEP [81/134]\n",
      "Total Loss G: 0.1270049661397934\n",
      "EPOCH [120/200], STEP [91/134]\n",
      "Total Loss G: 0.25138041377067566\n",
      "EPOCH [120/200], STEP [101/134]\n",
      "Total Loss G: 0.2311612367630005\n",
      "EPOCH [120/200], STEP [111/134]\n",
      "Total Loss G: 0.1548587679862976\n",
      "EPOCH [120/200], STEP [121/134]\n",
      "Total Loss G: 0.6061511635780334\n",
      "EPOCH [120/200], STEP [131/134]\n",
      "Total Loss G: 0.3350130319595337\n",
      "EPOCH [120/200], STEP [141/134]\n",
      "Total Loss G: 0.14625564217567444\n",
      "Training time is  0.8298817674318949 mins\n",
      "Valid: 2-shot EPOCH [120/200], STEP [10/33]\n",
      "Total Loss V: 0.6263219118118286\n",
      "Valid: 2-shot EPOCH [120/200], STEP [20/33]\n",
      "Total Loss V: 0.572450578212738\n",
      "Valid: 2-shot EPOCH [120/200], STEP [30/33]\n",
      "Total Loss V: 0.6003645658493042\n",
      "EPOCH [121/200], STEP [11/134]\n",
      "Total Loss G: 0.1651868373155594\n",
      "EPOCH [121/200], STEP [21/134]\n",
      "Total Loss G: 0.4558958113193512\n",
      "EPOCH [121/200], STEP [31/134]\n",
      "Total Loss G: 0.10338141769170761\n",
      "EPOCH [121/200], STEP [41/134]\n",
      "Total Loss G: 0.618557870388031\n",
      "EPOCH [121/200], STEP [51/134]\n",
      "Total Loss G: 0.2046576589345932\n",
      "EPOCH [121/200], STEP [61/134]\n",
      "Total Loss G: 0.29353320598602295\n",
      "EPOCH [121/200], STEP [71/134]\n",
      "Total Loss G: 0.18575815856456757\n",
      "EPOCH [121/200], STEP [81/134]\n",
      "Total Loss G: 0.14300625026226044\n",
      "EPOCH [121/200], STEP [91/134]\n",
      "Total Loss G: 0.20834504067897797\n",
      "EPOCH [121/200], STEP [101/134]\n",
      "Total Loss G: 0.19811417162418365\n",
      "EPOCH [121/200], STEP [111/134]\n",
      "Total Loss G: 0.15220683813095093\n",
      "EPOCH [121/200], STEP [121/134]\n",
      "Total Loss G: 0.5424506664276123\n",
      "EPOCH [121/200], STEP [131/134]\n",
      "Total Loss G: 0.2960260212421417\n",
      "EPOCH [121/200], STEP [141/134]\n",
      "Total Loss G: 0.16529574990272522\n",
      "Training time is  0.8284210642178853 mins\n",
      "Valid: 2-shot EPOCH [121/200], STEP [10/33]\n",
      "Total Loss V: 0.6246946454048157\n",
      "Valid: 2-shot EPOCH [121/200], STEP [20/33]\n",
      "Total Loss V: 0.3422262668609619\n",
      "Valid: 2-shot EPOCH [121/200], STEP [30/33]\n",
      "Total Loss V: 0.8486623764038086\n",
      "EPOCH [122/200], STEP [11/134]\n",
      "Total Loss G: 0.1719953417778015\n",
      "EPOCH [122/200], STEP [21/134]\n",
      "Total Loss G: 0.309134840965271\n",
      "EPOCH [122/200], STEP [31/134]\n",
      "Total Loss G: 0.22893401980400085\n",
      "EPOCH [122/200], STEP [41/134]\n",
      "Total Loss G: 0.6634609699249268\n",
      "EPOCH [122/200], STEP [51/134]\n",
      "Total Loss G: 0.43519309163093567\n",
      "EPOCH [122/200], STEP [61/134]\n",
      "Total Loss G: 0.3601333796977997\n",
      "EPOCH [122/200], STEP [71/134]\n",
      "Total Loss G: 0.6810632348060608\n",
      "EPOCH [122/200], STEP [81/134]\n",
      "Total Loss G: 0.1532040387392044\n",
      "EPOCH [122/200], STEP [91/134]\n",
      "Total Loss G: 0.18562467396259308\n",
      "EPOCH [122/200], STEP [101/134]\n",
      "Total Loss G: 0.2575550377368927\n",
      "EPOCH [122/200], STEP [111/134]\n",
      "Total Loss G: 0.17029941082000732\n",
      "EPOCH [122/200], STEP [121/134]\n",
      "Total Loss G: 0.5732595324516296\n",
      "EPOCH [122/200], STEP [131/134]\n",
      "Total Loss G: 0.41570866107940674\n",
      "EPOCH [122/200], STEP [141/134]\n",
      "Total Loss G: 0.17309997975826263\n",
      "Training time is  0.8278217871983846 mins\n",
      "Valid: 2-shot EPOCH [122/200], STEP [10/33]\n",
      "Total Loss V: 0.5962886810302734\n",
      "Valid: 2-shot EPOCH [122/200], STEP [20/33]\n",
      "Total Loss V: 0.36250072717666626\n",
      "Valid: 2-shot EPOCH [122/200], STEP [30/33]\n",
      "Total Loss V: 0.37469613552093506\n",
      "EPOCH [123/200], STEP [11/134]\n",
      "Total Loss G: 0.16205322742462158\n",
      "EPOCH [123/200], STEP [21/134]\n",
      "Total Loss G: 0.29912370443344116\n",
      "EPOCH [123/200], STEP [31/134]\n",
      "Total Loss G: 0.12417963892221451\n",
      "EPOCH [123/200], STEP [41/134]\n",
      "Total Loss G: 0.6530230045318604\n",
      "EPOCH [123/200], STEP [51/134]\n",
      "Total Loss G: 0.5556777715682983\n",
      "EPOCH [123/200], STEP [61/134]\n",
      "Total Loss G: 0.20898620784282684\n",
      "EPOCH [123/200], STEP [71/134]\n",
      "Total Loss G: 0.17800526320934296\n",
      "EPOCH [123/200], STEP [81/134]\n",
      "Total Loss G: 0.15245574712753296\n",
      "EPOCH [123/200], STEP [91/134]\n",
      "Total Loss G: 0.21993987262248993\n",
      "EPOCH [123/200], STEP [101/134]\n",
      "Total Loss G: 0.2097376435995102\n",
      "EPOCH [123/200], STEP [111/134]\n",
      "Total Loss G: 0.1353481262922287\n",
      "EPOCH [123/200], STEP [121/134]\n",
      "Total Loss G: 0.5393610596656799\n",
      "EPOCH [123/200], STEP [131/134]\n",
      "Total Loss G: 0.3632342219352722\n",
      "EPOCH [123/200], STEP [141/134]\n",
      "Total Loss G: 0.16792796552181244\n",
      "Training time is  0.8302807052930196 mins\n",
      "Valid: 2-shot EPOCH [123/200], STEP [10/33]\n",
      "Total Loss V: 0.6606070399284363\n",
      "Valid: 2-shot EPOCH [123/200], STEP [20/33]\n",
      "Total Loss V: 0.5873509645462036\n",
      "Valid: 2-shot EPOCH [123/200], STEP [30/33]\n",
      "Total Loss V: 0.5753762125968933\n",
      "EPOCH [124/200], STEP [11/134]\n",
      "Total Loss G: 0.18260011076927185\n",
      "EPOCH [124/200], STEP [21/134]\n",
      "Total Loss G: 0.35865986347198486\n",
      "EPOCH [124/200], STEP [31/134]\n",
      "Total Loss G: 0.22141218185424805\n",
      "EPOCH [124/200], STEP [41/134]\n",
      "Total Loss G: 0.6863074898719788\n",
      "EPOCH [124/200], STEP [51/134]\n",
      "Total Loss G: 0.1482720971107483\n",
      "EPOCH [124/200], STEP [61/134]\n",
      "Total Loss G: 0.20800091326236725\n",
      "EPOCH [124/200], STEP [71/134]\n",
      "Total Loss G: 0.19429919123649597\n",
      "EPOCH [124/200], STEP [81/134]\n",
      "Total Loss G: 0.1289558857679367\n",
      "EPOCH [124/200], STEP [91/134]\n",
      "Total Loss G: 0.2011873573064804\n",
      "EPOCH [124/200], STEP [101/134]\n",
      "Total Loss G: 0.19708964228630066\n",
      "EPOCH [124/200], STEP [111/134]\n",
      "Total Loss G: 0.13373294472694397\n",
      "EPOCH [124/200], STEP [121/134]\n",
      "Total Loss G: 0.512292206287384\n",
      "EPOCH [124/200], STEP [131/134]\n",
      "Total Loss G: 0.3486534357070923\n",
      "EPOCH [124/200], STEP [141/134]\n",
      "Total Loss G: 0.16733720898628235\n",
      "Training time is  0.8294081330299378 mins\n",
      "Valid: 2-shot EPOCH [124/200], STEP [10/33]\n",
      "Total Loss V: 0.6234834790229797\n",
      "Valid: 2-shot EPOCH [124/200], STEP [20/33]\n",
      "Total Loss V: 0.6939635872840881\n",
      "Valid: 2-shot EPOCH [124/200], STEP [30/33]\n",
      "Total Loss V: 0.3398323357105255\n",
      "EPOCH [125/200], STEP [11/134]\n",
      "Total Loss G: 0.16823716461658478\n",
      "EPOCH [125/200], STEP [21/134]\n",
      "Total Loss G: 0.2777189314365387\n",
      "EPOCH [125/200], STEP [31/134]\n",
      "Total Loss G: 0.15139105916023254\n",
      "EPOCH [125/200], STEP [41/134]\n",
      "Total Loss G: 0.6412845849990845\n",
      "EPOCH [125/200], STEP [51/134]\n",
      "Total Loss G: 0.2390080690383911\n",
      "EPOCH [125/200], STEP [61/134]\n",
      "Total Loss G: 0.2170667052268982\n",
      "EPOCH [125/200], STEP [71/134]\n",
      "Total Loss G: 0.2577167749404907\n",
      "EPOCH [125/200], STEP [81/134]\n",
      "Total Loss G: 0.12628304958343506\n",
      "EPOCH [125/200], STEP [91/134]\n",
      "Total Loss G: 0.20377089083194733\n",
      "EPOCH [125/200], STEP [101/134]\n",
      "Total Loss G: 0.20119453966617584\n",
      "EPOCH [125/200], STEP [111/134]\n",
      "Total Loss G: 0.14895090460777283\n",
      "EPOCH [125/200], STEP [121/134]\n",
      "Total Loss G: 0.5532090663909912\n",
      "EPOCH [125/200], STEP [131/134]\n",
      "Total Loss G: 0.328183650970459\n",
      "EPOCH [125/200], STEP [141/134]\n",
      "Total Loss G: 0.17236967384815216\n",
      "Training time is  0.8277546008427937 mins\n",
      "Valid: 2-shot EPOCH [125/200], STEP [10/33]\n",
      "Total Loss V: 0.6063529253005981\n",
      "Valid: 2-shot EPOCH [125/200], STEP [20/33]\n",
      "Total Loss V: 0.5302479267120361\n",
      "Valid: 2-shot EPOCH [125/200], STEP [30/33]\n",
      "Total Loss V: 0.7023937702178955\n",
      "EPOCH [126/200], STEP [11/134]\n",
      "Total Loss G: 0.1535169631242752\n",
      "EPOCH [126/200], STEP [21/134]\n",
      "Total Loss G: 0.3299889862537384\n",
      "EPOCH [126/200], STEP [31/134]\n",
      "Total Loss G: 0.1324259340763092\n",
      "EPOCH [126/200], STEP [41/134]\n",
      "Total Loss G: 0.619884192943573\n",
      "EPOCH [126/200], STEP [51/134]\n",
      "Total Loss G: 0.2565597891807556\n",
      "EPOCH [126/200], STEP [61/134]\n",
      "Total Loss G: 0.21656569838523865\n",
      "EPOCH [126/200], STEP [71/134]\n",
      "Total Loss G: 0.5455613136291504\n",
      "EPOCH [126/200], STEP [81/134]\n",
      "Total Loss G: 0.14730432629585266\n",
      "EPOCH [126/200], STEP [91/134]\n",
      "Total Loss G: 0.21295584738254547\n",
      "EPOCH [126/200], STEP [101/134]\n",
      "Total Loss G: 0.21234577894210815\n",
      "EPOCH [126/200], STEP [111/134]\n",
      "Total Loss G: 0.1173984706401825\n",
      "EPOCH [126/200], STEP [121/134]\n",
      "Total Loss G: 0.7197694182395935\n",
      "EPOCH [126/200], STEP [131/134]\n",
      "Total Loss G: 0.33189845085144043\n",
      "EPOCH [126/200], STEP [141/134]\n",
      "Total Loss G: 0.1453930139541626\n",
      "Training time is  0.8314775069554646 mins\n",
      "Valid: 2-shot EPOCH [126/200], STEP [10/33]\n",
      "Total Loss V: 0.49042192101478577\n",
      "Valid: 2-shot EPOCH [126/200], STEP [20/33]\n",
      "Total Loss V: 0.38301220536231995\n",
      "Valid: 2-shot EPOCH [126/200], STEP [30/33]\n",
      "Total Loss V: 0.24658028781414032\n",
      "EPOCH [127/200], STEP [11/134]\n",
      "Total Loss G: 0.17137309908866882\n",
      "EPOCH [127/200], STEP [21/134]\n",
      "Total Loss G: 0.2581072747707367\n",
      "EPOCH [127/200], STEP [31/134]\n",
      "Total Loss G: 0.2488517314195633\n",
      "EPOCH [127/200], STEP [41/134]\n",
      "Total Loss G: 0.6446657776832581\n",
      "EPOCH [127/200], STEP [51/134]\n",
      "Total Loss G: 0.369686484336853\n",
      "EPOCH [127/200], STEP [61/134]\n",
      "Total Loss G: 0.21279674768447876\n",
      "EPOCH [127/200], STEP [71/134]\n",
      "Total Loss G: 0.33200499415397644\n",
      "EPOCH [127/200], STEP [81/134]\n",
      "Total Loss G: 0.14385740458965302\n",
      "EPOCH [127/200], STEP [91/134]\n",
      "Total Loss G: 0.18632622063159943\n",
      "EPOCH [127/200], STEP [101/134]\n",
      "Total Loss G: 0.2345784455537796\n",
      "EPOCH [127/200], STEP [111/134]\n",
      "Total Loss G: 0.13751673698425293\n",
      "EPOCH [127/200], STEP [121/134]\n",
      "Total Loss G: 0.5207580924034119\n",
      "EPOCH [127/200], STEP [131/134]\n",
      "Total Loss G: 0.3388948440551758\n",
      "EPOCH [127/200], STEP [141/134]\n",
      "Total Loss G: 0.1530400514602661\n",
      "Training time is  0.8391883174578348 mins\n",
      "Valid: 2-shot EPOCH [127/200], STEP [10/33]\n",
      "Total Loss V: 0.6652398109436035\n",
      "Valid: 2-shot EPOCH [127/200], STEP [20/33]\n",
      "Total Loss V: 0.3405398428440094\n",
      "Valid: 2-shot EPOCH [127/200], STEP [30/33]\n",
      "Total Loss V: 0.427941232919693\n",
      "EPOCH [128/200], STEP [11/134]\n",
      "Total Loss G: 0.16743096709251404\n",
      "EPOCH [128/200], STEP [21/134]\n",
      "Total Loss G: 0.38018643856048584\n",
      "EPOCH [128/200], STEP [31/134]\n",
      "Total Loss G: 0.1437501758337021\n",
      "EPOCH [128/200], STEP [41/134]\n",
      "Total Loss G: 0.652627170085907\n",
      "EPOCH [128/200], STEP [51/134]\n",
      "Total Loss G: 0.31024083495140076\n",
      "EPOCH [128/200], STEP [61/134]\n",
      "Total Loss G: 0.37250208854675293\n",
      "EPOCH [128/200], STEP [71/134]\n",
      "Total Loss G: 0.28311389684677124\n",
      "EPOCH [128/200], STEP [81/134]\n",
      "Total Loss G: 0.3620268702507019\n",
      "EPOCH [128/200], STEP [91/134]\n",
      "Total Loss G: 0.2592087388038635\n",
      "EPOCH [128/200], STEP [101/134]\n",
      "Total Loss G: 0.19000136852264404\n",
      "EPOCH [128/200], STEP [111/134]\n",
      "Total Loss G: 0.12296896427869797\n",
      "EPOCH [128/200], STEP [121/134]\n",
      "Total Loss G: 0.5987219214439392\n",
      "EPOCH [128/200], STEP [131/134]\n",
      "Total Loss G: 0.34861326217651367\n",
      "EPOCH [128/200], STEP [141/134]\n",
      "Total Loss G: 0.14376991987228394\n",
      "Training time is  0.8332727114359538 mins\n",
      "Valid: 2-shot EPOCH [128/200], STEP [10/33]\n",
      "Total Loss V: 0.6296910047531128\n",
      "Valid: 2-shot EPOCH [128/200], STEP [20/33]\n",
      "Total Loss V: 0.6955733299255371\n",
      "Valid: 2-shot EPOCH [128/200], STEP [30/33]\n",
      "Total Loss V: 0.17560477554798126\n",
      "EPOCH [129/200], STEP [11/134]\n",
      "Total Loss G: 0.16502833366394043\n",
      "EPOCH [129/200], STEP [21/134]\n",
      "Total Loss G: 0.3329768478870392\n",
      "EPOCH [129/200], STEP [31/134]\n",
      "Total Loss G: 0.18739305436611176\n",
      "EPOCH [129/200], STEP [41/134]\n",
      "Total Loss G: 0.6714414954185486\n",
      "EPOCH [129/200], STEP [51/134]\n",
      "Total Loss G: 0.15689727663993835\n",
      "EPOCH [129/200], STEP [61/134]\n",
      "Total Loss G: 0.26494085788726807\n",
      "EPOCH [129/200], STEP [71/134]\n",
      "Total Loss G: 0.190499946475029\n",
      "EPOCH [129/200], STEP [81/134]\n",
      "Total Loss G: 0.14305128157138824\n",
      "EPOCH [129/200], STEP [91/134]\n",
      "Total Loss G: 0.15816695988178253\n",
      "EPOCH [129/200], STEP [101/134]\n",
      "Total Loss G: 0.20097088813781738\n",
      "EPOCH [129/200], STEP [111/134]\n",
      "Total Loss G: 0.12062051147222519\n",
      "EPOCH [129/200], STEP [121/134]\n",
      "Total Loss G: 0.555101752281189\n",
      "EPOCH [129/200], STEP [131/134]\n",
      "Total Loss G: 0.3495931923389435\n",
      "EPOCH [129/200], STEP [141/134]\n",
      "Total Loss G: 0.18819832801818848\n",
      "Training time is  0.8306226770083109 mins\n",
      "Valid: 2-shot EPOCH [129/200], STEP [10/33]\n",
      "Total Loss V: 0.5750612616539001\n",
      "Valid: 2-shot EPOCH [129/200], STEP [20/33]\n",
      "Total Loss V: 0.26939553022384644\n",
      "Valid: 2-shot EPOCH [129/200], STEP [30/33]\n",
      "Total Loss V: 0.545669674873352\n",
      "EPOCH [130/200], STEP [11/134]\n",
      "Total Loss G: 0.15414737164974213\n",
      "EPOCH [130/200], STEP [21/134]\n",
      "Total Loss G: 0.3395080864429474\n",
      "EPOCH [130/200], STEP [31/134]\n",
      "Total Loss G: 0.18093299865722656\n",
      "EPOCH [130/200], STEP [41/134]\n",
      "Total Loss G: 0.661298394203186\n",
      "EPOCH [130/200], STEP [51/134]\n",
      "Total Loss G: 0.22010982036590576\n",
      "EPOCH [130/200], STEP [61/134]\n",
      "Total Loss G: 0.217200368642807\n",
      "EPOCH [130/200], STEP [71/134]\n",
      "Total Loss G: 0.22096867859363556\n",
      "EPOCH [130/200], STEP [81/134]\n",
      "Total Loss G: 0.24385961890220642\n",
      "EPOCH [130/200], STEP [91/134]\n",
      "Total Loss G: 0.22011734545230865\n",
      "EPOCH [130/200], STEP [101/134]\n",
      "Total Loss G: 0.20106957852840424\n",
      "EPOCH [130/200], STEP [111/134]\n",
      "Total Loss G: 0.11702194809913635\n",
      "EPOCH [130/200], STEP [121/134]\n",
      "Total Loss G: 0.5367428064346313\n",
      "EPOCH [130/200], STEP [131/134]\n",
      "Total Loss G: 0.3056829571723938\n",
      "EPOCH [130/200], STEP [141/134]\n",
      "Total Loss G: 0.14264161884784698\n",
      "Training time is  0.8318100968996683 mins\n",
      "Valid: 2-shot EPOCH [130/200], STEP [10/33]\n",
      "Total Loss V: 0.6756831407546997\n",
      "Valid: 2-shot EPOCH [130/200], STEP [20/33]\n",
      "Total Loss V: 0.7366474866867065\n",
      "Valid: 2-shot EPOCH [130/200], STEP [30/33]\n",
      "Total Loss V: 0.3402821123600006\n",
      "EPOCH [131/200], STEP [11/134]\n",
      "Total Loss G: 0.14404265582561493\n",
      "EPOCH [131/200], STEP [21/134]\n",
      "Total Loss G: 0.2769753932952881\n",
      "EPOCH [131/200], STEP [31/134]\n",
      "Total Loss G: 0.11595474928617477\n",
      "EPOCH [131/200], STEP [41/134]\n",
      "Total Loss G: 0.6656935214996338\n",
      "EPOCH [131/200], STEP [51/134]\n",
      "Total Loss G: 0.20559769868850708\n",
      "EPOCH [131/200], STEP [61/134]\n",
      "Total Loss G: 0.23341715335845947\n",
      "EPOCH [131/200], STEP [71/134]\n",
      "Total Loss G: 0.16698713600635529\n",
      "EPOCH [131/200], STEP [81/134]\n",
      "Total Loss G: 0.1225762888789177\n",
      "EPOCH [131/200], STEP [91/134]\n",
      "Total Loss G: 0.23338302969932556\n",
      "EPOCH [131/200], STEP [101/134]\n",
      "Total Loss G: 0.19968894124031067\n",
      "EPOCH [131/200], STEP [111/134]\n",
      "Total Loss G: 0.13735957443714142\n",
      "EPOCH [131/200], STEP [121/134]\n",
      "Total Loss G: 0.6551089286804199\n",
      "EPOCH [131/200], STEP [131/134]\n",
      "Total Loss G: 0.34402549266815186\n",
      "EPOCH [131/200], STEP [141/134]\n",
      "Total Loss G: 0.16241168975830078\n",
      "Training time is  0.829333217938741 mins\n",
      "Valid: 2-shot EPOCH [131/200], STEP [10/33]\n",
      "Total Loss V: 0.5856842994689941\n",
      "Valid: 2-shot EPOCH [131/200], STEP [20/33]\n",
      "Total Loss V: 0.3734595775604248\n",
      "Valid: 2-shot EPOCH [131/200], STEP [30/33]\n",
      "Total Loss V: 0.3619765341281891\n",
      "EPOCH [132/200], STEP [11/134]\n",
      "Total Loss G: 0.13945943117141724\n",
      "EPOCH [132/200], STEP [21/134]\n",
      "Total Loss G: 0.3387262523174286\n",
      "EPOCH [132/200], STEP [31/134]\n",
      "Total Loss G: 0.09824758023023605\n",
      "EPOCH [132/200], STEP [41/134]\n",
      "Total Loss G: 0.6402184367179871\n",
      "EPOCH [132/200], STEP [51/134]\n",
      "Total Loss G: 0.17469771206378937\n",
      "EPOCH [132/200], STEP [61/134]\n",
      "Total Loss G: 0.2683102786540985\n",
      "EPOCH [132/200], STEP [71/134]\n",
      "Total Loss G: 0.19335365295410156\n",
      "EPOCH [132/200], STEP [81/134]\n",
      "Total Loss G: 0.14117465913295746\n",
      "EPOCH [132/200], STEP [91/134]\n",
      "Total Loss G: 0.17849008738994598\n",
      "EPOCH [132/200], STEP [101/134]\n",
      "Total Loss G: 0.22922730445861816\n",
      "EPOCH [132/200], STEP [111/134]\n",
      "Total Loss G: 0.1425192654132843\n",
      "EPOCH [132/200], STEP [121/134]\n",
      "Total Loss G: 0.5660600066184998\n",
      "EPOCH [132/200], STEP [131/134]\n",
      "Total Loss G: 0.2992693781852722\n",
      "EPOCH [132/200], STEP [141/134]\n",
      "Total Loss G: 0.1877700388431549\n",
      "Training time is  0.8333393812179566 mins\n",
      "Valid: 2-shot EPOCH [132/200], STEP [10/33]\n",
      "Total Loss V: 0.6058518886566162\n",
      "Valid: 2-shot EPOCH [132/200], STEP [20/33]\n",
      "Total Loss V: 0.6479678750038147\n",
      "Valid: 2-shot EPOCH [132/200], STEP [30/33]\n",
      "Total Loss V: 0.8439009189605713\n",
      "EPOCH [133/200], STEP [11/134]\n",
      "Total Loss G: 0.22918671369552612\n",
      "EPOCH [133/200], STEP [21/134]\n",
      "Total Loss G: 0.334541916847229\n",
      "EPOCH [133/200], STEP [31/134]\n",
      "Total Loss G: 0.13025394082069397\n",
      "EPOCH [133/200], STEP [41/134]\n",
      "Total Loss G: 0.6475652456283569\n",
      "EPOCH [133/200], STEP [51/134]\n",
      "Total Loss G: 0.14843270182609558\n",
      "EPOCH [133/200], STEP [61/134]\n",
      "Total Loss G: 0.2459167093038559\n",
      "EPOCH [133/200], STEP [71/134]\n",
      "Total Loss G: 0.36471331119537354\n",
      "EPOCH [133/200], STEP [81/134]\n",
      "Total Loss G: 0.17462705075740814\n",
      "EPOCH [133/200], STEP [91/134]\n",
      "Total Loss G: 0.22316808998584747\n",
      "EPOCH [133/200], STEP [101/134]\n",
      "Total Loss G: 0.2505366802215576\n",
      "EPOCH [133/200], STEP [111/134]\n",
      "Total Loss G: 0.16900627315044403\n",
      "EPOCH [133/200], STEP [121/134]\n",
      "Total Loss G: 0.5814754366874695\n",
      "EPOCH [133/200], STEP [131/134]\n",
      "Total Loss G: 0.29300522804260254\n",
      "EPOCH [133/200], STEP [141/134]\n",
      "Total Loss G: 0.16273699700832367\n",
      "Training time is  0.8316272894541422 mins\n",
      "Valid: 2-shot EPOCH [133/200], STEP [10/33]\n",
      "Total Loss V: 0.6000955104827881\n",
      "Valid: 2-shot EPOCH [133/200], STEP [20/33]\n",
      "Total Loss V: 0.4572417438030243\n",
      "Valid: 2-shot EPOCH [133/200], STEP [30/33]\n",
      "Total Loss V: 0.5226877331733704\n",
      "EPOCH [134/200], STEP [11/134]\n",
      "Total Loss G: 0.1693515032529831\n",
      "EPOCH [134/200], STEP [21/134]\n",
      "Total Loss G: 0.35976842045783997\n",
      "EPOCH [134/200], STEP [31/134]\n",
      "Total Loss G: 0.12041543424129486\n",
      "EPOCH [134/200], STEP [41/134]\n",
      "Total Loss G: 0.66127610206604\n",
      "EPOCH [134/200], STEP [51/134]\n",
      "Total Loss G: 0.21327990293502808\n",
      "EPOCH [134/200], STEP [61/134]\n",
      "Total Loss G: 0.3745024502277374\n",
      "EPOCH [134/200], STEP [71/134]\n",
      "Total Loss G: 0.18544749915599823\n",
      "EPOCH [134/200], STEP [81/134]\n",
      "Total Loss G: 0.14246435463428497\n",
      "EPOCH [134/200], STEP [91/134]\n",
      "Total Loss G: 0.24684755504131317\n",
      "EPOCH [134/200], STEP [101/134]\n",
      "Total Loss G: 0.2023085504770279\n",
      "EPOCH [134/200], STEP [111/134]\n",
      "Total Loss G: 0.11480866372585297\n",
      "EPOCH [134/200], STEP [121/134]\n",
      "Total Loss G: 0.5060423612594604\n",
      "EPOCH [134/200], STEP [131/134]\n",
      "Total Loss G: 0.3266270160675049\n",
      "EPOCH [134/200], STEP [141/134]\n",
      "Total Loss G: 0.16099482774734497\n",
      "Training time is  0.8306297739346822 mins\n",
      "Valid: 2-shot EPOCH [134/200], STEP [10/33]\n",
      "Total Loss V: 0.5576985478401184\n",
      "Valid: 2-shot EPOCH [134/200], STEP [20/33]\n",
      "Total Loss V: 0.26149895787239075\n",
      "Valid: 2-shot EPOCH [134/200], STEP [30/33]\n",
      "Total Loss V: 0.3053530156612396\n",
      "EPOCH [135/200], STEP [11/134]\n",
      "Total Loss G: 0.15499550104141235\n",
      "EPOCH [135/200], STEP [21/134]\n",
      "Total Loss G: 0.39022019505500793\n",
      "EPOCH [135/200], STEP [31/134]\n",
      "Total Loss G: 0.24729153513908386\n",
      "EPOCH [135/200], STEP [41/134]\n",
      "Total Loss G: 0.7273238897323608\n",
      "EPOCH [135/200], STEP [51/134]\n",
      "Total Loss G: 0.2621871829032898\n",
      "EPOCH [135/200], STEP [61/134]\n",
      "Total Loss G: 0.2115243375301361\n",
      "EPOCH [135/200], STEP [71/134]\n",
      "Total Loss G: 0.15461239218711853\n",
      "EPOCH [135/200], STEP [81/134]\n",
      "Total Loss G: 0.19799746572971344\n",
      "EPOCH [135/200], STEP [91/134]\n",
      "Total Loss G: 0.27042895555496216\n",
      "EPOCH [135/200], STEP [101/134]\n",
      "Total Loss G: 0.23185665905475616\n",
      "EPOCH [135/200], STEP [111/134]\n",
      "Total Loss G: 0.12321359664201736\n",
      "EPOCH [135/200], STEP [121/134]\n",
      "Total Loss G: 0.556119978427887\n",
      "EPOCH [135/200], STEP [131/134]\n",
      "Total Loss G: 0.3278089165687561\n",
      "EPOCH [135/200], STEP [141/134]\n",
      "Total Loss G: 0.13720649480819702\n",
      "Training time is  0.8345194339752198 mins\n",
      "Valid: 2-shot EPOCH [135/200], STEP [10/33]\n",
      "Total Loss V: 0.5219334363937378\n",
      "Valid: 2-shot EPOCH [135/200], STEP [20/33]\n",
      "Total Loss V: 0.2553710639476776\n",
      "Valid: 2-shot EPOCH [135/200], STEP [30/33]\n",
      "Total Loss V: 0.4292844831943512\n",
      "EPOCH [136/200], STEP [11/134]\n",
      "Total Loss G: 0.13338854908943176\n",
      "EPOCH [136/200], STEP [21/134]\n",
      "Total Loss G: 0.31018584966659546\n",
      "EPOCH [136/200], STEP [31/134]\n",
      "Total Loss G: 0.11065623909235\n",
      "EPOCH [136/200], STEP [41/134]\n",
      "Total Loss G: 0.6633234620094299\n",
      "EPOCH [136/200], STEP [51/134]\n",
      "Total Loss G: 0.18889503180980682\n",
      "EPOCH [136/200], STEP [61/134]\n",
      "Total Loss G: 0.3409457802772522\n",
      "EPOCH [136/200], STEP [71/134]\n",
      "Total Loss G: 0.21495671570301056\n",
      "EPOCH [136/200], STEP [81/134]\n",
      "Total Loss G: 0.1380660980939865\n",
      "EPOCH [136/200], STEP [91/134]\n",
      "Total Loss G: 0.15499888360500336\n",
      "EPOCH [136/200], STEP [101/134]\n",
      "Total Loss G: 0.2002720683813095\n",
      "EPOCH [136/200], STEP [111/134]\n",
      "Total Loss G: 0.11748851090669632\n",
      "EPOCH [136/200], STEP [121/134]\n",
      "Total Loss G: 0.556637704372406\n",
      "EPOCH [136/200], STEP [131/134]\n",
      "Total Loss G: 0.31280991435050964\n",
      "EPOCH [136/200], STEP [141/134]\n",
      "Total Loss G: 0.13253502547740936\n",
      "Training time is  0.8317571957906087 mins\n",
      "Valid: 2-shot EPOCH [136/200], STEP [10/33]\n",
      "Total Loss V: 0.46551114320755005\n",
      "Valid: 2-shot EPOCH [136/200], STEP [20/33]\n",
      "Total Loss V: 0.6258735060691833\n",
      "Valid: 2-shot EPOCH [136/200], STEP [30/33]\n",
      "Total Loss V: 0.23544910550117493\n",
      "EPOCH [137/200], STEP [11/134]\n",
      "Total Loss G: 0.13920488953590393\n",
      "EPOCH [137/200], STEP [21/134]\n",
      "Total Loss G: 0.3153502345085144\n",
      "EPOCH [137/200], STEP [31/134]\n",
      "Total Loss G: 0.1289183497428894\n",
      "EPOCH [137/200], STEP [41/134]\n",
      "Total Loss G: 0.6580179333686829\n",
      "EPOCH [137/200], STEP [51/134]\n",
      "Total Loss G: 0.1886170506477356\n",
      "EPOCH [137/200], STEP [61/134]\n",
      "Total Loss G: 0.2584626078605652\n",
      "EPOCH [137/200], STEP [71/134]\n",
      "Total Loss G: 0.26545268297195435\n",
      "EPOCH [137/200], STEP [81/134]\n",
      "Total Loss G: 0.12813207507133484\n",
      "EPOCH [137/200], STEP [91/134]\n",
      "Total Loss G: 0.20284251868724823\n",
      "EPOCH [137/200], STEP [101/134]\n",
      "Total Loss G: 0.2128167748451233\n",
      "EPOCH [137/200], STEP [111/134]\n",
      "Total Loss G: 0.11963558197021484\n",
      "EPOCH [137/200], STEP [121/134]\n",
      "Total Loss G: 0.5382669568061829\n",
      "EPOCH [137/200], STEP [131/134]\n",
      "Total Loss G: 0.32737860083580017\n",
      "EPOCH [137/200], STEP [141/134]\n",
      "Total Loss G: 0.1390429139137268\n",
      "Training time is  0.8293499231338501 mins\n",
      "Valid: 2-shot EPOCH [137/200], STEP [10/33]\n",
      "Total Loss V: 0.42026418447494507\n",
      "Valid: 2-shot EPOCH [137/200], STEP [20/33]\n",
      "Total Loss V: 0.4326804578304291\n",
      "Valid: 2-shot EPOCH [137/200], STEP [30/33]\n",
      "Total Loss V: 0.2843526005744934\n",
      "EPOCH [138/200], STEP [11/134]\n",
      "Total Loss G: 0.21592631936073303\n",
      "EPOCH [138/200], STEP [21/134]\n",
      "Total Loss G: 0.3591004014015198\n",
      "EPOCH [138/200], STEP [31/134]\n",
      "Total Loss G: 0.10971207916736603\n",
      "EPOCH [138/200], STEP [41/134]\n",
      "Total Loss G: 0.7500849366188049\n",
      "EPOCH [138/200], STEP [51/134]\n",
      "Total Loss G: 0.25638726353645325\n",
      "EPOCH [138/200], STEP [61/134]\n",
      "Total Loss G: 0.36039209365844727\n",
      "EPOCH [138/200], STEP [71/134]\n",
      "Total Loss G: 0.1976446509361267\n",
      "EPOCH [138/200], STEP [81/134]\n",
      "Total Loss G: 0.12748217582702637\n",
      "EPOCH [138/200], STEP [91/134]\n",
      "Total Loss G: 0.25166383385658264\n",
      "EPOCH [138/200], STEP [101/134]\n",
      "Total Loss G: 0.23776951432228088\n",
      "EPOCH [138/200], STEP [111/134]\n",
      "Total Loss G: 0.1202021911740303\n",
      "EPOCH [138/200], STEP [121/134]\n",
      "Total Loss G: 0.5252832174301147\n",
      "EPOCH [138/200], STEP [131/134]\n",
      "Total Loss G: 0.3022076487541199\n",
      "EPOCH [138/200], STEP [141/134]\n",
      "Total Loss G: 0.14941875636577606\n",
      "Training time is  0.8322920203208923 mins\n",
      "Valid: 2-shot EPOCH [138/200], STEP [10/33]\n",
      "Total Loss V: 0.44558852910995483\n",
      "Valid: 2-shot EPOCH [138/200], STEP [20/33]\n",
      "Total Loss V: 0.6792312264442444\n",
      "Valid: 2-shot EPOCH [138/200], STEP [30/33]\n",
      "Total Loss V: 0.523392379283905\n",
      "EPOCH [139/200], STEP [11/134]\n",
      "Total Loss G: 0.14613643288612366\n",
      "EPOCH [139/200], STEP [21/134]\n",
      "Total Loss G: 0.3236534297466278\n",
      "EPOCH [139/200], STEP [31/134]\n",
      "Total Loss G: 0.10399925708770752\n",
      "EPOCH [139/200], STEP [41/134]\n",
      "Total Loss G: 0.6252941489219666\n",
      "EPOCH [139/200], STEP [51/134]\n",
      "Total Loss G: 0.14801590144634247\n",
      "EPOCH [139/200], STEP [61/134]\n",
      "Total Loss G: 0.20313923060894012\n",
      "EPOCH [139/200], STEP [71/134]\n",
      "Total Loss G: 0.16511733829975128\n",
      "EPOCH [139/200], STEP [81/134]\n",
      "Total Loss G: 0.12070661783218384\n",
      "EPOCH [139/200], STEP [91/134]\n",
      "Total Loss G: 0.23005487024784088\n",
      "EPOCH [139/200], STEP [101/134]\n",
      "Total Loss G: 0.2257256805896759\n",
      "EPOCH [139/200], STEP [111/134]\n",
      "Total Loss G: 0.13579244911670685\n",
      "EPOCH [139/200], STEP [121/134]\n",
      "Total Loss G: 0.5074950456619263\n",
      "EPOCH [139/200], STEP [131/134]\n",
      "Total Loss G: 0.3308897018432617\n",
      "EPOCH [139/200], STEP [141/134]\n",
      "Total Loss G: 0.15425518155097961\n",
      "Training time is  0.828055469195048 mins\n",
      "Valid: 2-shot EPOCH [139/200], STEP [10/33]\n",
      "Total Loss V: 0.5752379298210144\n",
      "Valid: 2-shot EPOCH [139/200], STEP [20/33]\n",
      "Total Loss V: 0.7919960618019104\n",
      "Valid: 2-shot EPOCH [139/200], STEP [30/33]\n",
      "Total Loss V: 0.39081087708473206\n",
      "EPOCH [140/200], STEP [11/134]\n",
      "Total Loss G: 0.14874626696109772\n",
      "EPOCH [140/200], STEP [21/134]\n",
      "Total Loss G: 0.2688062787055969\n",
      "EPOCH [140/200], STEP [31/134]\n",
      "Total Loss G: 0.1705254763364792\n",
      "EPOCH [140/200], STEP [41/134]\n",
      "Total Loss G: 0.6213006377220154\n",
      "EPOCH [140/200], STEP [51/134]\n",
      "Total Loss G: 0.17027883231639862\n",
      "EPOCH [140/200], STEP [61/134]\n",
      "Total Loss G: 0.2619365453720093\n",
      "EPOCH [140/200], STEP [71/134]\n",
      "Total Loss G: 0.30256614089012146\n",
      "EPOCH [140/200], STEP [81/134]\n",
      "Total Loss G: 0.1393612027168274\n",
      "EPOCH [140/200], STEP [91/134]\n",
      "Total Loss G: 0.23874445259571075\n",
      "EPOCH [140/200], STEP [101/134]\n",
      "Total Loss G: 0.18174965679645538\n",
      "EPOCH [140/200], STEP [111/134]\n",
      "Total Loss G: 0.11429088562726974\n",
      "EPOCH [140/200], STEP [121/134]\n",
      "Total Loss G: 0.5614354014396667\n",
      "EPOCH [140/200], STEP [131/134]\n",
      "Total Loss G: 0.3081912696361542\n",
      "EPOCH [140/200], STEP [141/134]\n",
      "Total Loss G: 0.16041724383831024\n",
      "Training time is  0.8296170473098755 mins\n",
      "Valid: 2-shot EPOCH [140/200], STEP [10/33]\n",
      "Total Loss V: 0.5312161445617676\n",
      "Valid: 2-shot EPOCH [140/200], STEP [20/33]\n",
      "Total Loss V: 0.44909772276878357\n",
      "Valid: 2-shot EPOCH [140/200], STEP [30/33]\n",
      "Total Loss V: 0.8228899836540222\n",
      "EPOCH [141/200], STEP [11/134]\n",
      "Total Loss G: 0.19381162524223328\n",
      "EPOCH [141/200], STEP [21/134]\n",
      "Total Loss G: 0.5252973437309265\n",
      "EPOCH [141/200], STEP [31/134]\n",
      "Total Loss G: 0.10997513681650162\n",
      "EPOCH [141/200], STEP [41/134]\n",
      "Total Loss G: 0.9207150936126709\n",
      "EPOCH [141/200], STEP [51/134]\n",
      "Total Loss G: 0.19767850637435913\n",
      "EPOCH [141/200], STEP [61/134]\n",
      "Total Loss G: 0.19285321235656738\n",
      "EPOCH [141/200], STEP [71/134]\n",
      "Total Loss G: 0.1932106912136078\n",
      "EPOCH [141/200], STEP [81/134]\n",
      "Total Loss G: 0.14052316546440125\n",
      "EPOCH [141/200], STEP [91/134]\n",
      "Total Loss G: 0.30189570784568787\n",
      "EPOCH [141/200], STEP [101/134]\n",
      "Total Loss G: 0.20640261471271515\n",
      "EPOCH [141/200], STEP [111/134]\n",
      "Total Loss G: 0.12299252301454544\n",
      "EPOCH [141/200], STEP [121/134]\n",
      "Total Loss G: 0.6378098130226135\n",
      "EPOCH [141/200], STEP [131/134]\n",
      "Total Loss G: 0.26348721981048584\n",
      "EPOCH [141/200], STEP [141/134]\n",
      "Total Loss G: 0.15474411845207214\n",
      "Training time is  0.8248126586278279 mins\n",
      "Valid: 2-shot EPOCH [141/200], STEP [10/33]\n",
      "Total Loss V: 0.7058510184288025\n",
      "Valid: 2-shot EPOCH [141/200], STEP [20/33]\n",
      "Total Loss V: 0.5042452216148376\n",
      "Valid: 2-shot EPOCH [141/200], STEP [30/33]\n",
      "Total Loss V: 0.6417112946510315\n",
      "EPOCH [142/200], STEP [11/134]\n",
      "Total Loss G: 0.17343005537986755\n",
      "EPOCH [142/200], STEP [21/134]\n",
      "Total Loss G: 0.3735538721084595\n",
      "EPOCH [142/200], STEP [31/134]\n",
      "Total Loss G: 0.16164690256118774\n",
      "EPOCH [142/200], STEP [41/134]\n",
      "Total Loss G: 0.6494298577308655\n",
      "EPOCH [142/200], STEP [51/134]\n",
      "Total Loss G: 0.4071873426437378\n",
      "EPOCH [142/200], STEP [61/134]\n",
      "Total Loss G: 0.19668172299861908\n",
      "EPOCH [142/200], STEP [71/134]\n",
      "Total Loss G: 0.2230067253112793\n",
      "EPOCH [142/200], STEP [81/134]\n",
      "Total Loss G: 0.15113963186740875\n",
      "EPOCH [142/200], STEP [91/134]\n",
      "Total Loss G: 0.2996976971626282\n",
      "EPOCH [142/200], STEP [101/134]\n",
      "Total Loss G: 0.22271573543548584\n",
      "EPOCH [142/200], STEP [111/134]\n",
      "Total Loss G: 0.1510104537010193\n",
      "EPOCH [142/200], STEP [121/134]\n",
      "Total Loss G: 0.5796554684638977\n",
      "EPOCH [142/200], STEP [131/134]\n",
      "Total Loss G: 0.28896576166152954\n",
      "EPOCH [142/200], STEP [141/134]\n",
      "Total Loss G: 0.13154196739196777\n",
      "Training time is  0.825377098719279 mins\n",
      "Valid: 2-shot EPOCH [142/200], STEP [10/33]\n",
      "Total Loss V: 0.4962916672229767\n",
      "Valid: 2-shot EPOCH [142/200], STEP [20/33]\n",
      "Total Loss V: 0.4251948595046997\n",
      "Valid: 2-shot EPOCH [142/200], STEP [30/33]\n",
      "Total Loss V: 0.5215108394622803\n",
      "EPOCH [143/200], STEP [11/134]\n",
      "Total Loss G: 0.14773032069206238\n",
      "EPOCH [143/200], STEP [21/134]\n",
      "Total Loss G: 0.34348824620246887\n",
      "EPOCH [143/200], STEP [31/134]\n",
      "Total Loss G: 0.10644234716892242\n",
      "EPOCH [143/200], STEP [41/134]\n",
      "Total Loss G: 0.629485547542572\n",
      "EPOCH [143/200], STEP [51/134]\n",
      "Total Loss G: 0.29569023847579956\n",
      "EPOCH [143/200], STEP [61/134]\n",
      "Total Loss G: 0.1930447220802307\n",
      "EPOCH [143/200], STEP [71/134]\n",
      "Total Loss G: 0.3506130278110504\n",
      "EPOCH [143/200], STEP [81/134]\n",
      "Total Loss G: 0.13698863983154297\n",
      "EPOCH [143/200], STEP [91/134]\n",
      "Total Loss G: 0.23418760299682617\n",
      "EPOCH [143/200], STEP [101/134]\n",
      "Total Loss G: 0.20605047047138214\n",
      "EPOCH [143/200], STEP [111/134]\n",
      "Total Loss G: 0.10727856308221817\n",
      "EPOCH [143/200], STEP [121/134]\n",
      "Total Loss G: 0.502619206905365\n",
      "EPOCH [143/200], STEP [131/134]\n",
      "Total Loss G: 0.2859790623188019\n",
      "EPOCH [143/200], STEP [141/134]\n",
      "Total Loss G: 0.1380017101764679\n",
      "Training time is  0.8276372830073039 mins\n",
      "Valid: 2-shot EPOCH [143/200], STEP [10/33]\n",
      "Total Loss V: 0.6729955673217773\n",
      "Valid: 2-shot EPOCH [143/200], STEP [20/33]\n",
      "Total Loss V: 0.37906143069267273\n",
      "Valid: 2-shot EPOCH [143/200], STEP [30/33]\n",
      "Total Loss V: 0.3681279420852661\n",
      "EPOCH [144/200], STEP [11/134]\n",
      "Total Loss G: 0.23941858112812042\n",
      "EPOCH [144/200], STEP [21/134]\n",
      "Total Loss G: 0.3145787715911865\n",
      "EPOCH [144/200], STEP [31/134]\n",
      "Total Loss G: 0.16606342792510986\n",
      "EPOCH [144/200], STEP [41/134]\n",
      "Total Loss G: 0.6458737850189209\n",
      "EPOCH [144/200], STEP [51/134]\n",
      "Total Loss G: 0.1573566496372223\n",
      "EPOCH [144/200], STEP [61/134]\n",
      "Total Loss G: 0.27127206325531006\n",
      "EPOCH [144/200], STEP [71/134]\n",
      "Total Loss G: 0.16022905707359314\n",
      "EPOCH [144/200], STEP [81/134]\n",
      "Total Loss G: 0.1800922006368637\n",
      "EPOCH [144/200], STEP [91/134]\n",
      "Total Loss G: 0.16630294919013977\n",
      "EPOCH [144/200], STEP [101/134]\n",
      "Total Loss G: 0.1983470618724823\n",
      "EPOCH [144/200], STEP [111/134]\n",
      "Total Loss G: 0.12851132452487946\n",
      "EPOCH [144/200], STEP [121/134]\n",
      "Total Loss G: 0.529669463634491\n",
      "EPOCH [144/200], STEP [131/134]\n",
      "Total Loss G: 0.30605873465538025\n",
      "EPOCH [144/200], STEP [141/134]\n",
      "Total Loss G: 0.14213523268699646\n",
      "Training time is  0.8258592247962951 mins\n",
      "Valid: 2-shot EPOCH [144/200], STEP [10/33]\n",
      "Total Loss V: 0.5661381483078003\n",
      "Valid: 2-shot EPOCH [144/200], STEP [20/33]\n",
      "Total Loss V: 0.4895687997341156\n",
      "Valid: 2-shot EPOCH [144/200], STEP [30/33]\n",
      "Total Loss V: 0.5493761897087097\n",
      "EPOCH [145/200], STEP [11/134]\n",
      "Total Loss G: 0.1622738242149353\n",
      "EPOCH [145/200], STEP [21/134]\n",
      "Total Loss G: 0.34943464398384094\n",
      "EPOCH [145/200], STEP [31/134]\n",
      "Total Loss G: 0.12460189312696457\n",
      "EPOCH [145/200], STEP [41/134]\n",
      "Total Loss G: 0.7125930190086365\n",
      "EPOCH [145/200], STEP [51/134]\n",
      "Total Loss G: 0.22021877765655518\n",
      "EPOCH [145/200], STEP [61/134]\n",
      "Total Loss G: 0.23139433562755585\n",
      "EPOCH [145/200], STEP [71/134]\n",
      "Total Loss G: 0.21242040395736694\n",
      "EPOCH [145/200], STEP [81/134]\n",
      "Total Loss G: 0.13523954153060913\n",
      "EPOCH [145/200], STEP [91/134]\n",
      "Total Loss G: 0.21488381922245026\n",
      "EPOCH [145/200], STEP [101/134]\n",
      "Total Loss G: 0.25448986887931824\n",
      "EPOCH [145/200], STEP [111/134]\n",
      "Total Loss G: 0.11700724810361862\n",
      "EPOCH [145/200], STEP [121/134]\n",
      "Total Loss G: 0.6635737419128418\n",
      "EPOCH [145/200], STEP [131/134]\n",
      "Total Loss G: 0.35203057527542114\n",
      "EPOCH [145/200], STEP [141/134]\n",
      "Total Loss G: 0.15033698081970215\n",
      "Training time is  0.8303802609443665 mins\n",
      "Valid: 2-shot EPOCH [145/200], STEP [10/33]\n",
      "Total Loss V: 0.4932231605052948\n",
      "Valid: 2-shot EPOCH [145/200], STEP [20/33]\n",
      "Total Loss V: 0.7028648853302002\n",
      "Valid: 2-shot EPOCH [145/200], STEP [30/33]\n",
      "Total Loss V: 0.3522675037384033\n",
      "EPOCH [146/200], STEP [11/134]\n",
      "Total Loss G: 0.14897598326206207\n",
      "EPOCH [146/200], STEP [21/134]\n",
      "Total Loss G: 0.27901387214660645\n",
      "EPOCH [146/200], STEP [31/134]\n",
      "Total Loss G: 0.12531374394893646\n",
      "EPOCH [146/200], STEP [41/134]\n",
      "Total Loss G: 0.6581157445907593\n",
      "EPOCH [146/200], STEP [51/134]\n",
      "Total Loss G: 0.1451093554496765\n",
      "EPOCH [146/200], STEP [61/134]\n",
      "Total Loss G: 0.2540929615497589\n",
      "EPOCH [146/200], STEP [71/134]\n",
      "Total Loss G: 0.19987499713897705\n",
      "EPOCH [146/200], STEP [81/134]\n",
      "Total Loss G: 0.15005889534950256\n",
      "EPOCH [146/200], STEP [91/134]\n",
      "Total Loss G: 0.180374413728714\n",
      "EPOCH [146/200], STEP [101/134]\n",
      "Total Loss G: 0.20541386306285858\n",
      "EPOCH [146/200], STEP [111/134]\n",
      "Total Loss G: 0.13237832486629486\n",
      "EPOCH [146/200], STEP [121/134]\n",
      "Total Loss G: 0.5061773657798767\n",
      "EPOCH [146/200], STEP [131/134]\n",
      "Total Loss G: 0.2583996653556824\n",
      "EPOCH [146/200], STEP [141/134]\n",
      "Total Loss G: 0.1610402762889862\n",
      "Training time is  0.8317935307820638 mins\n",
      "Valid: 2-shot EPOCH [146/200], STEP [10/33]\n",
      "Total Loss V: 0.5298844575881958\n",
      "Valid: 2-shot EPOCH [146/200], STEP [20/33]\n",
      "Total Loss V: 0.56900554895401\n",
      "Valid: 2-shot EPOCH [146/200], STEP [30/33]\n",
      "Total Loss V: 0.8250690698623657\n",
      "EPOCH [147/200], STEP [11/134]\n",
      "Total Loss G: 0.13551592826843262\n",
      "EPOCH [147/200], STEP [21/134]\n",
      "Total Loss G: 0.2743437886238098\n",
      "EPOCH [147/200], STEP [31/134]\n",
      "Total Loss G: 0.11898937821388245\n",
      "EPOCH [147/200], STEP [41/134]\n",
      "Total Loss G: 0.5948606133460999\n",
      "EPOCH [147/200], STEP [51/134]\n",
      "Total Loss G: 0.17363889515399933\n",
      "EPOCH [147/200], STEP [61/134]\n",
      "Total Loss G: 0.19062820076942444\n",
      "EPOCH [147/200], STEP [71/134]\n",
      "Total Loss G: 0.18984131515026093\n",
      "EPOCH [147/200], STEP [81/134]\n",
      "Total Loss G: 0.11416414380073547\n",
      "EPOCH [147/200], STEP [91/134]\n",
      "Total Loss G: 0.1563919335603714\n",
      "EPOCH [147/200], STEP [101/134]\n",
      "Total Loss G: 0.24035170674324036\n",
      "EPOCH [147/200], STEP [111/134]\n",
      "Total Loss G: 0.1381169557571411\n",
      "EPOCH [147/200], STEP [121/134]\n",
      "Total Loss G: 0.5094014406204224\n",
      "EPOCH [147/200], STEP [131/134]\n",
      "Total Loss G: 0.2854643166065216\n",
      "EPOCH [147/200], STEP [141/134]\n",
      "Total Loss G: 0.13765926659107208\n",
      "Training time is  0.8315197388331096 mins\n",
      "Valid: 2-shot EPOCH [147/200], STEP [10/33]\n",
      "Total Loss V: 0.5212283134460449\n",
      "Valid: 2-shot EPOCH [147/200], STEP [20/33]\n",
      "Total Loss V: 0.37163040041923523\n",
      "Valid: 2-shot EPOCH [147/200], STEP [30/33]\n",
      "Total Loss V: 0.7474909424781799\n",
      "EPOCH [148/200], STEP [11/134]\n",
      "Total Loss G: 0.13793599605560303\n",
      "EPOCH [148/200], STEP [21/134]\n",
      "Total Loss G: 0.2559669613838196\n",
      "EPOCH [148/200], STEP [31/134]\n",
      "Total Loss G: 0.16241337358951569\n",
      "EPOCH [148/200], STEP [41/134]\n",
      "Total Loss G: 0.6556071043014526\n",
      "EPOCH [148/200], STEP [51/134]\n",
      "Total Loss G: 0.16829757392406464\n",
      "EPOCH [148/200], STEP [61/134]\n",
      "Total Loss G: 0.2986871898174286\n",
      "EPOCH [148/200], STEP [71/134]\n",
      "Total Loss G: 0.32265704870224\n",
      "EPOCH [148/200], STEP [81/134]\n",
      "Total Loss G: 0.11782297492027283\n",
      "EPOCH [148/200], STEP [91/134]\n",
      "Total Loss G: 0.16469785571098328\n",
      "EPOCH [148/200], STEP [101/134]\n",
      "Total Loss G: 0.19270864129066467\n",
      "EPOCH [148/200], STEP [111/134]\n",
      "Total Loss G: 0.1306075155735016\n",
      "EPOCH [148/200], STEP [121/134]\n",
      "Total Loss G: 0.4778363108634949\n",
      "EPOCH [148/200], STEP [131/134]\n",
      "Total Loss G: 0.3265921175479889\n",
      "EPOCH [148/200], STEP [141/134]\n",
      "Total Loss G: 0.1604629009962082\n",
      "Training time is  0.8278704603513082 mins\n",
      "Valid: 2-shot EPOCH [148/200], STEP [10/33]\n",
      "Total Loss V: 0.5844848155975342\n",
      "Valid: 2-shot EPOCH [148/200], STEP [20/33]\n",
      "Total Loss V: 0.8452622294425964\n",
      "Valid: 2-shot EPOCH [148/200], STEP [30/33]\n",
      "Total Loss V: 0.1681288778781891\n",
      "EPOCH [149/200], STEP [11/134]\n",
      "Total Loss G: 0.12839503586292267\n",
      "EPOCH [149/200], STEP [21/134]\n",
      "Total Loss G: 0.3581206798553467\n",
      "EPOCH [149/200], STEP [31/134]\n",
      "Total Loss G: 0.1234559416770935\n",
      "EPOCH [149/200], STEP [41/134]\n",
      "Total Loss G: 0.5924464464187622\n",
      "EPOCH [149/200], STEP [51/134]\n",
      "Total Loss G: 0.12498179078102112\n",
      "EPOCH [149/200], STEP [61/134]\n",
      "Total Loss G: 0.20623256266117096\n",
      "EPOCH [149/200], STEP [71/134]\n",
      "Total Loss G: 0.16168347001075745\n",
      "EPOCH [149/200], STEP [81/134]\n",
      "Total Loss G: 0.11954101175069809\n",
      "EPOCH [149/200], STEP [91/134]\n",
      "Total Loss G: 0.20666079223155975\n",
      "EPOCH [149/200], STEP [101/134]\n",
      "Total Loss G: 0.23280559480190277\n",
      "EPOCH [149/200], STEP [111/134]\n",
      "Total Loss G: 0.13073499500751495\n",
      "EPOCH [149/200], STEP [121/134]\n",
      "Total Loss G: 0.531658947467804\n",
      "EPOCH [149/200], STEP [131/134]\n",
      "Total Loss G: 0.3338123857975006\n",
      "EPOCH [149/200], STEP [141/134]\n",
      "Total Loss G: 0.14487217366695404\n",
      "Training time is  0.8236982583999634 mins\n",
      "Valid: 2-shot EPOCH [149/200], STEP [10/33]\n",
      "Total Loss V: 0.4343416690826416\n",
      "Valid: 2-shot EPOCH [149/200], STEP [20/33]\n",
      "Total Loss V: 0.46471989154815674\n",
      "Valid: 2-shot EPOCH [149/200], STEP [30/33]\n",
      "Total Loss V: 0.270786851644516\n",
      "EPOCH [150/200], STEP [11/134]\n",
      "Total Loss G: 0.13099567592144012\n",
      "EPOCH [150/200], STEP [21/134]\n",
      "Total Loss G: 0.353763610124588\n",
      "EPOCH [150/200], STEP [31/134]\n",
      "Total Loss G: 0.10155316442251205\n",
      "EPOCH [150/200], STEP [41/134]\n",
      "Total Loss G: 0.630779504776001\n",
      "EPOCH [150/200], STEP [51/134]\n",
      "Total Loss G: 0.41979265213012695\n",
      "EPOCH [150/200], STEP [61/134]\n",
      "Total Loss G: 0.24999049305915833\n",
      "EPOCH [150/200], STEP [71/134]\n",
      "Total Loss G: 0.4108443260192871\n",
      "EPOCH [150/200], STEP [81/134]\n",
      "Total Loss G: 0.1387910693883896\n",
      "EPOCH [150/200], STEP [91/134]\n",
      "Total Loss G: 0.19940999150276184\n",
      "EPOCH [150/200], STEP [101/134]\n",
      "Total Loss G: 0.2358100712299347\n",
      "EPOCH [150/200], STEP [111/134]\n",
      "Total Loss G: 0.11215540766716003\n",
      "EPOCH [150/200], STEP [121/134]\n",
      "Total Loss G: 0.4969431459903717\n",
      "EPOCH [150/200], STEP [131/134]\n",
      "Total Loss G: 0.2707260549068451\n",
      "EPOCH [150/200], STEP [141/134]\n",
      "Total Loss G: 0.1681899130344391\n",
      "Training time is  0.8248116850852967 mins\n",
      "Valid: 2-shot EPOCH [150/200], STEP [10/33]\n",
      "Total Loss V: 0.3848937451839447\n",
      "Valid: 2-shot EPOCH [150/200], STEP [20/33]\n",
      "Total Loss V: 0.7063137888908386\n",
      "Valid: 2-shot EPOCH [150/200], STEP [30/33]\n",
      "Total Loss V: 0.2788451313972473\n",
      "EPOCH [151/200], STEP [11/134]\n",
      "Total Loss G: 0.1233874186873436\n",
      "EPOCH [151/200], STEP [21/134]\n",
      "Total Loss G: 0.37201955914497375\n",
      "EPOCH [151/200], STEP [31/134]\n",
      "Total Loss G: 0.09159233421087265\n",
      "EPOCH [151/200], STEP [41/134]\n",
      "Total Loss G: 0.6399277448654175\n",
      "EPOCH [151/200], STEP [51/134]\n",
      "Total Loss G: 0.15764208137989044\n",
      "EPOCH [151/200], STEP [61/134]\n",
      "Total Loss G: 0.18976351618766785\n",
      "EPOCH [151/200], STEP [71/134]\n",
      "Total Loss G: 0.15060093998908997\n",
      "EPOCH [151/200], STEP [81/134]\n",
      "Total Loss G: 0.1402805596590042\n",
      "EPOCH [151/200], STEP [91/134]\n",
      "Total Loss G: 0.16161344945430756\n",
      "EPOCH [151/200], STEP [101/134]\n",
      "Total Loss G: 0.23415985703468323\n",
      "EPOCH [151/200], STEP [111/134]\n",
      "Total Loss G: 0.15856534242630005\n",
      "EPOCH [151/200], STEP [121/134]\n",
      "Total Loss G: 0.5091915130615234\n",
      "EPOCH [151/200], STEP [131/134]\n",
      "Total Loss G: 0.275605708360672\n",
      "EPOCH [151/200], STEP [141/134]\n",
      "Total Loss G: 0.1408543437719345\n",
      "Training time is  0.8210059642791748 mins\n",
      "Valid: 2-shot EPOCH [151/200], STEP [10/33]\n",
      "Total Loss V: 0.6977364420890808\n",
      "Valid: 2-shot EPOCH [151/200], STEP [20/33]\n",
      "Total Loss V: 0.5320876836776733\n",
      "Valid: 2-shot EPOCH [151/200], STEP [30/33]\n",
      "Total Loss V: 0.4124436378479004\n",
      "EPOCH [152/200], STEP [11/134]\n",
      "Total Loss G: 0.11791838705539703\n",
      "EPOCH [152/200], STEP [21/134]\n",
      "Total Loss G: 0.30388569831848145\n",
      "EPOCH [152/200], STEP [31/134]\n",
      "Total Loss G: 0.11955450475215912\n",
      "EPOCH [152/200], STEP [41/134]\n",
      "Total Loss G: 0.6059715151786804\n",
      "EPOCH [152/200], STEP [51/134]\n",
      "Total Loss G: 0.2545946538448334\n",
      "EPOCH [152/200], STEP [61/134]\n",
      "Total Loss G: 0.21696220338344574\n",
      "EPOCH [152/200], STEP [71/134]\n",
      "Total Loss G: 0.17834293842315674\n",
      "EPOCH [152/200], STEP [81/134]\n",
      "Total Loss G: 0.13355503976345062\n",
      "EPOCH [152/200], STEP [91/134]\n",
      "Total Loss G: 0.14571203291416168\n",
      "EPOCH [152/200], STEP [101/134]\n",
      "Total Loss G: 0.16753904521465302\n",
      "EPOCH [152/200], STEP [111/134]\n",
      "Total Loss G: 0.11679896712303162\n",
      "EPOCH [152/200], STEP [121/134]\n",
      "Total Loss G: 0.5314640998840332\n",
      "EPOCH [152/200], STEP [131/134]\n",
      "Total Loss G: 0.3091662526130676\n",
      "EPOCH [152/200], STEP [141/134]\n",
      "Total Loss G: 0.16857846081256866\n",
      "Training time is  0.8297321359316508 mins\n",
      "Valid: 2-shot EPOCH [152/200], STEP [10/33]\n",
      "Total Loss V: 0.4131779074668884\n",
      "Valid: 2-shot EPOCH [152/200], STEP [20/33]\n",
      "Total Loss V: 0.26682934165000916\n",
      "Valid: 2-shot EPOCH [152/200], STEP [30/33]\n",
      "Total Loss V: 0.2837705910205841\n",
      "EPOCH [153/200], STEP [11/134]\n",
      "Total Loss G: 0.1556999683380127\n",
      "EPOCH [153/200], STEP [21/134]\n",
      "Total Loss G: 0.2939791679382324\n",
      "EPOCH [153/200], STEP [31/134]\n",
      "Total Loss G: 0.1252768635749817\n",
      "EPOCH [153/200], STEP [41/134]\n",
      "Total Loss G: 0.6856808066368103\n",
      "EPOCH [153/200], STEP [51/134]\n",
      "Total Loss G: 0.1680174469947815\n",
      "EPOCH [153/200], STEP [61/134]\n",
      "Total Loss G: 0.35213953256607056\n",
      "EPOCH [153/200], STEP [71/134]\n",
      "Total Loss G: 0.2374298870563507\n",
      "EPOCH [153/200], STEP [81/134]\n",
      "Total Loss G: 0.12968671321868896\n",
      "EPOCH [153/200], STEP [91/134]\n",
      "Total Loss G: 0.19129329919815063\n",
      "EPOCH [153/200], STEP [101/134]\n",
      "Total Loss G: 0.1713295876979828\n",
      "EPOCH [153/200], STEP [111/134]\n",
      "Total Loss G: 0.1189040020108223\n",
      "EPOCH [153/200], STEP [121/134]\n",
      "Total Loss G: 0.5624600052833557\n",
      "EPOCH [153/200], STEP [131/134]\n",
      "Total Loss G: 0.2881268560886383\n",
      "EPOCH [153/200], STEP [141/134]\n",
      "Total Loss G: 0.13773676753044128\n",
      "Training time is  0.8284274419148763 mins\n",
      "Valid: 2-shot EPOCH [153/200], STEP [10/33]\n",
      "Total Loss V: 0.4070490896701813\n",
      "Valid: 2-shot EPOCH [153/200], STEP [20/33]\n",
      "Total Loss V: 0.29259365797042847\n",
      "Valid: 2-shot EPOCH [153/200], STEP [30/33]\n",
      "Total Loss V: 0.7014304995536804\n",
      "EPOCH [154/200], STEP [11/134]\n",
      "Total Loss G: 0.1265469491481781\n",
      "EPOCH [154/200], STEP [21/134]\n",
      "Total Loss G: 0.4230020344257355\n",
      "EPOCH [154/200], STEP [31/134]\n",
      "Total Loss G: 0.12601496279239655\n",
      "EPOCH [154/200], STEP [41/134]\n",
      "Total Loss G: 0.6409632563591003\n",
      "EPOCH [154/200], STEP [51/134]\n",
      "Total Loss G: 0.18124818801879883\n",
      "EPOCH [154/200], STEP [61/134]\n",
      "Total Loss G: 0.21244783699512482\n",
      "EPOCH [154/200], STEP [71/134]\n",
      "Total Loss G: 0.1659139096736908\n",
      "EPOCH [154/200], STEP [81/134]\n",
      "Total Loss G: 0.16739484667778015\n",
      "EPOCH [154/200], STEP [91/134]\n",
      "Total Loss G: 0.1751621961593628\n",
      "EPOCH [154/200], STEP [101/134]\n",
      "Total Loss G: 0.17515957355499268\n",
      "EPOCH [154/200], STEP [111/134]\n",
      "Total Loss G: 0.12392719089984894\n",
      "EPOCH [154/200], STEP [121/134]\n",
      "Total Loss G: 0.5263562202453613\n",
      "EPOCH [154/200], STEP [131/134]\n",
      "Total Loss G: 0.3454562723636627\n",
      "EPOCH [154/200], STEP [141/134]\n",
      "Total Loss G: 0.13551823794841766\n",
      "Training time is  0.8300492326418559 mins\n",
      "Valid: 2-shot EPOCH [154/200], STEP [10/33]\n",
      "Total Loss V: 0.48176634311676025\n",
      "Valid: 2-shot EPOCH [154/200], STEP [20/33]\n",
      "Total Loss V: 0.3303968012332916\n",
      "Valid: 2-shot EPOCH [154/200], STEP [30/33]\n",
      "Total Loss V: 0.7471895813941956\n",
      "EPOCH [155/200], STEP [11/134]\n",
      "Total Loss G: 0.19753529131412506\n",
      "EPOCH [155/200], STEP [21/134]\n",
      "Total Loss G: 0.2829151153564453\n",
      "EPOCH [155/200], STEP [31/134]\n",
      "Total Loss G: 0.19325606524944305\n",
      "EPOCH [155/200], STEP [41/134]\n",
      "Total Loss G: 0.6455026865005493\n",
      "EPOCH [155/200], STEP [51/134]\n",
      "Total Loss G: 0.2318485677242279\n",
      "EPOCH [155/200], STEP [61/134]\n",
      "Total Loss G: 0.2515103816986084\n",
      "EPOCH [155/200], STEP [71/134]\n",
      "Total Loss G: 0.18475817143917084\n",
      "EPOCH [155/200], STEP [81/134]\n",
      "Total Loss G: 0.14622323215007782\n",
      "EPOCH [155/200], STEP [91/134]\n",
      "Total Loss G: 0.16999244689941406\n",
      "EPOCH [155/200], STEP [101/134]\n",
      "Total Loss G: 0.1871044635772705\n",
      "EPOCH [155/200], STEP [111/134]\n",
      "Total Loss G: 0.1185208261013031\n",
      "EPOCH [155/200], STEP [121/134]\n",
      "Total Loss G: 0.5695577263832092\n",
      "EPOCH [155/200], STEP [131/134]\n",
      "Total Loss G: 0.31284162402153015\n",
      "EPOCH [155/200], STEP [141/134]\n",
      "Total Loss G: 0.13947361707687378\n",
      "Training time is  0.8790660301844279 mins\n",
      "Valid: 2-shot EPOCH [155/200], STEP [10/33]\n",
      "Total Loss V: 0.5665140151977539\n",
      "Valid: 2-shot EPOCH [155/200], STEP [20/33]\n",
      "Total Loss V: 0.7713496685028076\n",
      "Valid: 2-shot EPOCH [155/200], STEP [30/33]\n",
      "Total Loss V: 0.6951828598976135\n",
      "EPOCH [156/200], STEP [11/134]\n",
      "Total Loss G: 0.11853155493736267\n",
      "EPOCH [156/200], STEP [21/134]\n",
      "Total Loss G: 0.3741341531276703\n",
      "EPOCH [156/200], STEP [31/134]\n",
      "Total Loss G: 0.10268032550811768\n",
      "EPOCH [156/200], STEP [41/134]\n",
      "Total Loss G: 0.6281958818435669\n",
      "EPOCH [156/200], STEP [51/134]\n",
      "Total Loss G: 0.20338775217533112\n",
      "EPOCH [156/200], STEP [61/134]\n",
      "Total Loss G: 0.22155240178108215\n",
      "EPOCH [156/200], STEP [71/134]\n",
      "Total Loss G: 0.18058981001377106\n",
      "EPOCH [156/200], STEP [81/134]\n",
      "Total Loss G: 0.13384179770946503\n",
      "EPOCH [156/200], STEP [91/134]\n",
      "Total Loss G: 0.16113406419754028\n",
      "EPOCH [156/200], STEP [101/134]\n",
      "Total Loss G: 0.2170216590166092\n",
      "EPOCH [156/200], STEP [111/134]\n",
      "Total Loss G: 0.11641687154769897\n",
      "EPOCH [156/200], STEP [121/134]\n",
      "Total Loss G: 0.5086197853088379\n",
      "EPOCH [156/200], STEP [131/134]\n",
      "Total Loss G: 0.30767735838890076\n",
      "EPOCH [156/200], STEP [141/134]\n",
      "Total Loss G: 0.13234367966651917\n",
      "Training time is  0.9590704639752706 mins\n",
      "Valid: 2-shot EPOCH [156/200], STEP [10/33]\n",
      "Total Loss V: 0.4301936626434326\n",
      "Valid: 2-shot EPOCH [156/200], STEP [20/33]\n",
      "Total Loss V: 0.43282100558280945\n",
      "Valid: 2-shot EPOCH [156/200], STEP [30/33]\n",
      "Total Loss V: 0.580806314945221\n",
      "EPOCH [157/200], STEP [11/134]\n",
      "Total Loss G: 0.1823616474866867\n",
      "EPOCH [157/200], STEP [21/134]\n",
      "Total Loss G: 0.2771693766117096\n",
      "EPOCH [157/200], STEP [31/134]\n",
      "Total Loss G: 0.10421918332576752\n",
      "EPOCH [157/200], STEP [41/134]\n",
      "Total Loss G: 0.6156858205795288\n",
      "EPOCH [157/200], STEP [51/134]\n",
      "Total Loss G: 0.14943820238113403\n",
      "EPOCH [157/200], STEP [61/134]\n",
      "Total Loss G: 0.16786746680736542\n",
      "EPOCH [157/200], STEP [71/134]\n",
      "Total Loss G: 0.18742400407791138\n",
      "EPOCH [157/200], STEP [81/134]\n",
      "Total Loss G: 0.13862749934196472\n",
      "EPOCH [157/200], STEP [91/134]\n",
      "Total Loss G: 0.1801598072052002\n",
      "EPOCH [157/200], STEP [101/134]\n",
      "Total Loss G: 0.23505938053131104\n",
      "EPOCH [157/200], STEP [111/134]\n",
      "Total Loss G: 0.25402215123176575\n",
      "EPOCH [157/200], STEP [121/134]\n",
      "Total Loss G: 0.5530625581741333\n",
      "EPOCH [157/200], STEP [131/134]\n",
      "Total Loss G: 0.28248095512390137\n",
      "EPOCH [157/200], STEP [141/134]\n",
      "Total Loss G: 0.13682131469249725\n",
      "Training time is  0.946596908569336 mins\n",
      "Valid: 2-shot EPOCH [157/200], STEP [10/33]\n",
      "Total Loss V: 0.45988208055496216\n",
      "Valid: 2-shot EPOCH [157/200], STEP [20/33]\n",
      "Total Loss V: 0.39943093061447144\n",
      "Valid: 2-shot EPOCH [157/200], STEP [30/33]\n",
      "Total Loss V: 0.7517106533050537\n",
      "EPOCH [158/200], STEP [11/134]\n",
      "Total Loss G: 0.12660269439220428\n",
      "EPOCH [158/200], STEP [21/134]\n",
      "Total Loss G: 0.3229929804801941\n",
      "EPOCH [158/200], STEP [31/134]\n",
      "Total Loss G: 0.2128092646598816\n",
      "EPOCH [158/200], STEP [41/134]\n",
      "Total Loss G: 0.7109971642494202\n",
      "EPOCH [158/200], STEP [51/134]\n",
      "Total Loss G: 0.1578909009695053\n",
      "EPOCH [158/200], STEP [61/134]\n",
      "Total Loss G: 0.3127613663673401\n",
      "EPOCH [158/200], STEP [71/134]\n",
      "Total Loss G: 0.1607283055782318\n",
      "EPOCH [158/200], STEP [81/134]\n",
      "Total Loss G: 0.15317925810813904\n",
      "EPOCH [158/200], STEP [91/134]\n",
      "Total Loss G: 0.1834147423505783\n",
      "EPOCH [158/200], STEP [101/134]\n",
      "Total Loss G: 0.17169266939163208\n",
      "EPOCH [158/200], STEP [111/134]\n",
      "Total Loss G: 0.16014744341373444\n",
      "EPOCH [158/200], STEP [121/134]\n",
      "Total Loss G: 0.509690523147583\n",
      "EPOCH [158/200], STEP [131/134]\n",
      "Total Loss G: 0.3416336178779602\n",
      "EPOCH [158/200], STEP [141/134]\n",
      "Total Loss G: 0.13315677642822266\n",
      "Training time is  0.9450735569000244 mins\n",
      "Valid: 2-shot EPOCH [158/200], STEP [10/33]\n",
      "Total Loss V: 0.34745460748672485\n",
      "Valid: 2-shot EPOCH [158/200], STEP [20/33]\n",
      "Total Loss V: 0.5031705498695374\n",
      "Valid: 2-shot EPOCH [158/200], STEP [30/33]\n",
      "Total Loss V: 0.35695627331733704\n",
      "EPOCH [159/200], STEP [11/134]\n",
      "Total Loss G: 0.14152230322360992\n",
      "EPOCH [159/200], STEP [21/134]\n",
      "Total Loss G: 0.5152261853218079\n",
      "EPOCH [159/200], STEP [31/134]\n",
      "Total Loss G: 0.16323113441467285\n",
      "EPOCH [159/200], STEP [41/134]\n",
      "Total Loss G: 0.5950922966003418\n",
      "EPOCH [159/200], STEP [51/134]\n",
      "Total Loss G: 0.12153364717960358\n",
      "EPOCH [159/200], STEP [61/134]\n",
      "Total Loss G: 0.17742381989955902\n",
      "EPOCH [159/200], STEP [71/134]\n",
      "Total Loss G: 0.13311265408992767\n",
      "EPOCH [159/200], STEP [81/134]\n",
      "Total Loss G: 0.16981464624404907\n",
      "EPOCH [159/200], STEP [91/134]\n",
      "Total Loss G: 0.17933641374111176\n",
      "EPOCH [159/200], STEP [101/134]\n",
      "Total Loss G: 0.19577592611312866\n",
      "EPOCH [159/200], STEP [111/134]\n",
      "Total Loss G: 0.10927791893482208\n",
      "EPOCH [159/200], STEP [121/134]\n",
      "Total Loss G: 0.46254172921180725\n",
      "EPOCH [159/200], STEP [131/134]\n",
      "Total Loss G: 0.25911444425582886\n",
      "EPOCH [159/200], STEP [141/134]\n",
      "Total Loss G: 0.15880189836025238\n",
      "Training time is  0.867689065138499 mins\n",
      "Valid: 2-shot EPOCH [159/200], STEP [10/33]\n",
      "Total Loss V: 0.47529205679893494\n",
      "Valid: 2-shot EPOCH [159/200], STEP [20/33]\n",
      "Total Loss V: 0.41647040843963623\n",
      "Valid: 2-shot EPOCH [159/200], STEP [30/33]\n",
      "Total Loss V: 0.5155609250068665\n",
      "EPOCH [160/200], STEP [11/134]\n",
      "Total Loss G: 0.1371472328901291\n",
      "EPOCH [160/200], STEP [21/134]\n",
      "Total Loss G: 0.30524709820747375\n",
      "EPOCH [160/200], STEP [31/134]\n",
      "Total Loss G: 0.12932342290878296\n",
      "EPOCH [160/200], STEP [41/134]\n",
      "Total Loss G: 0.6348575353622437\n",
      "EPOCH [160/200], STEP [51/134]\n",
      "Total Loss G: 0.11991850286722183\n",
      "EPOCH [160/200], STEP [61/134]\n",
      "Total Loss G: 0.22680941224098206\n",
      "EPOCH [160/200], STEP [71/134]\n",
      "Total Loss G: 0.18230390548706055\n",
      "EPOCH [160/200], STEP [81/134]\n",
      "Total Loss G: 0.11520332843065262\n",
      "EPOCH [160/200], STEP [91/134]\n",
      "Total Loss G: 0.26208314299583435\n",
      "EPOCH [160/200], STEP [101/134]\n",
      "Total Loss G: 0.1867944747209549\n",
      "EPOCH [160/200], STEP [111/134]\n",
      "Total Loss G: 0.09588803350925446\n",
      "EPOCH [160/200], STEP [121/134]\n",
      "Total Loss G: 0.500117301940918\n",
      "EPOCH [160/200], STEP [131/134]\n",
      "Total Loss G: 0.2379993349313736\n",
      "EPOCH [160/200], STEP [141/134]\n",
      "Total Loss G: 0.12549294531345367\n",
      "Training time is  0.9337047338485718 mins\n",
      "Valid: 2-shot EPOCH [160/200], STEP [10/33]\n",
      "Total Loss V: 0.45473694801330566\n",
      "Valid: 2-shot EPOCH [160/200], STEP [20/33]\n",
      "Total Loss V: 0.4738894999027252\n",
      "Valid: 2-shot EPOCH [160/200], STEP [30/33]\n",
      "Total Loss V: 0.5152972936630249\n",
      "EPOCH [161/200], STEP [11/134]\n",
      "Total Loss G: 0.11275573074817657\n",
      "EPOCH [161/200], STEP [21/134]\n",
      "Total Loss G: 0.27370479702949524\n",
      "EPOCH [161/200], STEP [31/134]\n",
      "Total Loss G: 0.13486817479133606\n",
      "EPOCH [161/200], STEP [41/134]\n",
      "Total Loss G: 0.5655402541160583\n",
      "EPOCH [161/200], STEP [51/134]\n",
      "Total Loss G: 0.20063188672065735\n",
      "EPOCH [161/200], STEP [61/134]\n",
      "Total Loss G: 0.18320657312870026\n",
      "EPOCH [161/200], STEP [71/134]\n",
      "Total Loss G: 0.23642458021640778\n",
      "EPOCH [161/200], STEP [81/134]\n",
      "Total Loss G: 0.2483150213956833\n",
      "EPOCH [161/200], STEP [91/134]\n",
      "Total Loss G: 0.1219085231423378\n",
      "EPOCH [161/200], STEP [101/134]\n",
      "Total Loss G: 0.1957944631576538\n",
      "EPOCH [161/200], STEP [111/134]\n",
      "Total Loss G: 0.09582807123661041\n",
      "EPOCH [161/200], STEP [121/134]\n",
      "Total Loss G: 0.5073028206825256\n",
      "EPOCH [161/200], STEP [131/134]\n",
      "Total Loss G: 0.22670510411262512\n",
      "EPOCH [161/200], STEP [141/134]\n",
      "Total Loss G: 0.15231721103191376\n",
      "Training time is  0.9483070770899454 mins\n",
      "Valid: 2-shot EPOCH [161/200], STEP [10/33]\n",
      "Total Loss V: 0.35650724172592163\n",
      "Valid: 2-shot EPOCH [161/200], STEP [20/33]\n",
      "Total Loss V: 0.5090725421905518\n",
      "Valid: 2-shot EPOCH [161/200], STEP [30/33]\n",
      "Total Loss V: 0.714653491973877\n",
      "EPOCH [162/200], STEP [11/134]\n",
      "Total Loss G: 0.13248756527900696\n",
      "EPOCH [162/200], STEP [21/134]\n",
      "Total Loss G: 0.2750304043292999\n",
      "EPOCH [162/200], STEP [31/134]\n",
      "Total Loss G: 0.09371953457593918\n",
      "EPOCH [162/200], STEP [41/134]\n",
      "Total Loss G: 0.6307236552238464\n",
      "EPOCH [162/200], STEP [51/134]\n",
      "Total Loss G: 0.1525280922651291\n",
      "EPOCH [162/200], STEP [61/134]\n",
      "Total Loss G: 0.15737228095531464\n",
      "EPOCH [162/200], STEP [71/134]\n",
      "Total Loss G: 0.17224366962909698\n",
      "EPOCH [162/200], STEP [81/134]\n",
      "Total Loss G: 0.15647411346435547\n",
      "EPOCH [162/200], STEP [91/134]\n",
      "Total Loss G: 0.17054606974124908\n",
      "EPOCH [162/200], STEP [101/134]\n",
      "Total Loss G: 0.2974719703197479\n",
      "EPOCH [162/200], STEP [111/134]\n",
      "Total Loss G: 0.12862655520439148\n",
      "EPOCH [162/200], STEP [121/134]\n",
      "Total Loss G: 0.5278743505477905\n",
      "EPOCH [162/200], STEP [131/134]\n",
      "Total Loss G: 0.26768314838409424\n",
      "EPOCH [162/200], STEP [141/134]\n",
      "Total Loss G: 0.15200193226337433\n",
      "Training time is  0.9431647698084513 mins\n",
      "Valid: 2-shot EPOCH [162/200], STEP [10/33]\n",
      "Total Loss V: 0.3495153486728668\n",
      "Valid: 2-shot EPOCH [162/200], STEP [20/33]\n",
      "Total Loss V: 0.44209879636764526\n",
      "Valid: 2-shot EPOCH [162/200], STEP [30/33]\n",
      "Total Loss V: 0.35702773928642273\n",
      "EPOCH [163/200], STEP [11/134]\n",
      "Total Loss G: 0.13195720314979553\n",
      "EPOCH [163/200], STEP [21/134]\n",
      "Total Loss G: 0.3029528856277466\n",
      "EPOCH [163/200], STEP [31/134]\n",
      "Total Loss G: 0.0959375873208046\n",
      "EPOCH [163/200], STEP [41/134]\n",
      "Total Loss G: 0.6324653625488281\n",
      "EPOCH [163/200], STEP [51/134]\n",
      "Total Loss G: 0.24040628969669342\n",
      "EPOCH [163/200], STEP [61/134]\n",
      "Total Loss G: 0.17077086865901947\n",
      "EPOCH [163/200], STEP [71/134]\n",
      "Total Loss G: 0.13816814124584198\n",
      "EPOCH [163/200], STEP [81/134]\n",
      "Total Loss G: 0.1150474101305008\n",
      "EPOCH [163/200], STEP [91/134]\n",
      "Total Loss G: 0.159141406416893\n",
      "EPOCH [163/200], STEP [101/134]\n",
      "Total Loss G: 0.17798066139221191\n",
      "EPOCH [163/200], STEP [111/134]\n",
      "Total Loss G: 0.10484720021486282\n",
      "EPOCH [163/200], STEP [121/134]\n",
      "Total Loss G: 0.5218905806541443\n",
      "EPOCH [163/200], STEP [131/134]\n",
      "Total Loss G: 0.3279308080673218\n",
      "EPOCH [163/200], STEP [141/134]\n",
      "Total Loss G: 0.14430895447731018\n",
      "Training time is  0.9437274018923442 mins\n",
      "Valid: 2-shot EPOCH [163/200], STEP [10/33]\n",
      "Total Loss V: 0.41225916147232056\n",
      "Valid: 2-shot EPOCH [163/200], STEP [20/33]\n",
      "Total Loss V: 0.4957164227962494\n",
      "Valid: 2-shot EPOCH [163/200], STEP [30/33]\n",
      "Total Loss V: 0.47201013565063477\n",
      "EPOCH [164/200], STEP [11/134]\n",
      "Total Loss G: 0.12292508035898209\n",
      "EPOCH [164/200], STEP [21/134]\n",
      "Total Loss G: 0.2927122712135315\n",
      "EPOCH [164/200], STEP [31/134]\n",
      "Total Loss G: 0.11554748564958572\n",
      "EPOCH [164/200], STEP [41/134]\n",
      "Total Loss G: 0.5722552537918091\n",
      "EPOCH [164/200], STEP [51/134]\n",
      "Total Loss G: 0.12266186624765396\n",
      "EPOCH [164/200], STEP [61/134]\n",
      "Total Loss G: 0.16883710026741028\n",
      "EPOCH [164/200], STEP [71/134]\n",
      "Total Loss G: 0.25863802433013916\n",
      "EPOCH [164/200], STEP [81/134]\n",
      "Total Loss G: 0.16432099044322968\n",
      "EPOCH [164/200], STEP [91/134]\n",
      "Total Loss G: 0.17593546211719513\n",
      "EPOCH [164/200], STEP [101/134]\n",
      "Total Loss G: 0.2210385799407959\n",
      "EPOCH [164/200], STEP [111/134]\n",
      "Total Loss G: 0.12169218808412552\n",
      "EPOCH [164/200], STEP [121/134]\n",
      "Total Loss G: 0.4937577247619629\n",
      "EPOCH [164/200], STEP [131/134]\n",
      "Total Loss G: 0.2648513913154602\n",
      "EPOCH [164/200], STEP [141/134]\n",
      "Total Loss G: 0.1495407223701477\n",
      "Training time is  0.940835158030192 mins\n",
      "Valid: 2-shot EPOCH [164/200], STEP [10/33]\n",
      "Total Loss V: 0.4707089066505432\n",
      "Valid: 2-shot EPOCH [164/200], STEP [20/33]\n",
      "Total Loss V: 0.5132550597190857\n",
      "Valid: 2-shot EPOCH [164/200], STEP [30/33]\n",
      "Total Loss V: 0.3342287540435791\n",
      "EPOCH [165/200], STEP [11/134]\n",
      "Total Loss G: 0.13283364474773407\n",
      "EPOCH [165/200], STEP [21/134]\n",
      "Total Loss G: 0.2793295681476593\n",
      "EPOCH [165/200], STEP [31/134]\n",
      "Total Loss G: 0.11241337656974792\n",
      "EPOCH [165/200], STEP [41/134]\n",
      "Total Loss G: 0.6533177495002747\n",
      "EPOCH [165/200], STEP [51/134]\n",
      "Total Loss G: 0.2273128479719162\n",
      "EPOCH [165/200], STEP [61/134]\n",
      "Total Loss G: 0.2140122801065445\n",
      "EPOCH [165/200], STEP [71/134]\n",
      "Total Loss G: 0.2704314589500427\n",
      "EPOCH [165/200], STEP [81/134]\n",
      "Total Loss G: 0.13801607489585876\n",
      "EPOCH [165/200], STEP [91/134]\n",
      "Total Loss G: 0.2257574200630188\n",
      "EPOCH [165/200], STEP [101/134]\n",
      "Total Loss G: 0.16430187225341797\n",
      "EPOCH [165/200], STEP [111/134]\n",
      "Total Loss G: 0.10496556013822556\n",
      "EPOCH [165/200], STEP [121/134]\n",
      "Total Loss G: 0.4923713803291321\n",
      "EPOCH [165/200], STEP [131/134]\n",
      "Total Loss G: 0.26936373114585876\n",
      "EPOCH [165/200], STEP [141/134]\n",
      "Total Loss G: 0.13530559837818146\n",
      "Training time is  0.94263942639033 mins\n",
      "Valid: 2-shot EPOCH [165/200], STEP [10/33]\n",
      "Total Loss V: 0.564690113067627\n",
      "Valid: 2-shot EPOCH [165/200], STEP [20/33]\n",
      "Total Loss V: 0.46286603808403015\n",
      "Valid: 2-shot EPOCH [165/200], STEP [30/33]\n",
      "Total Loss V: 0.4376089572906494\n",
      "EPOCH [166/200], STEP [11/134]\n",
      "Total Loss G: 0.12102881073951721\n",
      "EPOCH [166/200], STEP [21/134]\n",
      "Total Loss G: 0.2648850381374359\n",
      "EPOCH [166/200], STEP [31/134]\n",
      "Total Loss G: 0.09012296050786972\n",
      "EPOCH [166/200], STEP [41/134]\n",
      "Total Loss G: 0.5898679494857788\n",
      "EPOCH [166/200], STEP [51/134]\n",
      "Total Loss G: 0.14074212312698364\n",
      "EPOCH [166/200], STEP [61/134]\n",
      "Total Loss G: 0.16261523962020874\n",
      "EPOCH [166/200], STEP [71/134]\n",
      "Total Loss G: 0.17485350370407104\n",
      "EPOCH [166/200], STEP [81/134]\n",
      "Total Loss G: 0.11982569098472595\n",
      "EPOCH [166/200], STEP [91/134]\n",
      "Total Loss G: 0.1820342242717743\n",
      "EPOCH [166/200], STEP [101/134]\n",
      "Total Loss G: 0.16560152173042297\n",
      "EPOCH [166/200], STEP [111/134]\n",
      "Total Loss G: 0.08908161520957947\n",
      "EPOCH [166/200], STEP [121/134]\n",
      "Total Loss G: 0.517547070980072\n",
      "EPOCH [166/200], STEP [131/134]\n",
      "Total Loss G: 0.3598890006542206\n",
      "EPOCH [166/200], STEP [141/134]\n",
      "Total Loss G: 0.14795595407485962\n",
      "Training time is  0.9379775325457255 mins\n",
      "Valid: 2-shot EPOCH [166/200], STEP [10/33]\n",
      "Total Loss V: 0.44493839144706726\n",
      "Valid: 2-shot EPOCH [166/200], STEP [20/33]\n",
      "Total Loss V: 0.37975695729255676\n",
      "Valid: 2-shot EPOCH [166/200], STEP [30/33]\n",
      "Total Loss V: 0.4278700053691864\n",
      "EPOCH [167/200], STEP [11/134]\n",
      "Total Loss G: 0.17226827144622803\n",
      "EPOCH [167/200], STEP [21/134]\n",
      "Total Loss G: 0.3881151080131531\n",
      "EPOCH [167/200], STEP [31/134]\n",
      "Total Loss G: 0.18013621866703033\n",
      "EPOCH [167/200], STEP [41/134]\n",
      "Total Loss G: 0.5680521726608276\n",
      "EPOCH [167/200], STEP [51/134]\n",
      "Total Loss G: 0.14146867394447327\n",
      "EPOCH [167/200], STEP [61/134]\n",
      "Total Loss G: 0.21770423650741577\n",
      "EPOCH [167/200], STEP [71/134]\n",
      "Total Loss G: 0.14726974070072174\n",
      "EPOCH [167/200], STEP [81/134]\n",
      "Total Loss G: 0.15000523626804352\n",
      "EPOCH [167/200], STEP [91/134]\n",
      "Total Loss G: 0.19092035293579102\n",
      "EPOCH [167/200], STEP [101/134]\n",
      "Total Loss G: 0.187800332903862\n",
      "EPOCH [167/200], STEP [111/134]\n",
      "Total Loss G: 0.1091550812125206\n",
      "EPOCH [167/200], STEP [121/134]\n",
      "Total Loss G: 0.47778892517089844\n",
      "EPOCH [167/200], STEP [131/134]\n",
      "Total Loss G: 0.29454144835472107\n",
      "EPOCH [167/200], STEP [141/134]\n",
      "Total Loss G: 0.12684811651706696\n",
      "Training time is  0.9430957635243734 mins\n",
      "Valid: 2-shot EPOCH [167/200], STEP [10/33]\n",
      "Total Loss V: 0.4766906201839447\n",
      "Valid: 2-shot EPOCH [167/200], STEP [20/33]\n",
      "Total Loss V: 0.38912704586982727\n",
      "Valid: 2-shot EPOCH [167/200], STEP [30/33]\n",
      "Total Loss V: 0.3900364935398102\n",
      "EPOCH [168/200], STEP [11/134]\n",
      "Total Loss G: 0.15480756759643555\n",
      "EPOCH [168/200], STEP [21/134]\n",
      "Total Loss G: 0.2537153363227844\n",
      "EPOCH [168/200], STEP [31/134]\n",
      "Total Loss G: 0.100734643638134\n",
      "EPOCH [168/200], STEP [41/134]\n",
      "Total Loss G: 0.5550069808959961\n",
      "EPOCH [168/200], STEP [51/134]\n",
      "Total Loss G: 0.10447198897600174\n",
      "EPOCH [168/200], STEP [61/134]\n",
      "Total Loss G: 0.19140596687793732\n",
      "EPOCH [168/200], STEP [71/134]\n",
      "Total Loss G: 0.21841005980968475\n",
      "EPOCH [168/200], STEP [81/134]\n",
      "Total Loss G: 0.11843341588973999\n",
      "EPOCH [168/200], STEP [91/134]\n",
      "Total Loss G: 0.20422139763832092\n",
      "EPOCH [168/200], STEP [101/134]\n",
      "Total Loss G: 0.20395667850971222\n",
      "EPOCH [168/200], STEP [111/134]\n",
      "Total Loss G: 0.13527171313762665\n",
      "EPOCH [168/200], STEP [121/134]\n",
      "Total Loss G: 0.4680442810058594\n",
      "EPOCH [168/200], STEP [131/134]\n",
      "Total Loss G: 0.29565462470054626\n",
      "EPOCH [168/200], STEP [141/134]\n",
      "Total Loss G: 0.13139210641384125\n",
      "Training time is  0.9430299878120423 mins\n",
      "Valid: 2-shot EPOCH [168/200], STEP [10/33]\n",
      "Total Loss V: 0.39342159032821655\n",
      "Valid: 2-shot EPOCH [168/200], STEP [20/33]\n",
      "Total Loss V: 0.407407283782959\n",
      "Valid: 2-shot EPOCH [168/200], STEP [30/33]\n",
      "Total Loss V: 0.3732142448425293\n",
      "EPOCH [169/200], STEP [11/134]\n",
      "Total Loss G: 0.11207389831542969\n",
      "EPOCH [169/200], STEP [21/134]\n",
      "Total Loss G: 0.24790997803211212\n",
      "EPOCH [169/200], STEP [31/134]\n",
      "Total Loss G: 0.10500204563140869\n",
      "EPOCH [169/200], STEP [41/134]\n",
      "Total Loss G: 0.5402281284332275\n",
      "EPOCH [169/200], STEP [51/134]\n",
      "Total Loss G: 0.11713424324989319\n",
      "EPOCH [169/200], STEP [61/134]\n",
      "Total Loss G: 0.20078584551811218\n",
      "EPOCH [169/200], STEP [71/134]\n",
      "Total Loss G: 0.15404796600341797\n",
      "EPOCH [169/200], STEP [81/134]\n",
      "Total Loss G: 0.11312169581651688\n",
      "EPOCH [169/200], STEP [91/134]\n",
      "Total Loss G: 0.22720007598400116\n",
      "EPOCH [169/200], STEP [101/134]\n",
      "Total Loss G: 0.16298246383666992\n",
      "EPOCH [169/200], STEP [111/134]\n",
      "Total Loss G: 0.12074054777622223\n",
      "EPOCH [169/200], STEP [121/134]\n",
      "Total Loss G: 0.5191053152084351\n",
      "EPOCH [169/200], STEP [131/134]\n",
      "Total Loss G: 0.2613096535205841\n",
      "EPOCH [169/200], STEP [141/134]\n",
      "Total Loss G: 0.1420314759016037\n",
      "Training time is  0.9462803284327189 mins\n",
      "Valid: 2-shot EPOCH [169/200], STEP [10/33]\n",
      "Total Loss V: 0.4368091821670532\n",
      "Valid: 2-shot EPOCH [169/200], STEP [20/33]\n",
      "Total Loss V: 0.34737375378608704\n",
      "Valid: 2-shot EPOCH [169/200], STEP [30/33]\n",
      "Total Loss V: 0.5089091658592224\n",
      "EPOCH [170/200], STEP [11/134]\n",
      "Total Loss G: 0.19605426490306854\n",
      "EPOCH [170/200], STEP [21/134]\n",
      "Total Loss G: 0.28338122367858887\n",
      "EPOCH [170/200], STEP [31/134]\n",
      "Total Loss G: 0.1236991211771965\n",
      "EPOCH [170/200], STEP [41/134]\n",
      "Total Loss G: 0.6123502850532532\n",
      "EPOCH [170/200], STEP [51/134]\n",
      "Total Loss G: 0.1531742513179779\n",
      "EPOCH [170/200], STEP [61/134]\n",
      "Total Loss G: 0.1855124980211258\n",
      "EPOCH [170/200], STEP [71/134]\n",
      "Total Loss G: 0.14835211634635925\n",
      "EPOCH [170/200], STEP [81/134]\n",
      "Total Loss G: 0.11775972694158554\n",
      "EPOCH [170/200], STEP [91/134]\n",
      "Total Loss G: 0.19422172009944916\n",
      "EPOCH [170/200], STEP [101/134]\n",
      "Total Loss G: 0.1812003254890442\n",
      "EPOCH [170/200], STEP [111/134]\n",
      "Total Loss G: 0.11372067779302597\n",
      "EPOCH [170/200], STEP [121/134]\n",
      "Total Loss G: 0.4538578987121582\n",
      "EPOCH [170/200], STEP [131/134]\n",
      "Total Loss G: 0.25057119131088257\n",
      "EPOCH [170/200], STEP [141/134]\n",
      "Total Loss G: 0.14079289138317108\n",
      "Training time is  0.9360981305440267 mins\n",
      "Valid: 2-shot EPOCH [170/200], STEP [10/33]\n",
      "Total Loss V: 0.3656761944293976\n",
      "Valid: 2-shot EPOCH [170/200], STEP [20/33]\n",
      "Total Loss V: 0.3650718927383423\n",
      "Valid: 2-shot EPOCH [170/200], STEP [30/33]\n",
      "Total Loss V: 0.33776000142097473\n",
      "EPOCH [171/200], STEP [11/134]\n",
      "Total Loss G: 0.17182837426662445\n",
      "EPOCH [171/200], STEP [21/134]\n",
      "Total Loss G: 0.25129684805870056\n",
      "EPOCH [171/200], STEP [31/134]\n",
      "Total Loss G: 0.09935488551855087\n",
      "EPOCH [171/200], STEP [41/134]\n",
      "Total Loss G: 0.6000267267227173\n",
      "EPOCH [171/200], STEP [51/134]\n",
      "Total Loss G: 0.24156661331653595\n",
      "EPOCH [171/200], STEP [61/134]\n",
      "Total Loss G: 0.18616081774234772\n",
      "EPOCH [171/200], STEP [71/134]\n",
      "Total Loss G: 0.39157068729400635\n",
      "EPOCH [171/200], STEP [81/134]\n",
      "Total Loss G: 0.11853321641683578\n",
      "EPOCH [171/200], STEP [91/134]\n",
      "Total Loss G: 0.26495596766471863\n",
      "EPOCH [171/200], STEP [101/134]\n",
      "Total Loss G: 0.16385182738304138\n",
      "EPOCH [171/200], STEP [111/134]\n",
      "Total Loss G: 0.12203983217477798\n",
      "EPOCH [171/200], STEP [121/134]\n",
      "Total Loss G: 0.5019831657409668\n",
      "EPOCH [171/200], STEP [131/134]\n",
      "Total Loss G: 0.2822333872318268\n",
      "EPOCH [171/200], STEP [141/134]\n",
      "Total Loss G: 0.1439698189496994\n",
      "Training time is  0.9351503372192382 mins\n",
      "Valid: 2-shot EPOCH [171/200], STEP [10/33]\n",
      "Total Loss V: 0.44764429330825806\n",
      "Valid: 2-shot EPOCH [171/200], STEP [20/33]\n",
      "Total Loss V: 1.2074764966964722\n",
      "Valid: 2-shot EPOCH [171/200], STEP [30/33]\n",
      "Total Loss V: 0.2763875126838684\n",
      "EPOCH [172/200], STEP [11/134]\n",
      "Total Loss G: 0.15148355066776276\n",
      "EPOCH [172/200], STEP [21/134]\n",
      "Total Loss G: 0.25257495045661926\n",
      "EPOCH [172/200], STEP [31/134]\n",
      "Total Loss G: 0.15395648777484894\n",
      "EPOCH [172/200], STEP [41/134]\n",
      "Total Loss G: 0.6372009515762329\n",
      "EPOCH [172/200], STEP [51/134]\n",
      "Total Loss G: 0.11859583109617233\n",
      "EPOCH [172/200], STEP [61/134]\n",
      "Total Loss G: 0.1744542270898819\n",
      "EPOCH [172/200], STEP [71/134]\n",
      "Total Loss G: 0.16269205510616302\n",
      "EPOCH [172/200], STEP [81/134]\n",
      "Total Loss G: 0.11158067733049393\n",
      "EPOCH [172/200], STEP [91/134]\n",
      "Total Loss G: 0.15083427727222443\n",
      "EPOCH [172/200], STEP [101/134]\n",
      "Total Loss G: 0.18182331323623657\n",
      "EPOCH [172/200], STEP [111/134]\n",
      "Total Loss G: 0.12688112258911133\n",
      "EPOCH [172/200], STEP [121/134]\n",
      "Total Loss G: 0.48146700859069824\n",
      "EPOCH [172/200], STEP [131/134]\n",
      "Total Loss G: 0.2953282594680786\n",
      "EPOCH [172/200], STEP [141/134]\n",
      "Total Loss G: 0.13393175601959229\n",
      "Training time is  0.9255311648050945 mins\n",
      "Valid: 2-shot EPOCH [172/200], STEP [10/33]\n",
      "Total Loss V: 0.6705441474914551\n",
      "Valid: 2-shot EPOCH [172/200], STEP [20/33]\n",
      "Total Loss V: 0.5333832502365112\n",
      "Valid: 2-shot EPOCH [172/200], STEP [30/33]\n",
      "Total Loss V: 0.27495241165161133\n",
      "EPOCH [173/200], STEP [11/134]\n",
      "Total Loss G: 0.1740173101425171\n",
      "EPOCH [173/200], STEP [21/134]\n",
      "Total Loss G: 0.3217204511165619\n",
      "EPOCH [173/200], STEP [31/134]\n",
      "Total Loss G: 0.11685431003570557\n",
      "EPOCH [173/200], STEP [41/134]\n",
      "Total Loss G: 0.5970568060874939\n",
      "EPOCH [173/200], STEP [51/134]\n",
      "Total Loss G: 0.1156637892127037\n",
      "EPOCH [173/200], STEP [61/134]\n",
      "Total Loss G: 0.21724797785282135\n",
      "EPOCH [173/200], STEP [71/134]\n",
      "Total Loss G: 0.14257174730300903\n",
      "EPOCH [173/200], STEP [81/134]\n",
      "Total Loss G: 0.22671861946582794\n",
      "EPOCH [173/200], STEP [91/134]\n",
      "Total Loss G: 0.1778404265642166\n",
      "EPOCH [173/200], STEP [101/134]\n",
      "Total Loss G: 0.17163407802581787\n",
      "EPOCH [173/200], STEP [111/134]\n",
      "Total Loss G: 0.10214907675981522\n",
      "EPOCH [173/200], STEP [121/134]\n",
      "Total Loss G: 0.45725560188293457\n",
      "EPOCH [173/200], STEP [131/134]\n",
      "Total Loss G: 0.2505038380622864\n",
      "EPOCH [173/200], STEP [141/134]\n",
      "Total Loss G: 0.12700411677360535\n",
      "Training time is  0.9443258206049602 mins\n",
      "Valid: 2-shot EPOCH [173/200], STEP [10/33]\n",
      "Total Loss V: 0.5664236545562744\n",
      "Valid: 2-shot EPOCH [173/200], STEP [20/33]\n",
      "Total Loss V: 0.4048823118209839\n",
      "Valid: 2-shot EPOCH [173/200], STEP [30/33]\n",
      "Total Loss V: 0.4884932041168213\n",
      "EPOCH [174/200], STEP [11/134]\n",
      "Total Loss G: 0.1329330950975418\n",
      "EPOCH [174/200], STEP [21/134]\n",
      "Total Loss G: 0.2672838866710663\n",
      "EPOCH [174/200], STEP [31/134]\n",
      "Total Loss G: 0.09505051374435425\n",
      "EPOCH [174/200], STEP [41/134]\n",
      "Total Loss G: 0.5648308992385864\n",
      "EPOCH [174/200], STEP [51/134]\n",
      "Total Loss G: 0.19012326002120972\n",
      "EPOCH [174/200], STEP [61/134]\n",
      "Total Loss G: 0.15873940289020538\n",
      "EPOCH [174/200], STEP [71/134]\n",
      "Total Loss G: 0.16242451965808868\n",
      "EPOCH [174/200], STEP [81/134]\n",
      "Total Loss G: 0.11875712126493454\n",
      "EPOCH [174/200], STEP [91/134]\n",
      "Total Loss G: 0.1562739908695221\n",
      "EPOCH [174/200], STEP [101/134]\n",
      "Total Loss G: 0.15964676439762115\n",
      "EPOCH [174/200], STEP [111/134]\n",
      "Total Loss G: 0.10882443934679031\n",
      "EPOCH [174/200], STEP [121/134]\n",
      "Total Loss G: 0.48610612750053406\n",
      "EPOCH [174/200], STEP [131/134]\n",
      "Total Loss G: 0.3248344659805298\n",
      "EPOCH [174/200], STEP [141/134]\n",
      "Total Loss G: 0.1376584768295288\n",
      "Training time is  0.9415672779083252 mins\n",
      "Valid: 2-shot EPOCH [174/200], STEP [10/33]\n",
      "Total Loss V: 0.4113274812698364\n",
      "Valid: 2-shot EPOCH [174/200], STEP [20/33]\n",
      "Total Loss V: 0.4294276535511017\n",
      "Valid: 2-shot EPOCH [174/200], STEP [30/33]\n",
      "Total Loss V: 0.29998552799224854\n",
      "EPOCH [175/200], STEP [11/134]\n",
      "Total Loss G: 0.1214069277048111\n",
      "EPOCH [175/200], STEP [21/134]\n",
      "Total Loss G: 0.3273283541202545\n",
      "EPOCH [175/200], STEP [31/134]\n",
      "Total Loss G: 0.0939410850405693\n",
      "EPOCH [175/200], STEP [41/134]\n",
      "Total Loss G: 0.616205632686615\n",
      "EPOCH [175/200], STEP [51/134]\n",
      "Total Loss G: 0.1085265576839447\n",
      "EPOCH [175/200], STEP [61/134]\n",
      "Total Loss G: 0.1619357019662857\n",
      "EPOCH [175/200], STEP [71/134]\n",
      "Total Loss G: 0.13286519050598145\n",
      "EPOCH [175/200], STEP [81/134]\n",
      "Total Loss G: 0.1351202428340912\n",
      "EPOCH [175/200], STEP [91/134]\n",
      "Total Loss G: 0.15541362762451172\n",
      "EPOCH [175/200], STEP [101/134]\n",
      "Total Loss G: 0.16926945745944977\n",
      "EPOCH [175/200], STEP [111/134]\n",
      "Total Loss G: 0.09259632974863052\n",
      "EPOCH [175/200], STEP [121/134]\n",
      "Total Loss G: 0.4825185537338257\n",
      "EPOCH [175/200], STEP [131/134]\n",
      "Total Loss G: 0.2237585186958313\n",
      "EPOCH [175/200], STEP [141/134]\n",
      "Total Loss G: 0.14449593424797058\n",
      "Training time is  0.9446421265602112 mins\n",
      "Valid: 2-shot EPOCH [175/200], STEP [10/33]\n",
      "Total Loss V: 0.3424244821071625\n",
      "Valid: 2-shot EPOCH [175/200], STEP [20/33]\n",
      "Total Loss V: 0.27066925168037415\n",
      "Valid: 2-shot EPOCH [175/200], STEP [30/33]\n",
      "Total Loss V: 0.471681147813797\n",
      "EPOCH [176/200], STEP [11/134]\n",
      "Total Loss G: 0.15606990456581116\n",
      "EPOCH [176/200], STEP [21/134]\n",
      "Total Loss G: 0.29959556460380554\n",
      "EPOCH [176/200], STEP [31/134]\n",
      "Total Loss G: 0.10694583505392075\n",
      "EPOCH [176/200], STEP [41/134]\n",
      "Total Loss G: 0.6162977814674377\n",
      "EPOCH [176/200], STEP [51/134]\n",
      "Total Loss G: 0.18928395211696625\n",
      "EPOCH [176/200], STEP [61/134]\n",
      "Total Loss G: 0.1694391518831253\n",
      "EPOCH [176/200], STEP [71/134]\n",
      "Total Loss G: 0.1905929297208786\n",
      "EPOCH [176/200], STEP [81/134]\n",
      "Total Loss G: 0.1840616762638092\n",
      "EPOCH [176/200], STEP [91/134]\n",
      "Total Loss G: 0.2129792720079422\n",
      "EPOCH [176/200], STEP [101/134]\n",
      "Total Loss G: 0.2634914815425873\n",
      "EPOCH [176/200], STEP [111/134]\n",
      "Total Loss G: 0.11820980906486511\n",
      "EPOCH [176/200], STEP [121/134]\n",
      "Total Loss G: 0.4634498953819275\n",
      "EPOCH [176/200], STEP [131/134]\n",
      "Total Loss G: 0.29946693778038025\n",
      "EPOCH [176/200], STEP [141/134]\n",
      "Total Loss G: 0.11374015361070633\n",
      "Training time is  0.945190167427063 mins\n",
      "Valid: 2-shot EPOCH [176/200], STEP [10/33]\n",
      "Total Loss V: 0.37932637333869934\n",
      "Valid: 2-shot EPOCH [176/200], STEP [20/33]\n",
      "Total Loss V: 0.7011227011680603\n",
      "Valid: 2-shot EPOCH [176/200], STEP [30/33]\n",
      "Total Loss V: 0.4009126126766205\n",
      "EPOCH [177/200], STEP [11/134]\n",
      "Total Loss G: 0.12867678701877594\n",
      "EPOCH [177/200], STEP [21/134]\n",
      "Total Loss G: 0.329304963350296\n",
      "EPOCH [177/200], STEP [31/134]\n",
      "Total Loss G: 0.09545638412237167\n",
      "EPOCH [177/200], STEP [41/134]\n",
      "Total Loss G: 0.561359167098999\n",
      "EPOCH [177/200], STEP [51/134]\n",
      "Total Loss G: 0.14604313671588898\n",
      "EPOCH [177/200], STEP [61/134]\n",
      "Total Loss G: 0.17426623404026031\n",
      "EPOCH [177/200], STEP [71/134]\n",
      "Total Loss G: 0.18556134402751923\n",
      "EPOCH [177/200], STEP [81/134]\n",
      "Total Loss G: 0.1351238638162613\n",
      "EPOCH [177/200], STEP [91/134]\n",
      "Total Loss G: 0.22630903124809265\n",
      "EPOCH [177/200], STEP [101/134]\n",
      "Total Loss G: 0.16577166318893433\n",
      "EPOCH [177/200], STEP [111/134]\n",
      "Total Loss G: 0.10756704211235046\n",
      "EPOCH [177/200], STEP [121/134]\n",
      "Total Loss G: 0.4471692442893982\n",
      "EPOCH [177/200], STEP [131/134]\n",
      "Total Loss G: 0.3754101097583771\n",
      "EPOCH [177/200], STEP [141/134]\n",
      "Total Loss G: 0.12503354251384735\n",
      "Training time is  0.9442094445228577 mins\n",
      "Valid: 2-shot EPOCH [177/200], STEP [10/33]\n",
      "Total Loss V: 0.5710802674293518\n",
      "Valid: 2-shot EPOCH [177/200], STEP [20/33]\n",
      "Total Loss V: 1.068232536315918\n",
      "Valid: 2-shot EPOCH [177/200], STEP [30/33]\n",
      "Total Loss V: 0.2065981924533844\n",
      "EPOCH [178/200], STEP [11/134]\n",
      "Total Loss G: 0.16899143159389496\n",
      "EPOCH [178/200], STEP [21/134]\n",
      "Total Loss G: 0.2855457663536072\n",
      "EPOCH [178/200], STEP [31/134]\n",
      "Total Loss G: 0.15404923260211945\n",
      "EPOCH [178/200], STEP [41/134]\n",
      "Total Loss G: 0.6262634992599487\n",
      "EPOCH [178/200], STEP [51/134]\n",
      "Total Loss G: 0.23440682888031006\n",
      "EPOCH [178/200], STEP [61/134]\n",
      "Total Loss G: 0.38435906171798706\n",
      "EPOCH [178/200], STEP [71/134]\n",
      "Total Loss G: 0.14918194711208344\n",
      "EPOCH [178/200], STEP [81/134]\n",
      "Total Loss G: 0.11886590719223022\n",
      "EPOCH [178/200], STEP [91/134]\n",
      "Total Loss G: 0.22215799987316132\n",
      "EPOCH [178/200], STEP [101/134]\n",
      "Total Loss G: 0.19070374965667725\n",
      "EPOCH [178/200], STEP [111/134]\n",
      "Total Loss G: 0.08930177241563797\n",
      "EPOCH [178/200], STEP [121/134]\n",
      "Total Loss G: 0.4701901078224182\n",
      "EPOCH [178/200], STEP [131/134]\n",
      "Total Loss G: 0.2648690342903137\n",
      "EPOCH [178/200], STEP [141/134]\n",
      "Total Loss G: 0.12162984907627106\n",
      "Training time is  0.9375606139500936 mins\n",
      "Valid: 2-shot EPOCH [178/200], STEP [10/33]\n",
      "Total Loss V: 0.36707037687301636\n",
      "Valid: 2-shot EPOCH [178/200], STEP [20/33]\n",
      "Total Loss V: 0.618959367275238\n",
      "Valid: 2-shot EPOCH [178/200], STEP [30/33]\n",
      "Total Loss V: 0.30937451124191284\n",
      "EPOCH [179/200], STEP [11/134]\n",
      "Total Loss G: 0.1363896280527115\n",
      "EPOCH [179/200], STEP [21/134]\n",
      "Total Loss G: 0.246636301279068\n",
      "EPOCH [179/200], STEP [31/134]\n",
      "Total Loss G: 0.20987121760845184\n",
      "EPOCH [179/200], STEP [41/134]\n",
      "Total Loss G: 0.5430111289024353\n",
      "EPOCH [179/200], STEP [51/134]\n",
      "Total Loss G: 0.11158563196659088\n",
      "EPOCH [179/200], STEP [61/134]\n",
      "Total Loss G: 0.23217974603176117\n",
      "EPOCH [179/200], STEP [71/134]\n",
      "Total Loss G: 0.14262133836746216\n",
      "EPOCH [179/200], STEP [81/134]\n",
      "Total Loss G: 0.14549465477466583\n",
      "EPOCH [179/200], STEP [91/134]\n",
      "Total Loss G: 0.18072544038295746\n",
      "EPOCH [179/200], STEP [101/134]\n",
      "Total Loss G: 0.17088523507118225\n",
      "EPOCH [179/200], STEP [111/134]\n",
      "Total Loss G: 0.14898627996444702\n",
      "EPOCH [179/200], STEP [121/134]\n",
      "Total Loss G: 0.4547165632247925\n",
      "EPOCH [179/200], STEP [131/134]\n",
      "Total Loss G: 0.2849387228488922\n",
      "EPOCH [179/200], STEP [141/134]\n",
      "Total Loss G: 0.14282850921154022\n",
      "Training time is  0.9231493473052979 mins\n",
      "Valid: 2-shot EPOCH [179/200], STEP [10/33]\n",
      "Total Loss V: 0.3490874767303467\n",
      "Valid: 2-shot EPOCH [179/200], STEP [20/33]\n",
      "Total Loss V: 0.40496477484703064\n",
      "Valid: 2-shot EPOCH [179/200], STEP [30/33]\n",
      "Total Loss V: 0.17357127368450165\n",
      "EPOCH [180/200], STEP [11/134]\n",
      "Total Loss G: 0.11884637922048569\n",
      "EPOCH [180/200], STEP [21/134]\n",
      "Total Loss G: 0.2549775540828705\n",
      "EPOCH [180/200], STEP [31/134]\n",
      "Total Loss G: 0.08911515027284622\n",
      "EPOCH [180/200], STEP [41/134]\n",
      "Total Loss G: 0.5672852993011475\n",
      "EPOCH [180/200], STEP [51/134]\n",
      "Total Loss G: 0.1275026649236679\n",
      "EPOCH [180/200], STEP [61/134]\n",
      "Total Loss G: 0.16938747465610504\n",
      "EPOCH [180/200], STEP [71/134]\n",
      "Total Loss G: 0.19291022419929504\n",
      "EPOCH [180/200], STEP [81/134]\n",
      "Total Loss G: 0.15749263763427734\n",
      "EPOCH [180/200], STEP [91/134]\n",
      "Total Loss G: 0.17075523734092712\n",
      "EPOCH [180/200], STEP [101/134]\n",
      "Total Loss G: 0.1834089159965515\n",
      "EPOCH [180/200], STEP [111/134]\n",
      "Total Loss G: 0.10343755781650543\n",
      "EPOCH [180/200], STEP [121/134]\n",
      "Total Loss G: 0.45470425486564636\n",
      "EPOCH [180/200], STEP [131/134]\n",
      "Total Loss G: 0.2336699217557907\n",
      "EPOCH [180/200], STEP [141/134]\n",
      "Total Loss G: 0.11957857012748718\n",
      "Training time is  0.93968825340271 mins\n",
      "Valid: 2-shot EPOCH [180/200], STEP [10/33]\n",
      "Total Loss V: 0.3653755784034729\n",
      "Valid: 2-shot EPOCH [180/200], STEP [20/33]\n",
      "Total Loss V: 0.827788233757019\n",
      "Valid: 2-shot EPOCH [180/200], STEP [30/33]\n",
      "Total Loss V: 0.17915302515029907\n",
      "EPOCH [181/200], STEP [11/134]\n",
      "Total Loss G: 0.12643396854400635\n",
      "EPOCH [181/200], STEP [21/134]\n",
      "Total Loss G: 0.23694758117198944\n",
      "EPOCH [181/200], STEP [31/134]\n",
      "Total Loss G: 0.09568905085325241\n",
      "EPOCH [181/200], STEP [41/134]\n",
      "Total Loss G: 0.5312798023223877\n",
      "EPOCH [181/200], STEP [51/134]\n",
      "Total Loss G: 0.1092393547296524\n",
      "EPOCH [181/200], STEP [61/134]\n",
      "Total Loss G: 0.16116224229335785\n",
      "EPOCH [181/200], STEP [71/134]\n",
      "Total Loss G: 0.15699432790279388\n",
      "EPOCH [181/200], STEP [81/134]\n",
      "Total Loss G: 0.15618230402469635\n",
      "EPOCH [181/200], STEP [91/134]\n",
      "Total Loss G: 0.1488926261663437\n",
      "EPOCH [181/200], STEP [101/134]\n",
      "Total Loss G: 0.16557595133781433\n",
      "EPOCH [181/200], STEP [111/134]\n",
      "Total Loss G: 0.10267264395952225\n",
      "EPOCH [181/200], STEP [121/134]\n",
      "Total Loss G: 0.4833202362060547\n",
      "EPOCH [181/200], STEP [131/134]\n",
      "Total Loss G: 0.2517440617084503\n",
      "EPOCH [181/200], STEP [141/134]\n",
      "Total Loss G: 0.11994262784719467\n",
      "Training time is  0.939755364259084 mins\n",
      "Valid: 2-shot EPOCH [181/200], STEP [10/33]\n",
      "Total Loss V: 0.37957075238227844\n",
      "Valid: 2-shot EPOCH [181/200], STEP [20/33]\n",
      "Total Loss V: 0.5582399964332581\n",
      "Valid: 2-shot EPOCH [181/200], STEP [30/33]\n",
      "Total Loss V: 0.2686867415904999\n",
      "EPOCH [182/200], STEP [11/134]\n",
      "Total Loss G: 0.14982548356056213\n",
      "EPOCH [182/200], STEP [21/134]\n",
      "Total Loss G: 0.30131202936172485\n",
      "EPOCH [182/200], STEP [31/134]\n",
      "Total Loss G: 0.1100972518324852\n",
      "EPOCH [182/200], STEP [41/134]\n",
      "Total Loss G: 0.5816121697425842\n",
      "EPOCH [182/200], STEP [51/134]\n",
      "Total Loss G: 0.23465754091739655\n",
      "EPOCH [182/200], STEP [61/134]\n",
      "Total Loss G: 0.19999100267887115\n",
      "EPOCH [182/200], STEP [71/134]\n",
      "Total Loss G: 0.18822024762630463\n",
      "EPOCH [182/200], STEP [81/134]\n",
      "Total Loss G: 0.11767411977052689\n",
      "EPOCH [182/200], STEP [91/134]\n",
      "Total Loss G: 0.1487054079771042\n",
      "EPOCH [182/200], STEP [101/134]\n",
      "Total Loss G: 0.1649223119020462\n",
      "EPOCH [182/200], STEP [111/134]\n",
      "Total Loss G: 0.11588254570960999\n",
      "EPOCH [182/200], STEP [121/134]\n",
      "Total Loss G: 0.46706917881965637\n",
      "EPOCH [182/200], STEP [131/134]\n",
      "Total Loss G: 0.2607226073741913\n",
      "EPOCH [182/200], STEP [141/134]\n",
      "Total Loss G: 0.11462146788835526\n",
      "Training time is  0.9442616025606791 mins\n",
      "Valid: 2-shot EPOCH [182/200], STEP [10/33]\n",
      "Total Loss V: 0.4440866708755493\n",
      "Valid: 2-shot EPOCH [182/200], STEP [20/33]\n",
      "Total Loss V: 0.4488077163696289\n",
      "Valid: 2-shot EPOCH [182/200], STEP [30/33]\n",
      "Total Loss V: 0.14622554183006287\n",
      "EPOCH [183/200], STEP [11/134]\n",
      "Total Loss G: 0.1629399210214615\n",
      "EPOCH [183/200], STEP [21/134]\n",
      "Total Loss G: 0.24494382739067078\n",
      "EPOCH [183/200], STEP [31/134]\n",
      "Total Loss G: 0.10148706287145615\n",
      "EPOCH [183/200], STEP [41/134]\n",
      "Total Loss G: 0.5945079922676086\n",
      "EPOCH [183/200], STEP [51/134]\n",
      "Total Loss G: 0.12092983722686768\n",
      "EPOCH [183/200], STEP [61/134]\n",
      "Total Loss G: 0.17209066450595856\n",
      "EPOCH [183/200], STEP [71/134]\n",
      "Total Loss G: 0.14310701191425323\n",
      "EPOCH [183/200], STEP [81/134]\n",
      "Total Loss G: 0.10853846371173859\n",
      "EPOCH [183/200], STEP [91/134]\n",
      "Total Loss G: 0.18459029495716095\n",
      "EPOCH [183/200], STEP [101/134]\n",
      "Total Loss G: 0.16447779536247253\n",
      "EPOCH [183/200], STEP [111/134]\n",
      "Total Loss G: 0.09059441834688187\n",
      "EPOCH [183/200], STEP [121/134]\n",
      "Total Loss G: 0.4767491817474365\n",
      "EPOCH [183/200], STEP [131/134]\n",
      "Total Loss G: 0.23983539640903473\n",
      "EPOCH [183/200], STEP [141/134]\n",
      "Total Loss G: 0.12167440354824066\n",
      "Training time is  0.9424746831258138 mins\n",
      "Valid: 2-shot EPOCH [183/200], STEP [10/33]\n",
      "Total Loss V: 0.56069415807724\n",
      "Valid: 2-shot EPOCH [183/200], STEP [20/33]\n",
      "Total Loss V: 0.8162363767623901\n",
      "Valid: 2-shot EPOCH [183/200], STEP [30/33]\n",
      "Total Loss V: 0.4261372685432434\n",
      "EPOCH [184/200], STEP [11/134]\n",
      "Total Loss G: 0.15408046543598175\n",
      "EPOCH [184/200], STEP [21/134]\n",
      "Total Loss G: 0.25255507230758667\n",
      "EPOCH [184/200], STEP [31/134]\n",
      "Total Loss G: 0.16907082498073578\n",
      "EPOCH [184/200], STEP [41/134]\n",
      "Total Loss G: 0.5782148241996765\n",
      "EPOCH [184/200], STEP [51/134]\n",
      "Total Loss G: 0.11622211337089539\n",
      "EPOCH [184/200], STEP [61/134]\n",
      "Total Loss G: 0.15018068253993988\n",
      "EPOCH [184/200], STEP [71/134]\n",
      "Total Loss G: 0.1439935863018036\n",
      "EPOCH [184/200], STEP [81/134]\n",
      "Total Loss G: 0.18825450539588928\n",
      "EPOCH [184/200], STEP [91/134]\n",
      "Total Loss G: 0.17548345029354095\n",
      "EPOCH [184/200], STEP [101/134]\n",
      "Total Loss G: 0.20912964642047882\n",
      "EPOCH [184/200], STEP [111/134]\n",
      "Total Loss G: 0.08898673206567764\n",
      "EPOCH [184/200], STEP [121/134]\n",
      "Total Loss G: 0.46106112003326416\n",
      "EPOCH [184/200], STEP [131/134]\n",
      "Total Loss G: 0.2237013876438141\n",
      "EPOCH [184/200], STEP [141/134]\n",
      "Total Loss G: 0.11098445951938629\n",
      "Training time is  0.8794326941172282 mins\n",
      "Valid: 2-shot EPOCH [184/200], STEP [10/33]\n",
      "Total Loss V: 0.46239975094795227\n",
      "Valid: 2-shot EPOCH [184/200], STEP [20/33]\n",
      "Total Loss V: 0.6550611257553101\n",
      "Valid: 2-shot EPOCH [184/200], STEP [30/33]\n",
      "Total Loss V: 0.3171730935573578\n",
      "EPOCH [185/200], STEP [11/134]\n",
      "Total Loss G: 0.11097458004951477\n",
      "EPOCH [185/200], STEP [21/134]\n",
      "Total Loss G: 0.2518520951271057\n",
      "EPOCH [185/200], STEP [31/134]\n",
      "Total Loss G: 0.08421321958303452\n",
      "EPOCH [185/200], STEP [41/134]\n",
      "Total Loss G: 0.528836727142334\n",
      "EPOCH [185/200], STEP [51/134]\n",
      "Total Loss G: 0.10616271197795868\n",
      "EPOCH [185/200], STEP [61/134]\n",
      "Total Loss G: 0.23287276923656464\n",
      "EPOCH [185/200], STEP [71/134]\n",
      "Total Loss G: 0.1506890058517456\n",
      "EPOCH [185/200], STEP [81/134]\n",
      "Total Loss G: 0.14333802461624146\n",
      "EPOCH [185/200], STEP [91/134]\n",
      "Total Loss G: 0.12923771142959595\n",
      "EPOCH [185/200], STEP [101/134]\n",
      "Total Loss G: 0.15735486149787903\n",
      "EPOCH [185/200], STEP [111/134]\n",
      "Total Loss G: 0.10149585455656052\n",
      "EPOCH [185/200], STEP [121/134]\n",
      "Total Loss G: 0.453524112701416\n",
      "EPOCH [185/200], STEP [131/134]\n",
      "Total Loss G: 0.3278220295906067\n",
      "EPOCH [185/200], STEP [141/134]\n",
      "Total Loss G: 0.15719325840473175\n",
      "Training time is  0.8314928929011027 mins\n",
      "Valid: 2-shot EPOCH [185/200], STEP [10/33]\n",
      "Total Loss V: 0.5123844742774963\n",
      "Valid: 2-shot EPOCH [185/200], STEP [20/33]\n",
      "Total Loss V: 0.4184587597846985\n",
      "Valid: 2-shot EPOCH [185/200], STEP [30/33]\n",
      "Total Loss V: 0.3571505844593048\n",
      "EPOCH [186/200], STEP [11/134]\n",
      "Total Loss G: 0.15627482533454895\n",
      "EPOCH [186/200], STEP [21/134]\n",
      "Total Loss G: 0.256582647562027\n",
      "EPOCH [186/200], STEP [31/134]\n",
      "Total Loss G: 0.1241644099354744\n",
      "EPOCH [186/200], STEP [41/134]\n",
      "Total Loss G: 0.576117992401123\n",
      "EPOCH [186/200], STEP [51/134]\n",
      "Total Loss G: 0.12340392172336578\n",
      "EPOCH [186/200], STEP [61/134]\n",
      "Total Loss G: 0.1495470404624939\n",
      "EPOCH [186/200], STEP [71/134]\n",
      "Total Loss G: 0.15866892039775848\n",
      "EPOCH [186/200], STEP [81/134]\n",
      "Total Loss G: 0.12192939221858978\n",
      "EPOCH [186/200], STEP [91/134]\n",
      "Total Loss G: 0.16134987771511078\n",
      "EPOCH [186/200], STEP [101/134]\n",
      "Total Loss G: 0.25949156284332275\n",
      "EPOCH [186/200], STEP [111/134]\n",
      "Total Loss G: 0.10214827954769135\n",
      "EPOCH [186/200], STEP [121/134]\n",
      "Total Loss G: 0.4419989287853241\n",
      "EPOCH [186/200], STEP [131/134]\n",
      "Total Loss G: 0.2606132924556732\n",
      "EPOCH [186/200], STEP [141/134]\n",
      "Total Loss G: 0.13156211376190186\n",
      "Training time is  0.8324085791905721 mins\n",
      "Valid: 2-shot EPOCH [186/200], STEP [10/33]\n",
      "Total Loss V: 0.350467324256897\n",
      "Valid: 2-shot EPOCH [186/200], STEP [20/33]\n",
      "Total Loss V: 0.3331887722015381\n",
      "Valid: 2-shot EPOCH [186/200], STEP [30/33]\n",
      "Total Loss V: 0.14490488171577454\n",
      "EPOCH [187/200], STEP [11/134]\n",
      "Total Loss G: 0.16360121965408325\n",
      "EPOCH [187/200], STEP [21/134]\n",
      "Total Loss G: 0.2517502009868622\n",
      "EPOCH [187/200], STEP [31/134]\n",
      "Total Loss G: 0.09539595991373062\n",
      "EPOCH [187/200], STEP [41/134]\n",
      "Total Loss G: 0.5921343564987183\n",
      "EPOCH [187/200], STEP [51/134]\n",
      "Total Loss G: 0.12935663759708405\n",
      "EPOCH [187/200], STEP [61/134]\n",
      "Total Loss G: 0.17582467198371887\n",
      "EPOCH [187/200], STEP [71/134]\n",
      "Total Loss G: 0.12929199635982513\n",
      "EPOCH [187/200], STEP [81/134]\n",
      "Total Loss G: 0.12738534808158875\n",
      "EPOCH [187/200], STEP [91/134]\n",
      "Total Loss G: 0.21156704425811768\n",
      "EPOCH [187/200], STEP [101/134]\n",
      "Total Loss G: 0.17037047445774078\n",
      "EPOCH [187/200], STEP [111/134]\n",
      "Total Loss G: 0.0923207551240921\n",
      "EPOCH [187/200], STEP [121/134]\n",
      "Total Loss G: 0.49263304471969604\n",
      "EPOCH [187/200], STEP [131/134]\n",
      "Total Loss G: 0.30699217319488525\n",
      "EPOCH [187/200], STEP [141/134]\n",
      "Total Loss G: 0.11851945519447327\n",
      "Training time is  0.9077408075332641 mins\n",
      "Valid: 2-shot EPOCH [187/200], STEP [10/33]\n",
      "Total Loss V: 0.43119823932647705\n",
      "Valid: 2-shot EPOCH [187/200], STEP [20/33]\n",
      "Total Loss V: 0.6789977550506592\n",
      "Valid: 2-shot EPOCH [187/200], STEP [30/33]\n",
      "Total Loss V: 0.2744150757789612\n",
      "EPOCH [188/200], STEP [11/134]\n",
      "Total Loss G: 0.1619126796722412\n",
      "EPOCH [188/200], STEP [21/134]\n",
      "Total Loss G: 0.2443327158689499\n",
      "EPOCH [188/200], STEP [31/134]\n",
      "Total Loss G: 0.1298057585954666\n",
      "EPOCH [188/200], STEP [41/134]\n",
      "Total Loss G: 0.5551644563674927\n",
      "EPOCH [188/200], STEP [51/134]\n",
      "Total Loss G: 0.12530726194381714\n",
      "EPOCH [188/200], STEP [61/134]\n",
      "Total Loss G: 0.19403332471847534\n",
      "EPOCH [188/200], STEP [71/134]\n",
      "Total Loss G: 0.2628718912601471\n",
      "EPOCH [188/200], STEP [81/134]\n",
      "Total Loss G: 0.11468460410833359\n",
      "EPOCH [188/200], STEP [91/134]\n",
      "Total Loss G: 0.19283312559127808\n",
      "EPOCH [188/200], STEP [101/134]\n",
      "Total Loss G: 0.1579952985048294\n",
      "EPOCH [188/200], STEP [111/134]\n",
      "Total Loss G: 0.12176156044006348\n",
      "EPOCH [188/200], STEP [121/134]\n",
      "Total Loss G: 0.4494082033634186\n",
      "EPOCH [188/200], STEP [131/134]\n",
      "Total Loss G: 0.2656416893005371\n",
      "EPOCH [188/200], STEP [141/134]\n",
      "Total Loss G: 0.12069250643253326\n",
      "Training time is  0.9348762631416321 mins\n",
      "Valid: 2-shot EPOCH [188/200], STEP [10/33]\n",
      "Total Loss V: 0.4315345585346222\n",
      "Valid: 2-shot EPOCH [188/200], STEP [20/33]\n",
      "Total Loss V: 0.6733143329620361\n",
      "Valid: 2-shot EPOCH [188/200], STEP [30/33]\n",
      "Total Loss V: 0.20409400761127472\n",
      "EPOCH [189/200], STEP [11/134]\n",
      "Total Loss G: 0.13062553107738495\n",
      "EPOCH [189/200], STEP [21/134]\n",
      "Total Loss G: 0.2775849401950836\n",
      "EPOCH [189/200], STEP [31/134]\n",
      "Total Loss G: 0.14209645986557007\n",
      "EPOCH [189/200], STEP [41/134]\n",
      "Total Loss G: 0.5084524154663086\n",
      "EPOCH [189/200], STEP [51/134]\n",
      "Total Loss G: 0.14240659773349762\n",
      "EPOCH [189/200], STEP [61/134]\n",
      "Total Loss G: 0.14853225648403168\n",
      "EPOCH [189/200], STEP [71/134]\n",
      "Total Loss G: 0.14201535284519196\n",
      "EPOCH [189/200], STEP [81/134]\n",
      "Total Loss G: 0.10509932786226273\n",
      "EPOCH [189/200], STEP [91/134]\n",
      "Total Loss G: 0.19701102375984192\n",
      "EPOCH [189/200], STEP [101/134]\n",
      "Total Loss G: 0.16495810449123383\n",
      "EPOCH [189/200], STEP [111/134]\n",
      "Total Loss G: 0.12206825613975525\n",
      "EPOCH [189/200], STEP [121/134]\n",
      "Total Loss G: 0.44807231426239014\n",
      "EPOCH [189/200], STEP [131/134]\n",
      "Total Loss G: 0.23424312472343445\n",
      "EPOCH [189/200], STEP [141/134]\n",
      "Total Loss G: 0.13823767006397247\n",
      "Training time is  0.898980446656545 mins\n",
      "Valid: 2-shot EPOCH [189/200], STEP [10/33]\n",
      "Total Loss V: 0.5082776546478271\n",
      "Valid: 2-shot EPOCH [189/200], STEP [20/33]\n",
      "Total Loss V: 0.6885968446731567\n",
      "Valid: 2-shot EPOCH [189/200], STEP [30/33]\n",
      "Total Loss V: 0.14333949983119965\n",
      "EPOCH [190/200], STEP [11/134]\n",
      "Total Loss G: 0.11867395043373108\n",
      "EPOCH [190/200], STEP [21/134]\n",
      "Total Loss G: 0.24953524768352509\n",
      "EPOCH [190/200], STEP [31/134]\n",
      "Total Loss G: 0.10462706536054611\n",
      "EPOCH [190/200], STEP [41/134]\n",
      "Total Loss G: 0.5523484945297241\n",
      "EPOCH [190/200], STEP [51/134]\n",
      "Total Loss G: 0.15294569730758667\n",
      "EPOCH [190/200], STEP [61/134]\n",
      "Total Loss G: 0.19069908559322357\n",
      "EPOCH [190/200], STEP [71/134]\n",
      "Total Loss G: 0.4182302951812744\n",
      "EPOCH [190/200], STEP [81/134]\n",
      "Total Loss G: 0.13580887019634247\n",
      "EPOCH [190/200], STEP [91/134]\n",
      "Total Loss G: 0.20537841320037842\n",
      "EPOCH [190/200], STEP [101/134]\n",
      "Total Loss G: 0.14938832819461823\n",
      "EPOCH [190/200], STEP [111/134]\n",
      "Total Loss G: 0.10333799570798874\n",
      "EPOCH [190/200], STEP [121/134]\n",
      "Total Loss G: 0.4908154308795929\n",
      "EPOCH [190/200], STEP [131/134]\n",
      "Total Loss G: 0.26069483160972595\n",
      "EPOCH [190/200], STEP [141/134]\n",
      "Total Loss G: 0.11874532699584961\n",
      "Training time is  0.9327904462814331 mins\n",
      "Valid: 2-shot EPOCH [190/200], STEP [10/33]\n",
      "Total Loss V: 0.3631199598312378\n",
      "Valid: 2-shot EPOCH [190/200], STEP [20/33]\n",
      "Total Loss V: 0.7395661473274231\n",
      "Valid: 2-shot EPOCH [190/200], STEP [30/33]\n",
      "Total Loss V: 0.43188661336898804\n",
      "EPOCH [191/200], STEP [11/134]\n",
      "Total Loss G: 0.12640509009361267\n",
      "EPOCH [191/200], STEP [21/134]\n",
      "Total Loss G: 0.2545572519302368\n",
      "EPOCH [191/200], STEP [31/134]\n",
      "Total Loss G: 0.11307329684495926\n",
      "EPOCH [191/200], STEP [41/134]\n",
      "Total Loss G: 0.7050840258598328\n",
      "EPOCH [191/200], STEP [51/134]\n",
      "Total Loss G: 0.13175763189792633\n",
      "EPOCH [191/200], STEP [61/134]\n",
      "Total Loss G: 0.1468973457813263\n",
      "EPOCH [191/200], STEP [71/134]\n",
      "Total Loss G: 0.14882111549377441\n",
      "EPOCH [191/200], STEP [81/134]\n",
      "Total Loss G: 0.11772830784320831\n",
      "EPOCH [191/200], STEP [91/134]\n",
      "Total Loss G: 0.14917854964733124\n",
      "EPOCH [191/200], STEP [101/134]\n",
      "Total Loss G: 0.1624869704246521\n",
      "EPOCH [191/200], STEP [111/134]\n",
      "Total Loss G: 0.12058873474597931\n",
      "EPOCH [191/200], STEP [121/134]\n",
      "Total Loss G: 0.48685482144355774\n",
      "EPOCH [191/200], STEP [131/134]\n",
      "Total Loss G: 0.26454684138298035\n",
      "EPOCH [191/200], STEP [141/134]\n",
      "Total Loss G: 0.12826937437057495\n",
      "Training time is  0.9430492242177327 mins\n",
      "Valid: 2-shot EPOCH [191/200], STEP [10/33]\n",
      "Total Loss V: 0.26388826966285706\n",
      "Valid: 2-shot EPOCH [191/200], STEP [20/33]\n",
      "Total Loss V: 0.4402676522731781\n",
      "Valid: 2-shot EPOCH [191/200], STEP [30/33]\n",
      "Total Loss V: 0.19599048793315887\n",
      "EPOCH [192/200], STEP [11/134]\n",
      "Total Loss G: 0.12013676762580872\n",
      "EPOCH [192/200], STEP [21/134]\n",
      "Total Loss G: 0.2267945557832718\n",
      "EPOCH [192/200], STEP [31/134]\n",
      "Total Loss G: 0.08594813942909241\n",
      "EPOCH [192/200], STEP [41/134]\n",
      "Total Loss G: 0.5607339143753052\n",
      "EPOCH [192/200], STEP [51/134]\n",
      "Total Loss G: 0.10449913889169693\n",
      "EPOCH [192/200], STEP [61/134]\n",
      "Total Loss G: 0.2034343183040619\n",
      "EPOCH [192/200], STEP [71/134]\n",
      "Total Loss G: 0.17983822524547577\n",
      "EPOCH [192/200], STEP [81/134]\n",
      "Total Loss G: 0.1290874034166336\n",
      "EPOCH [192/200], STEP [91/134]\n",
      "Total Loss G: 0.17371509969234467\n",
      "EPOCH [192/200], STEP [101/134]\n",
      "Total Loss G: 0.15426985919475555\n",
      "EPOCH [192/200], STEP [111/134]\n",
      "Total Loss G: 0.1326514631509781\n",
      "EPOCH [192/200], STEP [121/134]\n",
      "Total Loss G: 0.4410698711872101\n",
      "EPOCH [192/200], STEP [131/134]\n",
      "Total Loss G: 0.25431010127067566\n",
      "EPOCH [192/200], STEP [141/134]\n",
      "Total Loss G: 0.10937613993883133\n",
      "Training time is  0.9353952328364055 mins\n",
      "Valid: 2-shot EPOCH [192/200], STEP [10/33]\n",
      "Total Loss V: 0.40156012773513794\n",
      "Valid: 2-shot EPOCH [192/200], STEP [20/33]\n",
      "Total Loss V: 0.601327657699585\n",
      "Valid: 2-shot EPOCH [192/200], STEP [30/33]\n",
      "Total Loss V: 0.29036155343055725\n",
      "EPOCH [193/200], STEP [11/134]\n",
      "Total Loss G: 0.11282162368297577\n",
      "EPOCH [193/200], STEP [21/134]\n",
      "Total Loss G: 0.22560887038707733\n",
      "EPOCH [193/200], STEP [31/134]\n",
      "Total Loss G: 0.09413277357816696\n",
      "EPOCH [193/200], STEP [41/134]\n",
      "Total Loss G: 0.5097516179084778\n",
      "EPOCH [193/200], STEP [51/134]\n",
      "Total Loss G: 0.1806257665157318\n",
      "EPOCH [193/200], STEP [61/134]\n",
      "Total Loss G: 0.16040925681591034\n",
      "EPOCH [193/200], STEP [71/134]\n",
      "Total Loss G: 0.2292269468307495\n",
      "EPOCH [193/200], STEP [81/134]\n",
      "Total Loss G: 0.23052796721458435\n",
      "EPOCH [193/200], STEP [91/134]\n",
      "Total Loss G: 0.21969491243362427\n",
      "EPOCH [193/200], STEP [101/134]\n",
      "Total Loss G: 0.18472589552402496\n",
      "EPOCH [193/200], STEP [111/134]\n",
      "Total Loss G: 0.11578509956598282\n",
      "EPOCH [193/200], STEP [121/134]\n",
      "Total Loss G: 0.6131766438484192\n",
      "EPOCH [193/200], STEP [131/134]\n",
      "Total Loss G: 0.24720235168933868\n",
      "EPOCH [193/200], STEP [141/134]\n",
      "Total Loss G: 0.12299709767103195\n",
      "Training time is  0.9459049304326376 mins\n",
      "Valid: 2-shot EPOCH [193/200], STEP [10/33]\n",
      "Total Loss V: 0.2604347765445709\n",
      "Valid: 2-shot EPOCH [193/200], STEP [20/33]\n",
      "Total Loss V: 1.1475450992584229\n",
      "Valid: 2-shot EPOCH [193/200], STEP [30/33]\n",
      "Total Loss V: 0.11522889882326126\n",
      "EPOCH [194/200], STEP [11/134]\n",
      "Total Loss G: 0.12963807582855225\n",
      "EPOCH [194/200], STEP [21/134]\n",
      "Total Loss G: 0.393820583820343\n",
      "EPOCH [194/200], STEP [31/134]\n",
      "Total Loss G: 0.10865359008312225\n",
      "EPOCH [194/200], STEP [41/134]\n",
      "Total Loss G: 0.5663468837738037\n",
      "EPOCH [194/200], STEP [51/134]\n",
      "Total Loss G: 0.09508319199085236\n",
      "EPOCH [194/200], STEP [61/134]\n",
      "Total Loss G: 0.3508080542087555\n",
      "EPOCH [194/200], STEP [71/134]\n",
      "Total Loss G: 0.2253449261188507\n",
      "EPOCH [194/200], STEP [81/134]\n",
      "Total Loss G: 0.10439539700746536\n",
      "EPOCH [194/200], STEP [91/134]\n",
      "Total Loss G: 0.1748548448085785\n",
      "EPOCH [194/200], STEP [101/134]\n",
      "Total Loss G: 0.1736970692873001\n",
      "EPOCH [194/200], STEP [111/134]\n",
      "Total Loss G: 0.12468940764665604\n",
      "EPOCH [194/200], STEP [121/134]\n",
      "Total Loss G: 0.4713823199272156\n",
      "EPOCH [194/200], STEP [131/134]\n",
      "Total Loss G: 0.2690340280532837\n",
      "EPOCH [194/200], STEP [141/134]\n",
      "Total Loss G: 0.1429852694272995\n",
      "Training time is  0.9424807786941528 mins\n",
      "Valid: 2-shot EPOCH [194/200], STEP [10/33]\n",
      "Total Loss V: 0.3810678720474243\n",
      "Valid: 2-shot EPOCH [194/200], STEP [20/33]\n",
      "Total Loss V: 0.4099102318286896\n",
      "Valid: 2-shot EPOCH [194/200], STEP [30/33]\n",
      "Total Loss V: 0.24373942613601685\n",
      "EPOCH [195/200], STEP [11/134]\n",
      "Total Loss G: 0.2279285192489624\n",
      "EPOCH [195/200], STEP [21/134]\n",
      "Total Loss G: 0.2507440745830536\n",
      "EPOCH [195/200], STEP [31/134]\n",
      "Total Loss G: 0.10001879185438156\n",
      "EPOCH [195/200], STEP [41/134]\n",
      "Total Loss G: 0.5291134119033813\n",
      "EPOCH [195/200], STEP [51/134]\n",
      "Total Loss G: 0.09056691825389862\n",
      "EPOCH [195/200], STEP [61/134]\n",
      "Total Loss G: 0.16647154092788696\n",
      "EPOCH [195/200], STEP [71/134]\n",
      "Total Loss G: 0.3560979664325714\n",
      "EPOCH [195/200], STEP [81/134]\n",
      "Total Loss G: 0.19016899168491364\n",
      "EPOCH [195/200], STEP [91/134]\n",
      "Total Loss G: 0.14325851202011108\n",
      "EPOCH [195/200], STEP [101/134]\n",
      "Total Loss G: 0.2511325180530548\n",
      "EPOCH [195/200], STEP [111/134]\n",
      "Total Loss G: 0.0923658087849617\n",
      "EPOCH [195/200], STEP [121/134]\n",
      "Total Loss G: 0.44647881388664246\n",
      "EPOCH [195/200], STEP [131/134]\n",
      "Total Loss G: 0.21912553906440735\n",
      "EPOCH [195/200], STEP [141/134]\n",
      "Total Loss G: 0.11426293849945068\n",
      "Training time is  0.9443749984105428 mins\n",
      "Valid: 2-shot EPOCH [195/200], STEP [10/33]\n",
      "Total Loss V: 0.3522515594959259\n",
      "Valid: 2-shot EPOCH [195/200], STEP [20/33]\n",
      "Total Loss V: 0.3142370879650116\n",
      "Valid: 2-shot EPOCH [195/200], STEP [30/33]\n",
      "Total Loss V: 0.14816567301750183\n",
      "EPOCH [196/200], STEP [11/134]\n",
      "Total Loss G: 0.12237536907196045\n",
      "EPOCH [196/200], STEP [21/134]\n",
      "Total Loss G: 0.24072447419166565\n",
      "EPOCH [196/200], STEP [31/134]\n",
      "Total Loss G: 0.09361177682876587\n",
      "EPOCH [196/200], STEP [41/134]\n",
      "Total Loss G: 0.5738318562507629\n",
      "EPOCH [196/200], STEP [51/134]\n",
      "Total Loss G: 0.10209810733795166\n",
      "EPOCH [196/200], STEP [61/134]\n",
      "Total Loss G: 0.1583668738603592\n",
      "EPOCH [196/200], STEP [71/134]\n",
      "Total Loss G: 0.2772331237792969\n",
      "EPOCH [196/200], STEP [81/134]\n",
      "Total Loss G: 0.11526152491569519\n",
      "EPOCH [196/200], STEP [91/134]\n",
      "Total Loss G: 0.1788816750049591\n",
      "EPOCH [196/200], STEP [101/134]\n",
      "Total Loss G: 0.1582575887441635\n",
      "EPOCH [196/200], STEP [111/134]\n",
      "Total Loss G: 0.09215322881937027\n",
      "EPOCH [196/200], STEP [121/134]\n",
      "Total Loss G: 0.4071943759918213\n",
      "EPOCH [196/200], STEP [131/134]\n",
      "Total Loss G: 0.30678775906562805\n",
      "EPOCH [196/200], STEP [141/134]\n",
      "Total Loss G: 0.1267644762992859\n",
      "Training time is  0.9412507136662801 mins\n",
      "Valid: 2-shot EPOCH [196/200], STEP [10/33]\n",
      "Total Loss V: 0.44950008392333984\n",
      "Valid: 2-shot EPOCH [196/200], STEP [20/33]\n",
      "Total Loss V: 0.6481085419654846\n",
      "Valid: 2-shot EPOCH [196/200], STEP [30/33]\n",
      "Total Loss V: 0.542591392993927\n",
      "EPOCH [197/200], STEP [11/134]\n",
      "Total Loss G: 0.2003394216299057\n",
      "EPOCH [197/200], STEP [21/134]\n",
      "Total Loss G: 0.25464650988578796\n",
      "EPOCH [197/200], STEP [31/134]\n",
      "Total Loss G: 0.09255251288414001\n",
      "EPOCH [197/200], STEP [41/134]\n",
      "Total Loss G: 0.5383643507957458\n",
      "EPOCH [197/200], STEP [51/134]\n",
      "Total Loss G: 0.10490599274635315\n",
      "EPOCH [197/200], STEP [61/134]\n",
      "Total Loss G: 0.1325550079345703\n",
      "EPOCH [197/200], STEP [71/134]\n",
      "Total Loss G: 0.21649068593978882\n",
      "EPOCH [197/200], STEP [81/134]\n",
      "Total Loss G: 0.13085928559303284\n",
      "EPOCH [197/200], STEP [91/134]\n",
      "Total Loss G: 0.1572536677122116\n",
      "EPOCH [197/200], STEP [101/134]\n",
      "Total Loss G: 0.15833531320095062\n",
      "EPOCH [197/200], STEP [111/134]\n",
      "Total Loss G: 0.11667519807815552\n",
      "EPOCH [197/200], STEP [121/134]\n",
      "Total Loss G: 0.41500526666641235\n",
      "EPOCH [197/200], STEP [131/134]\n",
      "Total Loss G: 0.24212965369224548\n",
      "EPOCH [197/200], STEP [141/134]\n",
      "Total Loss G: 0.11792825907468796\n",
      "Training time is  0.9487972219785055 mins\n",
      "Valid: 2-shot EPOCH [197/200], STEP [10/33]\n",
      "Total Loss V: 0.4531583786010742\n",
      "Valid: 2-shot EPOCH [197/200], STEP [20/33]\n",
      "Total Loss V: 0.5690875053405762\n",
      "Valid: 2-shot EPOCH [197/200], STEP [30/33]\n",
      "Total Loss V: 0.2785038650035858\n",
      "EPOCH [198/200], STEP [11/134]\n",
      "Total Loss G: 0.12133929133415222\n",
      "EPOCH [198/200], STEP [21/134]\n",
      "Total Loss G: 0.24538035690784454\n",
      "EPOCH [198/200], STEP [31/134]\n",
      "Total Loss G: 0.10510807484388351\n",
      "EPOCH [198/200], STEP [41/134]\n",
      "Total Loss G: 0.5194677114486694\n",
      "EPOCH [198/200], STEP [51/134]\n",
      "Total Loss G: 0.10880658775568008\n",
      "EPOCH [198/200], STEP [61/134]\n",
      "Total Loss G: 0.1400252729654312\n",
      "EPOCH [198/200], STEP [71/134]\n",
      "Total Loss G: 0.1581803560256958\n",
      "EPOCH [198/200], STEP [81/134]\n",
      "Total Loss G: 0.1256430596113205\n",
      "EPOCH [198/200], STEP [91/134]\n",
      "Total Loss G: 0.16785988211631775\n",
      "EPOCH [198/200], STEP [101/134]\n",
      "Total Loss G: 0.18194682896137238\n",
      "EPOCH [198/200], STEP [111/134]\n",
      "Total Loss G: 0.10789777338504791\n",
      "EPOCH [198/200], STEP [121/134]\n",
      "Total Loss G: 0.4235597550868988\n",
      "EPOCH [198/200], STEP [131/134]\n",
      "Total Loss G: 0.22838978469371796\n",
      "EPOCH [198/200], STEP [141/134]\n",
      "Total Loss G: 0.11703843623399734\n",
      "Training time is  0.9441928346951802 mins\n",
      "Valid: 2-shot EPOCH [198/200], STEP [10/33]\n",
      "Total Loss V: 0.523288905620575\n",
      "Valid: 2-shot EPOCH [198/200], STEP [20/33]\n",
      "Total Loss V: 0.6757495403289795\n",
      "Valid: 2-shot EPOCH [198/200], STEP [30/33]\n",
      "Total Loss V: 0.366895854473114\n",
      "EPOCH [199/200], STEP [11/134]\n",
      "Total Loss G: 0.15148521959781647\n",
      "EPOCH [199/200], STEP [21/134]\n",
      "Total Loss G: 0.27049416303634644\n",
      "EPOCH [199/200], STEP [31/134]\n",
      "Total Loss G: 0.10140305012464523\n",
      "EPOCH [199/200], STEP [41/134]\n",
      "Total Loss G: 0.5422704219818115\n",
      "EPOCH [199/200], STEP [51/134]\n",
      "Total Loss G: 0.20539115369319916\n",
      "EPOCH [199/200], STEP [61/134]\n",
      "Total Loss G: 0.24868683516979218\n",
      "EPOCH [199/200], STEP [71/134]\n",
      "Total Loss G: 0.277322381734848\n",
      "EPOCH [199/200], STEP [81/134]\n",
      "Total Loss G: 0.1878701150417328\n",
      "EPOCH [199/200], STEP [91/134]\n",
      "Total Loss G: 0.1539301574230194\n",
      "EPOCH [199/200], STEP [101/134]\n",
      "Total Loss G: 0.1556728631258011\n",
      "EPOCH [199/200], STEP [111/134]\n",
      "Total Loss G: 0.10005481541156769\n",
      "EPOCH [199/200], STEP [121/134]\n",
      "Total Loss G: 0.4505416750907898\n",
      "EPOCH [199/200], STEP [131/134]\n",
      "Total Loss G: 0.3064144551753998\n",
      "EPOCH [199/200], STEP [141/134]\n",
      "Total Loss G: 0.12300965189933777\n",
      "Training time is  0.9455392479896545 mins\n",
      "Valid: 2-shot EPOCH [199/200], STEP [10/33]\n",
      "Total Loss V: 0.3822973370552063\n",
      "Valid: 2-shot EPOCH [199/200], STEP [20/33]\n",
      "Total Loss V: 0.5053762197494507\n",
      "Valid: 2-shot EPOCH [199/200], STEP [30/33]\n",
      "Total Loss V: 0.2050553560256958\n",
      "EPOCH [200/200], STEP [11/134]\n",
      "Total Loss G: 0.228877991437912\n",
      "EPOCH [200/200], STEP [21/134]\n",
      "Total Loss G: 0.2793841063976288\n",
      "EPOCH [200/200], STEP [31/134]\n",
      "Total Loss G: 0.10009265691041946\n",
      "EPOCH [200/200], STEP [41/134]\n",
      "Total Loss G: 0.5993866324424744\n",
      "EPOCH [200/200], STEP [51/134]\n",
      "Total Loss G: 0.21863842010498047\n",
      "EPOCH [200/200], STEP [61/134]\n",
      "Total Loss G: 0.18221817910671234\n",
      "EPOCH [200/200], STEP [71/134]\n",
      "Total Loss G: 0.13884638249874115\n",
      "EPOCH [200/200], STEP [81/134]\n",
      "Total Loss G: 0.11776981502771378\n",
      "EPOCH [200/200], STEP [91/134]\n",
      "Total Loss G: 0.16224417090415955\n",
      "EPOCH [200/200], STEP [101/134]\n",
      "Total Loss G: 0.16646267473697662\n",
      "EPOCH [200/200], STEP [111/134]\n",
      "Total Loss G: 0.17218822240829468\n",
      "EPOCH [200/200], STEP [121/134]\n",
      "Total Loss G: 0.46043816208839417\n",
      "EPOCH [200/200], STEP [131/134]\n",
      "Total Loss G: 0.24197964370250702\n",
      "EPOCH [200/200], STEP [141/134]\n",
      "Total Loss G: 0.14119523763656616\n",
      "Training time is  0.9443091869354248 mins\n",
      "Valid: 2-shot EPOCH [200/200], STEP [10/33]\n",
      "Total Loss V: 0.35708218812942505\n",
      "Valid: 2-shot EPOCH [200/200], STEP [20/33]\n",
      "Total Loss V: 0.5522030591964722\n",
      "Valid: 2-shot EPOCH [200/200], STEP [30/33]\n",
      "Total Loss V: 0.19208930432796478\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    parser = argparse.ArgumentParser(description='parameters of PINN')\n",
    "    parser.add_argument('--NUM_EPOCH', default = 200, type=int,nargs='*', help='number of epochs')\n",
    "    parser.add_argument('--START_EPOCH', default = 0, type=int, nargs='*', help='start epoch')\n",
    "    parser.add_argument('--DECAY_EPOCH', default = 5, type=int, nargs='*', help='decay epoch')\n",
    "    parser.add_argument('--CRITIC_ITER', default = 1, type=int, nargs='*', help='critic iteration')\n",
    "    parser.add_argument('--SAVE_EPOCH', default = 10, type=int, nargs='*', help='save iteration')\n",
    "    parser.add_argument('--BATCH_SIZE', default = 1, type=int, nargs=1, help='batch size')\n",
    "    parser.add_argument('--lr', default = 5e-4, type=float, nargs=1, help='initial learning rate')\n",
    "    parser.add_argument('--beta1', default = 0.9, type=float, nargs=1, help='first-moment exponential decay rate')\n",
    "    parser.add_argument('--beta2', default = 0.999, type=float, nargs=1, help='second-moment exponential decay rate')\n",
    "    parser.add_argument('--input_nc', default = 1, type=int, nargs=1, help='input channel')\n",
    "    parser.add_argument('--output_nc', default = 1, type=int, nargs=1, help='output channel')\n",
    "    parser.add_argument('--nf', default = 32, type=int, nargs=1, help='number of filters')\n",
    "    parser.add_argument('--ks', default = 3, type=int, nargs=1, help='kernel size')\n",
    "    parser.add_argument('--tradeoff', default = 1e-2, nargs=1, type=float, help='trade-off value')\n",
    "    parser.add_argument('--itr_method', default = 'learn', nargs=1, type=str, help='constant or learning trade-off value')\n",
    "    parser.add_argument('--dpix', default = 0.22e-6, type=float, nargs=1, help='pixel size')\n",
    "    parser.add_argument('--d', default = 2e-6, type=float, nargs=1, help='propagation distance')\n",
    "    parser.add_argument('--Hsize', default = 512, type=int, nargs=1, help='image size')\n",
    "    parser.add_argument('--wl', default = 660e-9, type=float, nargs=1, help='wave length')\n",
    "    parser.add_argument('--k', default = 9.51e6, nargs=1, type=int, help='k value')\n",
    "    parser.add_argument('--loss_function', default = 'mix', type=str, help='training loss function')\n",
    "    parser.add_argument('--alpha', default = 5, type=float, nargs=1, help='trade-off value of mix loss function')\n",
    "    parser.add_argument('--model_name', default = 'pinn', type=str, help='project model')\n",
    "    parser.add_argument('--pretrain', default = False, type=bool, help='model pretrain')\n",
    "    parser.add_argument('--debug', action='store_true', help='debug mode')\n",
    "    parser.add_argument('--savefig', action='store_true',\n",
    "                        help='Save output images and masks')\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "    save_frq = 10\n",
    "    \n",
    "    #specify work\n",
    "    if args.model_name == 'pinn':\n",
    "        pinn = PINN(n_channels = args.input_nc, n_classes = args.output_nc, nf = args.nf, ks = args.ks, trade_off = args.tradeoff,\n",
    "                        dpix = args.dpix, z = args.d, Hsize = args.Hsize, _lambda = args.wl, k = args.k, method = args.itr_method) \n",
    "    elif args.model_name == 'unet':\n",
    "        pinn = Unet(n_channels = args.input_nc, n_classes = args.output_nc, nf = args.nf, ks = args.ks)\n",
    "    else:\n",
    "        pinn= DenseUNet(n_classes = args.output_nc)\n",
    "   \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Use {} GPUs\".format(torch.cuda.device_count()), \"=\" * 9)\n",
    "        pinn = nn.DataParallel(pinn)\n",
    "        if args.pretrain is True:\n",
    "            init_weights(pinn, 'normal', init_gain=0.02)\n",
    "    \n",
    "    pinn.to(device)\n",
    "    # loss\n",
    "    criterion_GAN = nn.MSELoss() #L2 loss\n",
    "    criterion_Sensitive = nn.L1Loss() #L1 loss\n",
    "    criterion_ssim = SSIM(window_size = 11) #SSIM loss\n",
    "    \n",
    "    # mix loss function recommended\n",
    "    if cuda:\n",
    "        pinn = pinn.cuda()\n",
    "        if args.loss_function == 'l2':\n",
    "            criterion_loss = criterion_GAN.cuda()\n",
    "        elif args.loss_function == 'l1':\n",
    "            criterion_loss = criterion_Sensitive.cuda()\n",
    "        elif args.loss_function == 'ssim':\n",
    "            criterion_loss = criterion_ssim.cuda()\n",
    "        elif args.loss_function == 'mix':\n",
    "            criterion_ssim = criterion_ssim.cuda() \n",
    "            criterion_mse = criterion_GAN.cuda()   \n",
    "\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(pinn.parameters(), lr=args.lr, betas=(args.beta1, args.beta2))\n",
    "\n",
    "    # learning rate schedulers\n",
    "    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=LambdaLR_(args.NUM_EPOCH, args.START_EPOCH, args.DECAY_EPOCH).step)\n",
    "\n",
    "   # input & target data & intensity images\n",
    "    train_dataset = build_phasedata(dataset = 'train', norm_range=(0, 1))\n",
    "    train_loader = train_phase_data_loader(dataset = train_dataset, crop_size=None, crop_n=None)\n",
    "    train_data = train_loader.__getitem__()\n",
    "    (train_im, train_gt, train_id, train_i0) = train_data\n",
    "    (m, m_chan, m_r, m_c) = train_im.shape\n",
    "\n",
    "    valid_dataset = build_phasedata(dataset = 'valid', norm_range=(0, 1))\n",
    "    valid_loader = train_phase_data_loader(dataset = valid_dataset, crop_size=None, crop_n=None)\n",
    "    valid_data = valid_loader.__getitem__()\n",
    "    (valid_im, valid_gt, valid_id, valid_i0) = valid_data\n",
    "    (m_valid, n_chan, n_r, n_c) = valid_im.shape\n",
    "\n",
    "    test_dataset = build_phasedata(dataset = 'test', norm_range=(0, 1))\n",
    "    test_loader = train_phase_data_loader(dataset = test_dataset, crop_size=None, crop_n=None)                                    \n",
    "    test_data = test_loader.__getitem__()\n",
    "    \n",
    "#     Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "    Tensor = torch.cuda.FloatTensor #GPU only\n",
    "    \n",
    "    Loss_list = [] #visualize result\n",
    "    valid_list = []\n",
    "    #Store models and the results in test-set\n",
    "    project_root = '' \n",
    "    save_dir = os.path.join(project_root, '\\\\%s' % args.model_name)\n",
    "    os.chdir(save_dir)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for epoch in range(args.START_EPOCH, args.NUM_EPOCH):\n",
    "        start_time = time.time()\n",
    "        count = 0\n",
    "        total_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        torch.cuda.empty_cache() #crear the GPU storage\n",
    "        train_mini_batches, valid_mini_batches, test_mini_batches = random_mini_batches(train_data, valid_data, test_data, mini_batch_size=args.BATCH_SIZE, shuffle = True)\n",
    "\n",
    "        #Training process\n",
    "        for minibatch in train_mini_batches:\n",
    "            count += 1\n",
    "        \n",
    "            im = prep_input(minibatch, mode='train')\n",
    "            target_img = im['targets']\n",
    "\n",
    "            ######## Train PINN ########\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            if count % args.CRITIC_ITER == 0:\n",
    "                \n",
    "                fake_img = pinn(im)\n",
    "                if args.loss_function == 'ssim':\n",
    "                    loss_G = -criterion_loss(fake_img,target_img)\n",
    "                elif args.loss_function == 'mix':\n",
    "                    loss_G = (1-criterion_ssim(fake_img,target_img)) * args.alpha + criterion_mse(fake_img,target_img)\n",
    "                else:\n",
    "                    loss_G = criterion_loss(fake_img,target_img)\n",
    "                total_loss += float(loss_G)\n",
    "                loss_G.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if count % 10 == 0:\n",
    "                print(\"EPOCH [{}/{}], STEP [{}/{}]\".format(epoch+1, args.NUM_EPOCH, count+1, m))\n",
    "                print(\"Total Loss G: {}\".format(loss_G))\n",
    "        end_time = time.time()\n",
    "        print(\"Training time is \",(end_time-start_time)/60,'mins')\n",
    "        Loss_list.append(total_loss / m)\n",
    "        \n",
    "    #Validation process\n",
    "        count = 0\n",
    "        for minibatch in valid_mini_batches:\n",
    "            count += 1\n",
    "            im = prep_input(minibatch, mode='valid')\n",
    "            target_img = im['targets']\n",
    "        \n",
    "            if count % args.CRITIC_ITER == 0:\n",
    "                \n",
    "                fake_img = pinn(im)\n",
    "                if args.loss_function == 'mix':\n",
    "                    loss_V = (1-criterion_ssim(fake_img,target_img)) * args.alpha + criterion_mse(fake_img,target_img)\n",
    "                else:\n",
    "                    loss_V = criterion_loss(fake_img,target_img)\n",
    "                valid_loss += float(loss_V)\n",
    "                \n",
    "            if count % 10 == 0:\n",
    "                print(\"Valid: 2-shot EPOCH [{}/{}], STEP [{}/{}]\".format(epoch+1, args.NUM_EPOCH, count, m_valid))\n",
    "                print(\"Total Loss V: {}\".format(loss_V))\n",
    "        valid_list.append(valid_loss / m_valid)\n",
    "    \n",
    "\n",
    "        #Test process save test figure in every 10 epochs\n",
    "        total_loss_t = 0.\n",
    "        test_count = 0\n",
    "        if (epoch+1) > (args.NUM_EPOCH/2) and (epoch+1) % args.SAVE_EPOCH == 0:\n",
    "            for mini_batch in test_mini_batches:\n",
    "                test_count += 1\n",
    "                im = prep_input(mini_batch, mode='test')\n",
    "                input_img = im['input']\n",
    "                target_img = im['targets']\n",
    "\n",
    "                fake_img = pinn(im)\n",
    "\n",
    "                if test_count % 1 == 0:\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "\n",
    "                        #pytorch tensor\n",
    "                        input_pic = input_img.cpu().numpy()\n",
    "                        fake_pic = fake_img.cpu().numpy()\n",
    "                        target_pic = target_img.cpu().numpy()\n",
    "\n",
    "                        #numpy array\n",
    "                        scio.savemat(\"InputIn\"+str(test_count)+\".mat\", {'array':input_pic})\n",
    "                        scio.savemat(str(epoch+1)+\"_\"+str(test_count)+\".mat\", {'array':fake_pic})\n",
    "                        scio.savemat(\"GT\"+str(test_count)+\".mat\", {'array':target_pic})\n",
    "    \n",
    "    #save models\n",
    "    torch.save(pinn.state_dict(),os.path.join(save_dir,'net.pth'))\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch_WXF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8fabc88d99945535ba9ceb4ce867800f20bfe6c6f54ef3203be94f92b308bfbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
